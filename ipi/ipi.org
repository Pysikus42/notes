#+AUTHOR: Robin Heinemann
#+TITLE: Einführung in die Anwendungsorientierte Informatik (Köthe)
#+OPTIONS: H:6
#+OPTIONS: ^:nil
#+LATEX_CLASS: koma-article
#+LATEX_CLASS_OPTIONS: [a4paper]
#+LATEX_HEADER: \usepackage{siunitx}%
#+LATEX_HEADER: \usepackage{fontspec}%
#+LATEX_HEADER: \sisetup{load-configurations = abbrevations}%
#+LATEX_HEADER: \newcommand{\estimates}{\overset{\scriptscriptstyle\wedge}{=}}%
#+LATEX_HEADER: \usepackage{mathtools}%
#+LATEX_HEADER: \DeclarePairedDelimiter\abs{\lvert}{\rvert}%
#+LATEX_HEADER: \DeclarePairedDelimiter\norm{\lVert}{\rVert}%
#+LATEX_HEADER: \DeclareMathOperator{\Exists}{\exists}%
#+LATEX_HEADER: \DeclareMathOperator{\Forall}{\forall}%
#+LATEX_HEADER: \def\colvec#1{\left(\vcenter{\halign{\hfil$##$\hfil\cr \colvecA#1;;}}\right)}
#+LATEX_HEADER: \def\colvecA#1;{\if;#1;\else #1\cr \expandafter \colvecA \fi}
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage{makecell}
# #+LATEX_HEADER: \usemintedstyle{tango}
#+LATEX_HEADER: \usemintedstyle{perldoc}
#+LATEX_HEADER: \usepackage{tikz}
#+LATEX_HEADER: \usetikzlibrary{arrows,automata}
#+LATEX_HEADER: \usepackage{tikz-qtree}
#+LATEX_HEADER: \usepackage{enumitem}
#+LATEX_HEADER: \setlistdepth{20}
#+LATEX_HEADER: \renewlist{itemize}{itemize}{20}
#+LATEX_HEADER: \setlist[itemize]{label=$\cdot$}
#+LATEX_HEADER: \usepackage{amsthm}
#+LATEX_HEADER: \theoremstyle{definition}
#+LATEX_HEADER: \newtheorem{defn}{Definition}
#+LATEX_HEADER: \theoremstyle{plain}
#+LATEX_HEADER: \newtheorem{thm}{Satz}
#+LATEX_HEADER: \theoremstyle{remark}
#+LATEX_HEADER: \newtheorem{remark}{Bemerkung}
#+LATEX_HEADER: \theoremstyle{remark}
#+LATEX_HEADER: \newtheorem{ex}{Beispiel}
#+LATEX_HEADER: \usepackage{etoolbox}
#+LATEX_HEADER: \patchcmd{\thmhead}{(#3)}{#3}{}{}
#+LATEX_HEADER: \usepackage{xparse}% http://ctan.org/pkg/xparse
#+LATEX_HEADER: \NewDocumentCommand{\overarrow}{O{=} O{\uparrow} m}{%
#+LATEX_HEADER:  \overset{\makebox[0pt]{\begin{tabular}{@{}c@{}}#3\\[0pt]\ensuremath{#2}\end{tabular}}}{#1}
#+LATEX_HEADER: }
#+LATEX_HEADER: \NewDocumentCommand{\underarrow}{O{=} O{\downarrow} m}{%
#+LATEX_HEADER:  \underset{\makebox[0pt]{\begin{tabular}{@{}c@{}}\ensuremath{#2}\\[0pt]#3\end{tabular}}}{#1}
#+LATEX_HEADER: }
#+LATEX_HEADER: \renewcommand*{\proofname}{Beweis}

# #+BEGIN_SRC cpp
# for(int i = 0; i < 5) {
#    std::cout << i << std::endl;
# }
# #+END_SRC

#+INCLUDE: "/home/robin/study/lectures/ipi/introduction.org" :minlevel 1
#+INCLUDE: "/home/robin/study/lectures/ipi/differences.org" :minlevel 1
#+INCLUDE: "/home/robin/study/lectures/ipi/substitution_model.org" :minlevel 1
#+INCLUDE: "/home/robin/study/lectures/ipi/machine_code.org" :minlevel 1
#+INCLUDE: "/home/robin/study/lectures/ipi/functional_programming.org" :minlevel 1
#+INCLUDE: "/home/robin/study/lectures/ipi/procedural_programming.org" :minlevel 1
#+INCLUDE: "/home/robin/study/lectures/ipi/datatypes.org" :minlevel 1
#+INCLUDE: "/home/robin/study/lectures/ipi/stack_model.org" :minlevel 1
#+INCLUDE: "/home/robin/study/lectures/ipi/references.org" :minlevel 1
#+INCLUDE: "/home/robin/study/lectures/ipi/container.org" :minlevel 1
#+INCLUDE: "/home/robin/study/lectures/ipi/itertators.org" :minlevel 1

* Insertion Sort
  schnellster Sortieralgorithmus für kleine Arrays ($n\leq 30$) hängt von Compiler und CPU ab
  - Idee von Insertion Sort:
	- wie beim Aufnehmen und Ordnen eines Kartenblatts
	- gegeben: bereits sortierte Teilmenge bis Position $k - 1$ Karten bereits in Fächer
	- Einfügen des k-ten Elements an richtiger Stelle \rightarrow Erzeuge Lücke an richtiger Position durch verschieben von Elementen nach rechts
	- Wiederholung für $k = 1, \ldots, N$
	- Beispiel:
	  | 4 | 2 | 3 | 5 | 1 |
	  |---+---+---+---+---|
	  | 4 | _ | 3 | 5 | 1 |
	  | _ | 4 | 3 | 5 | 1 |
	  | 2 | 4 | 3 | 5 | 1 |
	  |---+---+---+---+---|
	  | 2 | 4 | _ | 5 | 1 |
	  | 2 | _ | 4 | 5 | 1 |
	  | 2 | 3 | 4 | 5 | 1 |
	  |---+---+---+---+---|
	  | 2 | 3 | 4 | _ | 1 |
	  | 2 | 3 | 4 | 5 | 1 |
	  |---+---+---+---+---|
	  | 2 | 3 | 4 | 5 | _ |
	  | _ | 2 | 3 | 4 | 5 |
	  | 1 | 2 | 3 | 4 | 5 |
	  #+BEGIN_SRC cpp
	  void insertion_sort(std::vector<double> & v) {
		  for(int i = 0; i < v.size(); i++) {
			  double current = v[i];
			  int j = i; // Anfangsposition der Lücke
			  while(j > 0) {
				  if(v[j - 1] < current) { // -> if(cmp(a, b))
					  break; // j ist richtige Position der Lücke
				  }
				  v[j] = v[j - 1];
				  j--;
			  }
			  v[j] = current;
		  }
	  }
	  #+END_SRC
	- andere Sortierung: definiere Funktor cmp(a, b), der das gewünschte kleiner realisiert (gibt genau dann "true" zurück, wenn a "kleiner" b nach neuer Sortierung)
	- neue Sortierung am besten per Lambda-Funktion an std::sort übergeben
	  #+BEGIN_SRC cpp
	  std::sort(v.begin(), v.end()); // Standartsort mit "<"
	  std::sort(v.begin(), v.end(), [](double a, double b) { return a < b; }); // Standardsortierung aufsteigen
	  std::sort(v.begin(), v.end(), [](double a, double b) { return b < a; }); // absteigende Sortierung
	  std::sort(v.begin(), v.end(), [](double a, double b) { return std::abs(a) < std::abs(b); }); // Normal nach Betrag; // Normal nach Betrag
	  std::sort(v.begin(), v.end(), [](std::string a, std::string b) {
		  std::transform(a.begin(), a.end(), a.begin(), std::tolower);
		  std::transform(b.begin(), b.end(), b.begin(), std::tolower);
		  return a < b;
	  });
	  #+END_SRC
* generische Programmierung
  insertion_sort soll für beliebige Elementtypen funktionieren
  #+BEGIN_SRC cpp
	  template<typename T>
	  void insertion_sort(std::vector<T> & v) {
		  for(int i = 0; i < v.size(); i++) {
			  T current = v[i];
			  int j = i; // Anfangsposition der Lücke
			  while(j > 0) {
				  if(v[j - 1] < current) { // -> if(cmp(a, b))
					  break; // j ist richtige Position der Lücke
				  }
				  v[j] = v[j - 1];
				  j--;
			  }
			  v[j] = current;
		  }
	  }
  #+END_SRC
  - Ziel: benutze template-Mechanismus, damit *eine* Implementation für viele verschiedene Typen verwendbar ist
	- erweitert funktionale und prozedurale und objekt-orientiere Programmierung
  - zwei Arten von Templates ("Schablone"):
	1. Klassen-templates für Datenstrukturen, zum Beispiel Container sollen beliebige Elementtypen unterstützen
	   - Implementation $\implies$ später
	   - Benutzung: Datenstrukturname gefolgt vom Elementtyp in spitzen Klammern (std::vector<double>), oder mehrere Typen, zum Beispiel Schlüssel und Wert bei std::map<std::string, double>
	2. Funktionen-Templates: es gab schon function overloading
	   #+BEGIN_SRC cpp
	   int sq(int x) {
		   return x * x;
	   }

	   double sq(double x) {
		  return x * x;
	   }

	   // und so weiter für komplexe und rationale Zahlen...
	   #+END_SRC
	   - Nachteil
		 - wenn die Implementationen gleich sind \rightarrow nutzlose Arbeit
		 - Redundanz ist gefährlich: korrigiert man einen Bug wir leicht eine Variante vergessen
	   - mit templates reicht eine Implementation
		 #+BEGIN_SRC cpp
		 template<typename T> // T: Platzhalter für beliebigen Typ, wird später durch einen tatsächlichen Typ ersetzt
		 T sq(T x) {
			 return x * x; // implizierte Anforderung an den Typ T, er muss Multiplikation unterstützen, sonst: Fehlermeldung
		 }
		 #+END_SRC
		 - wie bei Substituieren von Variablen mit Werten, aber jetzt mit Typen
		 - Benutzung:
		   - Typen für die Platzhalter hinter dem Funktionsnamen in spitzen klammern
			 #+BEGIN_SRC cpp
			 sq<int>(2) == 4;
			 sq<double>(3.0) == 9.0,
			 #+END_SRC
		   - meist kann man die Typenangabe <type> weglassen, weil der Computer sie anhand des Argumenttyps automatisch einsetzt:
			 #+BEGIN_SRC cpp
			 sq(2); // == sq<int>(2) == 4
			 sq(3.0); // == sq<double>(3.0) == 9
			 #+END_SRC
		   - kombiniert man templates mit Overloading, wird die ausprogrammierte Variante vom Compiler bevorzugt.
			 Komplizierte Fälle (Argument teilweise Template, teilweise hard_coded) $\implies$ für Fortgeschrittene
		 - Beispiel 2: Funktion, die ein Array auf Konsole ausgibt, für beliebige Elementtypen
		   #+BEGIN_SRC cpp
		   template<typename ElementType>
		   void print_vector(std::vector<ElementType> const & v) {
			   std::cout << "{";
			   if(v.size() > 0) {
				   std::cout << " " << v[0];
				   for(int i = 1; i < v.size(); i++) {
					   std::cout << ", " << v[i];
				   }
			   }
			   std::cout << " }";
		   }
		   #+END_SRC
		 - Verallgemeinerung für beliebige Container mittels Iteratoren:
		   #+BEGIN_SRC cpp
		   std::list<int> l = {1, 2, 3};
		   print_container(l.begin(), l.end()); // "{1,2,3}"
		   #+END_SRC
		 - es genügen forward_itertators
		   #+BEGIN_SRC cpp
		   Iterator iter2 = iter1; // Kopie erzeugen
		   iter1++; // zum nächsten Element
		   iter1 == iter2; // Zeigen sie auf das selbe Element?
		   iter1 != end;
		   *iter1; // Zugriff auf aktuelles Element

		   template<typename Iterator>
		   void print_container(Iterator begin, Iterator end) {
			   std::cout << "{}";
			   if(begin != end) { // Container nicht leer?
				   std::cout << " " << *begin++;
				   for(;begin != end; begin++) {
					   std::cout << ", " << *begin;
				   }
			   std::cout << "}";
		   }
		   #+END_SRC
		 - Beispiel 3: überprüfen, ob Container sortiert ist
		   #+BEGIN_SRC cpp
		   template<typename E, typename CMP>
		   bool check_sorted(std::vector<E> const & v, CMP less_than) {
			   for(int i = 1; i < v.size(); i++) {
				   if(less_than(v[k], v[k - 1])) { // statt v[k] < v[k - 1], ausnutzen der Transitivität
					   return false;
				   }
			   }
			   return true;
		   }

		   // Aufruf:
		   std::vector<double> v = {1.0, 2.0, 3.0};
		   check_sorted(v, [](double a, double b) { return a < b; } ); // == true

		   check_sorted(v, [](double a, double b) { return a > b; } ); // == false

		   // Implementation für Iteratoren
		   template<typename Iterator, typename CMP>
		   bool check_sorted(Iterator begin, Iterator end, CMP less_than) {
			   if(begin == end) {
				   return true;
			   }
			   Iterator next = begin;
			   ++next;
			   for(; next != end; ++begin, ++next) {
				   if(less_than(*next, *begin)) {
					   return false;
				   }
			   }
			   return true;
		   }
		   // == std::is_sorted
		   #+END_SRC
		 - Bemerkung: Compiler-Fehlermeldungen bei Template-Code sind oft schwer zu interpretieren, $\implies$ Erfahrung nötig aber: Compiler werden darin immer besser, besonders clang-Compiler
		 - mit Templates kann man noch viel raffinierter Dinge machen, zum Beispiel Traits-Klassen, intelligent libraries template meta programming $\implies$ nur für Fortgeschrittene
* Effizienz von Algorithmen und Datenstrukturen
** Bestimmung der Effizienz
   2 Möglichkeiten:
   1. Messe die "wall clock time" - wie lange muss man auf das Ergebnis warten
   2. unabhängig von Hardware benutzt man das Konzept der algorithmischen Komplexität
*** wall clock
   wall clock time misst man zum Beispiel mit dem Modul <chrono>
   #+BEGIN_SRC cpp
   #include <chrono>
   #include <iostream>

   int main() {
	   // alles zur Zeitmessung vorbereiten

	   auto start = std::chrono::high_resolution_clock::now(); // Startzeit
	   // code der gemessen werden soll
	   auto stop = std::chrono::high_resolution_clock::now();
	   std::chrono::duration<double> diff = stop - start; // Zeitdifferenz
	   std::cout << "Zeitdauer: " << diff.count() << " Sekunden\n" << std::endl; // ausgeben
   }
   #+END_SRC
   Pitfalls:
   - moderne Compiler optimieren oft zu gut, das heißt komplexe Berechnungen werden zur Compilezeit ausgeführt und ersetzt $\implies$ gemessene Zeit ist viel zu kurz.
	 Abhilfen:
	 - Daten nicht "hard-wired", sondern zum Beispiel von Platte lesen
	 - "volatile" Schlüsselwort "volatile int k = 3;"
   - der Algorithmus ist schneller als die clock $\implies$ rufe den Algorithmus mehrmals in einer Schleife
	 auf
   - die Ausführung ihres Programms kann vom Betriebssystem jederzeit für etwas wichtigeres unterbrochen werden
	 (zum Beispiel Mail checken) $\implies$ gemessene Zeit zu lang $\implies$ messe
	 mehrmals und nimm die kürzeste Zeit (meist reicht 3 bis 10 fach)
   - Faustregel: Messung zwischen $\SI{0.02}{\second}$ und $\SI{3}{\second}$
   Nachteil: Zeit hängt von der Qualität der Implementation, den Daten (insbesondere der Menge) und der Hardware ab
*** algorithmische Komplexität
	Algorithmische Komplexität ist davon unabhängig, ist eine Art theoretisches Effizienzmaß. Sie
	beschreibt, wie sich die Laufzeit verlängert, wenn man mehr Daten hat.

	#+begin_ex latex
	Algorithmus braucht für $n$ Elemente $x$ Sekunden, wie lange dauert es für $2n$, $10n$ für große $n$
	#+end_ex
	Bei effiziente Algorithmen steigt der Aufwand mit $n$ nur langsam (oder bestenfalls gar nicht) \\
	Grundidee:
	1. berechne, wie viele elementare Schritte der Algorithmus in Abhängigkeit von $n$ benötigt $\implies$ komplizierte Formel $f(n)$
	2. vereinfache $f(n)$ in eine einfache Formel $g(n)$, die dasselbe wesentliche Verhalten hat. Die Vereinfachung erfolgt mittels *$O$-Notation* und ihren Verwandten
	   Gegeben: $f(n)$ und $g(n)$
	   1. $g(n)$ ist eine asymptotische (für große $n$) obere Schranke für $f(n)$ ("f(n) \leq g(n)"), $f(n) \in O(g(n))$ "$f(n)$ ist in der Komplexitätsklasse $g(n)$", wenn es ein $n_0$ (Mindestgröße) gibt
		  und $C$ (Konstante) gibt, sodass $\Forall n > n_0: f(n) \leq C g(n) \iff f(n) \in O(g(n))$
	   2. $g(n)$ ist asymptotische untere Schranke für $f(n)$ ($f(n) \geq g(n)$)
		  \[f(n) \in \Omega(g(n)) \iff \Exists n_0,C : \Forall n > n_0 f(n) \geq C g(n)\]
	   3. $g(n)$ ist asymptotisch scharfe Schranke für $f(n) (f(n) = g(n))$
		  \[f(n) \in \Theta(g(n)) \iff f(n) \in O(g(n)) \wedge f(n) \in \Omega(g(n))\]
	Regeln:
	1. $f(n) \in \Theta(f(n)) \implies f(n) \in O(f(n)), f(n) \in \Omega(f(n))$
	2. $c' f(n) \in \Theta(f(n))$
	3. $O(f(n)) \cdot O(g(n)) \in O(f(n) g(n))$ \hfill Multiplikationsregel
	4. $O(f(n)) + O(g(n)) \in O(\text{"max"}(f(n), g(n)))$ \hfill Additionsregel \\
	   formal: wenn $f(n) \in O(g(n)) \implies O(f(n)) + O(g(n)) \in O(g(n))$ \\
	   $g(n) \in O(f(n)) \implies O(f(n)) + O(g(n)) \in O(f(n))$
	5. $n^p \in O(n^q)$ wenn $p \leq q$
	Beliebte Wahl für $g(n)$
	- $O(1)$ \hfill "konstante Komplexität" \\
	  elementare Operation "+, -, *, /", Array-Zugriff v[k] (v: std::vector)
	- $O(\log(n))$ \hfill "logarithmische Komplexität" \\
	  zum Beispiel: auf Element von std::map zugreifen m[k] (m: std::map)
	- $O(n)$ \hfill "lineare Komplexität" \\
	  zum Beispiel std::transform() ($n$ = Anzahl der transformierten Elemente)
	- $O(n \log(n))$ \hfill{"n log n", "log linear" "linearithmisch"} \\
	  Beispiel: std::sort
	- $O(n^2)$ \hfill "quadratische Komplexität"
	- $O(n^p)$ \hfill "polynomielle Komplexität"
	- $O(2^n)$ \hfill "exponentielle Komplexität"
	#+begin_ex latex
	\[f(n) = 1 + 15 n + 4n^2 + 7n^3 \in O(n^3)\]
	#+end_ex
*** Anwendung
	1. Fibonacci-Zahlen: $f_k = f_{k - 2} + f_{k - 1}$
	   | k     | 0 | 1 | 2 | 3 | 4 | 5 | 6 |  7 |  8 |
	   |-------+---+---+---+---+---+---+---+----+----|
	   | $f_k$ | 0 | 1 | 1 | 2 | 3 | 5 | 8 | 13 | 21 |
	   #+begin_src cpp
	   int fib1(int k) {
		   if(k < 2) { // O(1)
			   return k; // O(1)
		   }
		   // O(1)
		   int f1 = 0; // letzten beiden Fibonacci Zahlen, anfangs die ersten beiden
		   int f2 = 1;
		   for(int i = 2; i <= k; i++) { // f(k) = k - 1 e O(k)
			   int f = f1 + f2; // O(1)
			   f1 = f2; // O(1)
			   f2 = f; // O(1)
		   } // gesamte Schleife: O(1)*O(k) = O(k)
		   return f2;
	   } // gesamte Funktion: teuerstes gewinnt: O(k)

	   // rekursive Variante:
	   int fib2(int k) {
		   if(k < 2) { // O(1)
			   return k; // O(1)
		   }
		   return fib2(k - 2) + fib2(k - 1);
	   }
	   #+end_src
	   - sehr ineffizient, weil alle Fibonacci-Zahlen $< k$  mehrmals berechnet werden
	   Sei $f(k)$  die Anzahl der Schritte, $f'(k)$ die Schritte oberhalb, Annahme: jeder Knoten ist $O(1) \implies f(k) \in O(\text{Anzahl Knoten})$.
	   Oberhalb ist der Baum vollständig (jeder nnere Knoten hat zwei Kinder), Anzahl der Knoten im vollständigen Baum der Tielfe $l$:
	   \[1 + 2 + 4 + \ldots + 2^l = 2^{l + 1} - 1\]
* Zahlendarstellung im Computer
  Problem: es gibt $\infty$ viele Zahlen, aber der Computer ist endlich.
** Natürliche Zahlen
   Natürliche Zahlen $\implies x \geq 0$. c++ bietet Typen verschiederne Größe.
   | klassisch          | mit Größe | Anzahl Bits | Bereich                | Literale |
   |--------------------+-----------+-------------+------------------------+----------|
   | unsigned char      | uint8_t   | ($\geq$) 8  | 0 - 255                |          |
   | unsigned short     | uint16_t  | ($\geq$) 16 | 0 - 65535              |          |
   | unsigned int       | uint32_t  | ($\geq$) 32 | 0 - $\SI{4e9}{}$       |          |
   | unsigned long      |           | 32 oder 64  |                        |          |
   | unsigned long long | uint64_t  | 64          | 0 - 0 -  $\SI{2e19}{}$ | L        |
   was passiert bei zu großen Zahlen? \\
   - alle Operationen werden Modula $2^m$ ausgeführt, wenn der Typ $m$ Bits hat
	 #+begin_src cpp
	 uint8_t x = 250, y = 100;
	 uint8_t s = x + y; // 350 % 256 = 94
	 uint8_t p = x * y; // 25000 % 256 = 168
	 #+end_src
   "integer overflow": einfach Bits oberhalb von $m$ wegwerfen
*** Pitfalls
	#+begin_src cpp
	std::vector<uint8_t> v = { ... };
	uint8_t sum = 0; // FALSCH, da es zu overflow kommen kann
	// verwende uint32_t, uint64_t, verhndern overflow mit hoher Wahrscheinlichkeit
	for(int k = 0; k < v.size(); k++) {
		sum += v[k];
	}

	// Endlosschleife, da i nie < 0, da unsigned
	// Abhilfe: int verwenden
	for(uint8_t i = v.size(); i >= 0; i++) {
		// auf v[k] zugreifen
	}
	#+end_src
*** arithmetische Operationen
	- Addition in Kapitel Automaten \\
**** Subtraktion
	 Subtraktion kann auf Addition zurückgeführt werden
	 Erinnerung: Restklassenarithmetik: (Modulo) \\
	 alle Zahlen mit dem gleichen Rest modulo $k$ bilden "Äquivalenzklasse", zum Beispiel $k = 4$
	 \begin{align*}
	 0 \mod 4 &= 0 \equiv 4 \mod 4 \equiv 8 \mod 4 \equiv 12 \mod 4 \ldots \\
	 1 \mod 4 &= 0 \equiv 5 \mod 4 \equiv 9 \mod 4 \equiv 13 \mod 4 \ldots \\
	 2 \mod 4 &= 0 \equiv 6 \mod 4 \equiv 10 \mod 4 \equiv 14 \mod 4 \ldots \\
	 3 \mod 4 &= 0 \equiv 7 \mod 4 \equiv 11 \mod 4 \equiv 15 \mod 4 \ldots \\
	 \end{align*}
	 Ein Mitglied jeder Äquivalentzklasse wird Represäntant. \\
	 Hier: kleinste Repreäsentanten $0, \ldots, (k - 1)$, mit $k = 2^m$
	 sind das gerade die uint-Werte \\
	 Eigenschaft: man kann Vielfache $n k$ addieren, ohne Äquivalenzklase zu ändern: \\
	 \[ (a - b) \mod 2^m = (a + \underbrace{2^m - b}_{\mathclap{z:~\text{Zweierkomplement}}}) \mod 2^m = (a + z) \mod 2^m \]
	 $z = (2^m - b) \mod 2^m$ lässt sich billig berechnen als $(\sim b + 1) \mod 2^m$
	 Dabei ist $\sim$ bitweise Negation (dreht alle Bits um)
	 - $m = 4, \sim(1001) = 0110$
	 #+begin_thm latex
	 \[(2^m - b) \mod 2^m = (\sim b + 1) \mod 2^m\]
	 #+end_thm
	 #+begin_proof latex
	 \begin{align*}
	 b + \sim b = 1111\ldots 1 = 2^m - 1 \\
	 \sim b + 1 = 2^{m} - b \\
	 \intertext{Fall 1: $b > 0$}
	 \implies \sim b < 2^m - 1 \implies \sim b + 1 < 2^m \implies (\sim b + 1) \mod 2^m = \sim b + 1 \\
	 \implies (\sim b + 1) \mod 2^m = (2^m - b) \mod 2^m \\
	 \intertext{Fall 2: $b = 0$}
	 \implies \sim b = 2^m - 1 \\
	 \sim b + 1 = 2^m \\
	 (\sim b + 1) \mod 2^m = 0 \\
	 2^m - b = 2^m
	 z = (2^m - b) \mod 2^m = (\sim b + 1) \mod 2^m = 0
	 \end{align*}
	 #+end_proof
**** Multiplikation
	 Neue Operationen: $\ll$  und $\gg$ (left und right shift). Verschiebt die Bits um $k$ Positionen nach
	 links oder rechts. Die herausgeschobenen Bits werden vergessen und auf der anderen Seite durch
	 $0$-bits ersetzt.

	 #+begin_src cpp
	 // m = 8
	 assert(11011101b << 3 == 11101000b)
	 assert(11011101b >> 3 == 00011011b)
	 #+end_src
	 #+begin_thm latex
	 \begin{align*}
	 x \ll k \equiv (x \cdot 2^k) \mod 2^m \\
	 x >> k \equiv (\frac{x}{2^k}) \\
	 \end{align*}
	 #+end_thm
	 Operation \& und |: bitw4eise und beziehungsweise oder-Verknüpfung (nicht verwechseln mit \&\& und || füür logische Operationen)
	 m = 8:
	 $10110011 \& 1 = $
	 | 1 | 0 | 1 | 1 | 0 | 0 | 1 | 1 |
	 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 |
	 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 |
	 (testet, ob in linker Zahl Bit 0 gesetzt ist)
	 $10110011 \mid 1 =$
	 | 1 | 0 | 1 | 1 | 0 | 0 | 1 | 1 |
	 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 |
	 | 1 | 0 | 1 | 1 | 0 | 0 | 1 | 1 |
	 kombiniere \& mit $\ll$:
	 \[x \& (1 \ll k)\]
	 testet, ob in $x$ Bit $k$ gesetzt ist.
	 #+begin_src cpp
	 uint8_t mul(uint8_t x, uint8_t y) {
		  uint8_t res = 0;
		  for(int i = 0; i < 8; i++) {
			   if(y & (1 << i)) {
					res += x;
			   }
			   x = x << 1; // x * 2
		  }
	 }
	 #+end_src
** Ganze Zahlen
   | klassisch        | mit Größe | Anzahl Bits | Bereich               |
   |------------------+-----------+-------------+-----------------------|
   | signed char      | int8_t    |           8 | -128 \ldots 127       |
   | signed short     | int16_t   |          16 | -2^15 \ldots 2^15 - 1 |
   | signed int       | int32_t   |          32 | -2^31 \ldots 2^31 - 2 |
   | signed long      |           |  32 oder 64 |                       |
   | signed long long | int64_t   |          64 | -2^63 \ldots 2^63 - 1 |
   Wird der erlaubte Bereich überschritte, ist Verhalten Compiler abhängig.
   In der Praxis: auch Modulo $2^m$, aber mit anderen Repräsentanten.


   für Restklassen: \\
   statt $0\ldots 2^m$ bei unsigned jetzt $-2^{m - 1} \ldots 2^{m - 2} - 1$ \\
   das heißt:
   - $x < 2^{m - 1}$: Repräsentant bleibt
   - $x \geq 2^{m - 1}$: neuer Represenant $x - 2^{m}$ ist gleiche Restklasse
   Vorteil: $x, -, *$ kann von unsigned übernommen werden \\
   $a,b$ signed: $a$ OP $b$ \to $c$ signed
   (interpretiere Bitmuster von $a$ und $b$ als unsigned und Interpretiere das Ergebnis dann als signed)
  Konsequenzen:
   - bei negativer Zahl ist höchstes Bit 1, weil $x \to x - 2^m$ falls $x \geq 2^{m - 1}$
   - unäre Negation $-x$ duch Zweierkomplement
	 \begin{align*}
	 -x &= (\sim x + 1) \mod 2^m \\
	 -0 &= (\sim 00000000 + 1) \mod 2^8 \\
	 &= (11111111 + 1) \mod 2^8 \\
	 &= \underbrace{(100000000)}_{2^8} \mod 2^8 = 0
	 -1 &= (\sim 00000001 + 1) \mod 2^8 \\
	 &= (11111110 + 1) \mod 2^8 \\
	 &= \underbrace{(11111111)}_{2^8 - 1 < 2^8} \mod 2^8 \\
	 &= 11111111
	 \end{align*}
   Ausnahmeregel für $\gg$ bei negativen Zahlen: Compilerabhängig, meist wird links
   ein 1-Bit reingeschoben, damit Zahl negativ bleibt $\implies$ es gilt immer noch $x \gg k = (x / 2^k)$
   Reichen 64 Bit nicht aus (zum Beispiel bei moderner Verschlüsselung) verwende BigInt: Datentyp variabler Größe.
   Zum Beispiel GNU Multi-Precision Library
