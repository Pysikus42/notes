#+AUTHOR: Robin Heinemann
#+TITLE: Einführung in die Anwendungsorientierte Informatik (Köthe)
#+OPTIONS: H:6
#+OPTIONS: ^:nil
#+LATEX_CLASS: koma-article
#+LATEX_CLASS_OPTIONS: [a4paper]
#+LATEX_HEADER: \usepackage{siunitx}%
#+LATEX_HEADER: \usepackage{fontspec}%
#+LATEX_HEADER: \sisetup{load-configurations = abbrevations}%
#+LATEX_HEADER: \newcommand{\estimates}{\overset{\scriptscriptstyle\wedge}{=}}%
#+LATEX_HEADER: \usepackage{mathtools}%
#+LATEX_HEADER: \DeclarePairedDelimiter\abs{\lvert}{\rvert}%
#+LATEX_HEADER: \DeclarePairedDelimiter\norm{\lVert}{\rVert}%
#+LATEX_HEADER: \DeclareMathOperator{\Exists}{\exists}%
#+LATEX_HEADER: \DeclareMathOperator{\Forall}{\forall}%
#+LATEX_HEADER: \def\colvec#1{\left(\vcenter{\halign{\hfil$##$\hfil\cr \colvecA#1;;}}\right)}
#+LATEX_HEADER: \def\colvecA#1;{\if;#1;\else #1\cr \expandafter \colvecA \fi}
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage{makecell}
# #+LATEX_HEADER: \usemintedstyle{tango}
#+LATEX_HEADER: \usemintedstyle{perldoc}
#+LATEX_HEADER: \usepackage{tikz}
#+LATEX_HEADER: \usetikzlibrary{arrows,automata}
#+LATEX_HEADER: \usepackage{tikz-qtree}
#+LATEX_HEADER: \usepackage{enumitem}
#+LATEX_HEADER: \setlistdepth{20}
#+LATEX_HEADER: \renewlist{itemize}{itemize}{20}
#+LATEX_HEADER: \setlist[itemize]{label=$\cdot$}
#+LATEX_HEADER: \usepackage{amsthm}
#+LATEX_HEADER: \theoremstyle{definition}
#+LATEX_HEADER: \newtheorem{defn}{Definition}
#+LATEX_HEADER: \theoremstyle{plain}
#+LATEX_HEADER: \newtheorem{thm}{Satz}
#+LATEX_HEADER: \theoremstyle{remark}
#+LATEX_HEADER: \newtheorem{remark}{Bemerkung}
#+LATEX_HEADER: \theoremstyle{remark}
#+LATEX_HEADER: \newtheorem{ex}{Beispiel}
#+LATEX_HEADER: \usepackage{etoolbox}
#+LATEX_HEADER: \patchcmd{\thmhead}{(#3)}{#3}{}{}
#+LATEX_HEADER: \usepackage{xparse}% http://ctan.org/pkg/xparse
#+LATEX_HEADER: \NewDocumentCommand{\overarrow}{O{=} O{\uparrow} m}{%
#+LATEX_HEADER:  \overset{\makebox[0pt]{\begin{tabular}{@{}c@{}}#3\\[0pt]\ensuremath{#2}\end{tabular}}}{#1}
#+LATEX_HEADER: }
#+LATEX_HEADER: \NewDocumentCommand{\underarrow}{O{=} O{\downarrow} m}{%
#+LATEX_HEADER:  \underset{\makebox[0pt]{\begin{tabular}{@{}c@{}}\ensuremath{#2}\\[0pt]#3\end{tabular}}}{#1}
#+LATEX_HEADER: }
#+LATEX_HEADER: \renewcommand*{\proofname}{Beweis}

# #+BEGIN_SRC cpp
# for(int i = 0; i < 5) {
#    std::cout << i << std::endl;
# }
# #+END_SRC

#+INCLUDE: "/home/robin/study/lectures/ipi/introduction.org" :minlevel 1
#+INCLUDE: "/home/robin/study/lectures/ipi/differences.org" :minlevel 1
#+INCLUDE: "/home/robin/study/lectures/ipi/substitution_model.org" :minlevel 1
#+INCLUDE: "/home/robin/study/lectures/ipi/machine_code.org" :minlevel 1
#+INCLUDE: "/home/robin/study/lectures/ipi/functional_programming.org" :minlevel 1
#+INCLUDE: "/home/robin/study/lectures/ipi/procedural_programming.org" :minlevel 1
#+INCLUDE: "/home/robin/study/lectures/ipi/datatypes.org" :minlevel 1
#+INCLUDE: "/home/robin/study/lectures/ipi/stack_model.org" :minlevel 1
#+INCLUDE: "/home/robin/study/lectures/ipi/references.org" :minlevel 1
#+INCLUDE: "/home/robin/study/lectures/ipi/container.org" :minlevel 1
#+INCLUDE: "/home/robin/study/lectures/ipi/itertators.org" :minlevel 1

* Insertion Sort
  schnellster Sortieralgorithmus für kleine Arrays ($n\leq 30$) hängt von Compiler und CPU ab
  - Idee von Insertion Sort:
	- wie beim Aufnehmen und Ordnen eines Kartenblatts
	- gegeben: bereits sortierte Teilmenge bis Position $k - 1$ Karten bereits in Fächer
	- Einfügen des k-ten Elements an richtiger Stelle \rightarrow Erzeuge Lücke an richtiger Position durch verschieben von Elementen nach rechts
	- Wiederholung für $k = 1, \ldots, N$
	- Beispiel:
	  | 4 | 2 | 3 | 5 | 1 |
	  |---+---+---+---+---|
	  | 4 | _ | 3 | 5 | 1 |
	  | _ | 4 | 3 | 5 | 1 |
	  | 2 | 4 | 3 | 5 | 1 |
	  |---+---+---+---+---|
	  | 2 | 4 | _ | 5 | 1 |
	  | 2 | _ | 4 | 5 | 1 |
	  | 2 | 3 | 4 | 5 | 1 |
	  |---+---+---+---+---|
	  | 2 | 3 | 4 | _ | 1 |
	  | 2 | 3 | 4 | 5 | 1 |
	  |---+---+---+---+---|
	  | 2 | 3 | 4 | 5 | _ |
	  | _ | 2 | 3 | 4 | 5 |
	  | 1 | 2 | 3 | 4 | 5 |
	  #+BEGIN_SRC cpp
	  void insertion_sort(std::vector<double> & v) {
		  for(int i = 0; i < v.size(); i++) {
			  double current = v[i];
			  int j = i; // Anfangsposition der Lücke
			  while(j > 0) {
				  if(v[j - 1] < current) { // -> if(cmp(a, b))
					  break; // j ist richtige Position der Lücke
				  }
				  v[j] = v[j - 1];
				  j--;
			  }
			  v[j] = current;
		  }
	  }
	  #+END_SRC
	- andere Sortierung: definiere Funktor cmp(a, b), der das gewünschte kleiner realisiert (gibt genau dann "true" zurück, wenn a "kleiner" b nach neuer Sortierung)
	- neue Sortierung am besten per Lambda-Funktion an std::sort übergeben
	  #+BEGIN_SRC cpp
	  std::sort(v.begin(), v.end()); // Standartsort mit "<"
	  std::sort(v.begin(), v.end(), [](double a, double b) { return a < b; }); // Standardsortierung aufsteigen
	  std::sort(v.begin(), v.end(), [](double a, double b) { return b < a; }); // absteigende Sortierung
	  std::sort(v.begin(), v.end(), [](double a, double b) { return std::abs(a) < std::abs(b); }); // Normal nach Betrag; // Normal nach Betrag
	  std::sort(v.begin(), v.end(), [](std::string a, std::string b) {
		  std::transform(a.begin(), a.end(), a.begin(), std::tolower);
		  std::transform(b.begin(), b.end(), b.begin(), std::tolower);
		  return a < b;
	  });
	  #+END_SRC
* generische Programmierung
  insertion\_sort soll für beliebige Elementtypen funktionieren
  #+BEGIN_SRC cpp
	  template<typename T>
	  void insertion_sort(std::vector<T> & v) {
		  for(int i = 0; i < v.size(); i++) {
			  T current = v[i];
			  int j = i; // Anfangsposition der Lücke
			  while(j > 0) {
				  if(v[j - 1] < current) { // -> if(cmp(a, b))
					  break; // j ist richtige Position der Lücke
				  }
				  v[j] = v[j - 1];
				  j--;
			  }
			  v[j] = current;
		  }
	  }
  #+END_SRC
  - Ziel: benutze template-Mechanismus, damit *eine* Implementation für viele verschiedene Typen verwendbar ist
	- erweitert funktionale und prozedurale und objekt-orientiere Programmierung
  - zwei Arten von Templates ("Schablone"):
	1. Klassen-templates für Datenstrukturen, zum Beispiel Container sollen beliebige Elementtypen unterstützen
	   - Implementation $\implies$ später
	   - Benutzung: Datenstrukturname gefolgt vom Elementtyp in spitzen Klammern (std::vector<double>), oder mehrere Typen, zum Beispiel Schlüssel und Wert bei std::map<std::string, double>
	2. Funktionen-Templates: es gab schon function overloading
	   #+BEGIN_SRC cpp
	   int sq(int x) {
		   return x * x;
	   }

	   double sq(double x) {
		  return x * x;
	   }

	   // und so weiter für komplexe und rationale Zahlen...
	   #+END_SRC
	   - Nachteil
		 - wenn die Implementationen gleich sind \rightarrow nutzlose Arbeit
		 - Redundanz ist gefährlich: korrigiert man einen Bug wir leicht eine Variante vergessen
	   - mit templates reicht eine Implementation
		 #+BEGIN_SRC cpp
		 template<typename T> // T: Platzhalter für beliebigen Typ, wird später durch einen tatsächlichen Typ ersetzt
		 T sq(T x) {
			 return x * x; // implizierte Anforderung an den Typ T, er muss Multiplikation unterstützen, sonst: Fehlermeldung
		 }
		 #+END_SRC
		 - wie bei Substituieren von Variablen mit Werten, aber jetzt mit Typen
		 - Benutzung:
		   - Typen für die Platzhalter hinter dem Funktionsnamen in spitzen klammern
			 #+BEGIN_SRC cpp
			 sq<int>(2) == 4;
			 sq<double>(3.0) == 9.0,
			 #+END_SRC
		   - meist kann man die Typenangabe <type> weglassen, weil der Computer sie anhand des Argumenttyps automatisch einsetzt:
			 #+BEGIN_SRC cpp
			 sq(2); // == sq<int>(2) == 4
			 sq(3.0); // == sq<double>(3.0) == 9
			 #+END_SRC
		   - kombiniert man templates mit Overloading, wird die ausprogrammierte Variante vom Compiler bevorzugt.
			 Komplizierte Fälle (Argument teilweise Template, teilweise hard_coded) $\implies$ für Fortgeschrittene
		 - Beispiel 2: Funktion, die ein Array auf Konsole ausgibt, für beliebige Elementtypen
		   #+BEGIN_SRC cpp
		   template<typename ElementType>
		   void print_vector(std::vector<ElementType> const & v) {
			   std::cout << "{";
			   if(v.size() > 0) {
				   std::cout << " " << v[0];
				   for(int i = 1; i < v.size(); i++) {
					   std::cout << ", " << v[i];
				   }
			   }
			   std::cout << " }";
		   }
		   #+END_SRC
		 - Verallgemeinerung für beliebige Container mittels Iteratoren:
		   #+BEGIN_SRC cpp
		   std::list<int> l = {1, 2, 3};
		   print_container(l.begin(), l.end()); // "{1,2,3}"
		   #+END_SRC
		 - es genügen forward_itertators
		   #+BEGIN_SRC cpp
		   Iterator iter2 = iter1; // Kopie erzeugen
		   iter1++; // zum nächsten Element
		   iter1 == iter2; // Zeigen sie auf das selbe Element?
		   iter1 != end;
		   *iter1; // Zugriff auf aktuelles Element

		   template<typename Iterator>
		   void print_container(Iterator begin, Iterator end) {
			   std::cout << "{}";
			   if(begin != end) { // Container nicht leer?
				   std::cout << " " << *begin++;
				   for(;begin != end; begin++) {
					   std::cout << ", " << *begin;
				   }
			   std::cout << "}";
		   }
		   #+END_SRC
		 - Beispiel 3: überprüfen, ob Container sortiert ist
		   #+BEGIN_SRC cpp
		   template<typename E, typename CMP>
		   bool check_sorted(std::vector<E> const & v, CMP less_than) {
			   for(int i = 1; i < v.size(); i++) {
				   if(less_than(v[k], v[k - 1])) { // statt v[k] < v[k - 1], ausnutzen der Transitivität
					   return false;
				   }
			   }
			   return true;
		   }

		   // Aufruf:
		   std::vector<double> v = {1.0, 2.0, 3.0};
		   check_sorted(v, [](double a, double b) { return a < b; } ); // == true

		   check_sorted(v, [](double a, double b) { return a > b; } ); // == false

		   // Implementation für Iteratoren
		   template<typename Iterator, typename CMP>
		   bool check_sorted(Iterator begin, Iterator end, CMP less_than) {
			   if(begin == end) {
				   return true;
			   }
			   Iterator next = begin;
			   ++next;
			   for(; next != end; ++begin, ++next) {
				   if(less_than(*next, *begin)) {
					   return false;
				   }
			   }
			   return true;
		   }
		   // == std::is_sorted
		   #+END_SRC
		 - Bemerkung: Compiler-Fehlermeldungen bei Template-Code sind oft schwer zu interpretieren, $\implies$ Erfahrung nötig aber: Compiler werden darin immer besser, besonders clang-Compiler
		 - mit Templates kann man noch viel raffinierter Dinge machen, zum Beispiel Traits-Klassen, intelligent libraries template meta programming $\implies$ nur für Fortgeschrittene
* Effizienz von Algorithmen und Datenstrukturen
** Bestimmung der Effizienz
   2 Möglichkeiten:
   1. Messe die "wall clock time" - wie lange muss man auf das Ergebnis warten
   2. unabhängig von Hardware benutzt man das Konzept der algorithmischen Komplexität
*** wall clock
   wall clock time misst man zum Beispiel mit dem Modul <chrono>
   #+BEGIN_SRC cpp
   #include <chrono>
   #include <iostream>

   int main() {
	   // alles zur Zeitmessung vorbereiten

	   auto start = std::chrono::high_resolution_clock::now(); // Startzeit
	   // code der gemessen werden soll
	   auto stop = std::chrono::high_resolution_clock::now();
	   std::chrono::duration<double> diff = stop - start; // Zeitdifferenz
	   std::cout << "Zeitdauer: " << diff.count() << " Sekunden\n" << std::endl; // ausgeben
   }
   #+END_SRC
   Pitfalls:
   - moderne Compiler optimieren oft zu gut, das heißt komplexe Berechnungen werden zur Compilezeit ausgeführt und ersetzt $\implies$ gemessene Zeit ist viel zu kurz.
	 Abhilfen:
	 - Daten nicht "hard-wired", sondern zum Beispiel von Platte lesen
	 - "volatile" Schlüsselwort "volatile int k = 3;"
   - der Algorithmus ist schneller als die clock $\implies$ rufe den Algorithmus mehrmals in einer Schleife
	 auf
   - die Ausführung ihres Programms kann vom Betriebssystem jederzeit für etwas wichtigeres unterbrochen werden
	 (zum Beispiel Mail checken) $\implies$ gemessene Zeit zu lang $\implies$ messe
	 mehrmals und nimm die kürzeste Zeit (meist reicht 3 bis 10 fach)
   - Faustregel: Messung zwischen $\SI{0.02}{\second}$ und $\SI{3}{\second}$
   Nachteil: Zeit hängt von der Qualität der Implementation, den Daten (insbesondere der Menge) und der Hardware ab
*** algorithmische Komplexität
	Algorithmische Komplexität ist davon unabhängig, ist eine Art theoretisches Effizienzmaß. Sie
	beschreibt, wie sich die Laufzeit verlängert, wenn man mehr Daten hat.

	#+begin_ex latex
	Algorithmus braucht für $n$ Elemente $x$ Sekunden, wie lange dauert es für $2n$, $10n$ für große $n$
	#+end_ex
	Bei effiziente Algorithmen steigt der Aufwand mit $n$ nur langsam (oder bestenfalls gar nicht) \\
	Grundidee:
	1. berechne, wie viele elementare Schritte der Algorithmus in Abhängigkeit von $n$ benötigt $\implies$ komplizierte Formel $f(n)$
	2. vereinfache $f(n)$ in eine einfache Formel $g(n)$, die dasselbe wesentliche Verhalten hat. Die Vereinfachung erfolgt mittels *$O$-Notation* und ihren Verwandten
	   Gegeben: $f(n)$ und $g(n)$
	   1. $g(n)$ ist eine asymptotische (für große $n$) obere Schranke für $f(n)$ ("f(n) \leq g(n)"), $f(n) \in O(g(n))$ "$f(n)$ ist in der Komplexitätsklasse $g(n)$", wenn es ein $n_0$ (Mindestgröße) gibt
		  und $C$ (Konstante) gibt, sodass $\Forall n > n_0: f(n) \leq C g(n) \iff f(n) \in O(g(n))$
	   2. $g(n)$ ist asymptotische untere Schranke für $f(n)$ ($f(n) \geq g(n)$)
		  \[f(n) \in \Omega(g(n)) \iff \Exists n_0,C : \Forall n > n_0 f(n) \geq C g(n)\]
	   3. $g(n)$ ist asymptotisch scharfe Schranke für $f(n) (f(n) = g(n))$
		  \[f(n) \in \Theta(g(n)) \iff f(n) \in O(g(n)) \wedge f(n) \in \Omega(g(n))\]
	Regeln:
	1. $f(n) \in \Theta(f(n)) \implies f(n) \in O(f(n)), f(n) \in \Omega(f(n))$
	2. $c' f(n) \in \Theta(f(n))$
	3. $O(f(n)) \cdot O(g(n)) \in O(f(n) g(n))$ \hfill Multiplikationsregel
	4. $O(f(n)) + O(g(n)) \in O(\text{"max"}(f(n), g(n)))$ \hfill Additionsregel \\
	   formal: wenn $f(n) \in O(g(n)) \implies O(f(n)) + O(g(n)) \in O(g(n))$ \\
	   $g(n) \in O(f(n)) \implies O(f(n)) + O(g(n)) \in O(f(n))$
	5. $n^p \in O(n^q)$ wenn $p \leq q$
	Beliebte Wahl für $g(n)$
	- $O(1)$ \hfill "konstante Komplexität" \\
	  elementare Operation "+, -, *, /", Array-Zugriff v[k] (v: std::vector)
	- $O(\log(n))$ \hfill "logarithmische Komplexität" \\
	  zum Beispiel: auf Element von std::map zugreifen m[k] (m: std::map)
	- $O(n)$ \hfill "lineare Komplexität" \\
	  zum Beispiel std::transform() ($n$ = Anzahl der transformierten Elemente)
	- $O(n \log(n))$ \hfill{"n log n", "log linear" "linearithmisch"} \\
	  Beispiel: std::sort
	- $O(n^2)$ \hfill "quadratische Komplexität"
	- $O(n^p)$ \hfill "polynomielle Komplexität"
	- $O(2^n)$ \hfill "exponentielle Komplexität"
	#+begin_ex latex
	\[f(n) = 1 + 15 n + 4n^2 + 7n^3 \in O(n^3)\]
	#+end_ex
*** Anwendung
	1. Fibonacci-Zahlen: $f_k = f_{k - 2} + f_{k - 1}$
	   | k     | 0 | 1 | 2 | 3 | 4 | 5 | 6 |  7 |  8 |
	   |-------+---+---+---+---+---+---+---+----+----|
	   | $f_k$ | 0 | 1 | 1 | 2 | 3 | 5 | 8 | 13 | 21 |
	   #+begin_src cpp
	   int fib1(int k) {
		   if(k < 2) { // O(1)
			   return k; // O(1)
		   }
		   // O(1)
		   int f1 = 0; // letzten beiden Fibonacci Zahlen, anfangs die ersten beiden
		   int f2 = 1;
		   for(int i = 2; i <= k; i++) { // f(k) = k - 1 e O(k)
			   int f = f1 + f2; // O(1)
			   f1 = f2; // O(1)
			   f2 = f; // O(1)
		   } // gesamte Schleife: O(1)*O(k) = O(k)
		   return f2;
	   } // gesamte Funktion: teuerstes gewinnt: O(k)

	   // rekursive Variante:
	   int fib2(int k) {
		   if(k < 2) { // O(1)
			   return k; // O(1)
		   }
		   return fib2(k - 2) + fib2(k - 1);
	   }
	   #+end_src
	   - sehr ineffizient, weil alle Fibonacci-Zahlen $< k$  mehrmals berechnet werden
	   Sei $f(k)$  die Anzahl der Schritte, Annahme: jeder Knoten ist $O(1) \implies f(k) \in O(\text{Anzahl Knoten})$
