#+AUTHOR: Robin Heinemann
#+TITLE: Analysis III (Marciniak-Czochra)

#+INCLUDE: "../header.org" :minlevel 1
#+LATEX_HEADER:	\theoremsymbol{}
#+LATEX_HEADER: \theoremstyle{nonumberplain}
#+LATEX_HEADER: \renewtheorem{remark}{Bemerkung}
#+LATEX_HEADER: \newtheorem{notation}{Notation}
#+LATEX_HEADER: \theoremstyle{}
#+LATEX_HEADER: \renewtheorem*{ex*}{Beispiel}

# Klausur 20.2.18
# Nachklausur 10.4.18

# Forster: Analysis 3 (Springer 2012)
# Elstrodt: Maß- und Integrationstheorie (Springer 2011)
# Bauer: Maß- und Integrationstheorie (De Gruyter 2011)
# Rudin
# Amman
# Hildebrandt

* Grundlagen der Maß- und Integrationstheorie
  Motivation: Erweiterung des Riemannintegrals auf einen größeren Bereich von Funktionen
  #+ATTR_LATEX: :options [Kriterium für Riemann Integrierbarkeit]
  #+begin_thm latex
  Sei $f:[a,b] \to ℝ$ beschränkt. Dann ist $f$ genau dann Riemann integrierbar, falls die Menge $S$ der Unstetigkeiten von $f$ eine Nullmenge ist, im Sinne, dass es
  für jedes für jedes $ε > 0$ eine abzählbare Familie von Intervallen $I_i$ gibt, mit
  \begin{align*}
  S &⊂ \bigcup_{i = 1}^∞ I_i \\
  \sum_{i = 1}^{∞} \abs{I_i} &< ε
  \end{align*}
  #+end_thm
  #+begin_remark latex
  Insbesondere ist die Funktion
  \[f:[0,1] \to ℝ, f(x) = \begin{cases} 1 & x ∈ ℚ \\  0 & x ∈ ℝ \setminus ℚ \end{cases}\]
  nicht Riemann integrierbar.
  #+end_remark
  Das Riemann-Integral der Funktion ist definiert über eine Zerlegnug des Definitionsbereiches in kleine Intervalle.
  Beim Lebesgue Integral wird stattdessen der Bildbereich zerlegt! Für eine nichtnegative $f: Ω \to [0, ∞], Ω ⊂ ℝ^n$
  betrachten wir die Mengen
  \[E_k := f^{-1}(\string(t_k, t_{k + 1}]) ⊂ ℝ^n\]
  wobei $t_k = h k$ für ein vorgegebenens $h > 0$, und approximieren dann das Integral von $f$ durch
  \begin{equation*}
  \sum_{i = 1}^{∞} t_k^{(h)} μ(E_k) \leq ∫ f(x) \d x \leq \sum_{i = 1}^{∞} t_{k + 1}^{(h)} μ(E_k) \tag{$\ast$}
  \end{equation*}
  wobei das *Maß* $μ: \mathcal{P}(ℝ^n) \to [0, ∞]$ eine Abbildung ist, welche das Maß
  der Menge $E = \mathcal{P}(ℝ^n)$ misst. Das Integral ergibt sich aus $(\ast)$ im Limes $h \to 0$.
  Für das Lebesgue-Integral müssen wir ein geeignetes Maß definieren $\to$ Lebesguemaß $\mathcal{L}^n$
  \[∫_0^1 f(x) \d \mathcal{L}^1(x) = \underbrace{\mathcal{L}^1(ℚ)}_{0} · 1 + \underbrace{\mathcal{L}^2(ℝ\setminus ℚ)}_{1} · 0 = 0\]
  #+ATTR_LATEX: :options [Maßproblem]
  #+begin_defn latex
  Wir suchen eine Abbildung $μ:\mathcal{P}(ℝ^n) \to [0, ∞]$ mit den folgenden Eigenschaft
  1. $μ(A) ⊆ μ(B) ∀ A ⊂ B$ \hfill (Monotonie)
  2. $\displaystyle{μ(\bigcup_{i = 1}^∞ A_i) = \sum_{i = 1}^{∞}μ(A_i)}$ falls $A_i \cap A_j = \emptyset ∀ i \neq j$ \hfill (\(σ\)-Additivität)
  3. $μ([0,1]^n) = 1$ \hfill (Normierung)
  4. $μ(Q A + y) = μ(A)$ falls $Q ∈ O(n), y ∈ ℝ^n$ \hfill (Euklidische Invarianz)
  Dieses Problem heißt Maßproblem. In einer etwas schwächeren Version kann man auch fordern
  2. [@2] $\displaystyle{μ(\bigcup_{i = 1}^k A_i) = \sum_{i = 1}^{k} μ(A_i)}$
  4. [@4] $μ(A + y) = μ(A)$ für $y ∈ ℝ^n$
  #+end_defn
  #+ATTR_LATEX: :options [Vitali: 1908]
  #+begin_thm latex
  Es gibt keine Abbildung $μ:\mathcal{P}(ℝ^n) \to [0, ∞]$ welche die Forderungen des Maßproblems erfüllt.
  #+end_thm
  #+begin_proof latex
  Sei $μ: \mathcal{P}(ℝ^n) \to [0, ∞]$ eine Abbildung die die Forderungen des Maßproblems erfüllt.
  Sei $q_i, i ∈ ℕ$ eine Abzählung von $[0, 1]^n \cap ℚ^n$. Wir definieren die Äquivalenzrelation
  $x \sim y$ auf $E := [0, 1]^n$ durch $x \sim y ⇔ x - y ∈ ℚ$. Nach dem Auswahlaxiom gibt es eine
  Menge $M_0 ⊂ [0,1]^n$, welche aus jeder Äquivalenzklasse genau ein Element enthält, das heißt es
  gilt:
  1. $∀ y ∈ [0, 1]^n ∃ x ∈ M_0: x \sim y ∈ ℚ$
  2. Aus $x, y ∈ M_0, x - y ∈ ℚ ⇒ x = y$
  Wir definieren $M_i = M_0 + q_i$. Aus der	Definition von $M_i$ folgt $M_i \cap M_j = \emptyset ∀ i \neq j$.
  In der Tat falls $x ∈ M_i \cap M_j$, dann $x - q_i ∈ M_0$ und $x - q_j ∈ M_0 \xRightarrow{1.} q_i = q_j$.
  Außerdem gilt $[0, 1]^n ⊂ \bigcup_{i = 1}^∞ M_i ⊂ [0, 2]^n$. Die erste Einbettung folgt aus 1., die zweite
  Einbettung gilt, da $y + q_j ∈ [0, 2]^n ∀ y ∈ M_0$ und $y ∈ [0, 1]^n$ schließlich gilt
  $μ(M_j) = μ(M_0) ∀ j ∈ ℕ$. Dies folgt aus den Forderungen 1., 3., 4. (abgeschwächte Version reicht).
  \[⇒ 1 = μ([0, 1]^n) \leq μ(\bigcup_{j = 0}^∞ M_j) = \sum_{i = 0}^{∞}μ(M_i) = \sum_{i = 0}^{∞} μ(M_0) ⇒ μ(M_i) = μ(M_0) > 0\]
  und
  \[μ(\bigcup_{i = 0}^∞ M_i) = ∞\]
  Aus 3. und 4. folgt andererseits
  \begin{align*}
  μ([0,2]^n) &= 2^n μ([0,1]^n) = 2^n \\
  \xRightarrow{(\ast)} μ(\bigcup_{i = 0}^∞ M_i) &\leq μ([0,2]^n) = 2^n < ∞ \lightning
  \end{align*}
  #+end_proof
  #+begin_remark latex
  Jedes Maß, welche die Eigenschaften des Maßproblems erfüllt, kann also nicht auf der ganzen
  $\mathcal{P}(ℝ^n)$ definiert sein, sondern auf einer Untermenge der $\mathcal{P}(ℝ^n)$.
  #+end_remark
  Frage: Welche ist die "größte" (eine "gute") Untermenge $\mathcal{A} ⊂ \mathcal{P}(ℝ^n)$, sodass
  es eine Lösung des Maßproblems gibt?
  #+ATTR_LATEX: :options [Algebra und \(σ\)-Algebra]
  #+begin_defn latex
  Eine Algebra $\mathcal{A}$ ist die Familie von Teilmengen einer gegebenen Menge $X$ mit
  - $X ∈ \mathcal{A}$
  - $A ∈ \mathcal{A} ⇒ A^C := X \setminus A ∈ \mathcal{A}$
  - $A, B ∈ \mathcal{A} ⇒ A \cup B ∈ \mathcal{A}$
  Falls
  \[(A_k)_{k ∈ ℕ} ⊂ \mathcal{A} ⇒ \bigcup_{k ∈ ℕ} A ∈ \mathcal{A}\]
  so spricht man von einer \(σ\)-Algebra.
  #+end_defn
  #+begin_lemma latex
  Sei $X$ eine Menge, $\mathcal{A}$ eine $σ$ Algebra und $(A_k)_{k ∈ ℕ} ⊂ \mathcal{A}$. Dann gehören $\emptyset, \bigcap_{k ∈ ℕ} A_k$ und $A_1 \setminus A_2$ zu $\mathcal{A}$.
  #+end_lemma
  #+begin_proof latex
  (Übung)
  #+end_proof
  #+ATTR_LATEX: :options [Erzeugte und relative \(σ\)-Algebra]
  #+begin_defn latex
  Für $S ⊂ \mathcal{P}(X)$ wird
  \[Σ(S) = Σ(S \mid X) := \bigcap \{\mathcal{A} ⊂ \mathcal{P}(X) \mid \mathcal{A} \text{ ist eine \(σ\)-Algebra mit \(S ⊆ \mathcal{A}\)}\}\]
  als die von $S$ erzeugte \(σ\)-Algebra bezeichnet.
  $∀ Y ⊂ X$ definieren wir die relative \(σ\)-Algebra
  \[\mathcal{A} \cap Y := \{A \cap Y \mid A ∈ \mathcal{A}\}\]
  #+end_defn
  #+begin_lemma latex
  Die erzeugte relative \(σ\)-Algebra sind wohldefiniert. Für alle Mengen $S ⊂ \mathcal{P}(X), Y ⊂ X$ gilt
  \[Σ(S \cap Y \mid Y) = Σ(S \mid X) \cap Y\]
  #+end_lemma
  #+begin_proof latex
  (Übungen)
  #+end_proof
  #+ATTR_LATEX: :options [Topologischer Raum]
  #+begin_defn latex
  Ein topologischer Raum ist ein Paar $(X,\mathcal{O})$ bestehend aus Menge $X$ und $\mathcal{O} ⊂ \mathcal{P}(X)$ mit
  - $\emptyset, X ∈ \mathcal{O}$
  - $U, V ∈ \mathcal{O} ⇒ U \cap V ∈ \mathcal{O}$
  - $(U_k)_{k ∈ I} ⊂ \mathcal{O} ⇒ \bigcup_{k ∈ I} U_k ∈ \mathcal{O}$ für eine beliebige Indexmenge $I$.
  Die Elemente von $\mathcal{O}$ werden als *offene Menge* bezeichnet.
  #+end_defn
  #+begin_remark latex
  Topologische Raum ist abgeschlossen unter endlichen Schnitten und abzählbaren Vereinigungen.
  #+end_remark
  #+ATTR_LATEX: :options [Borel-\(σ\)-Algebra, Borel Menge]
  #+begin_defn latex
  Ist $X$ ein topologischer Raum, so ist die Borel-\(σ\)-Algebra $\mathcal{B}(X)$ diejenige \(σ\)-Algebra, die von den offenen Mengen erzeugt wird. Ihre Elemente heißen Borel-Mengen.
  \begin{align*}
  \mathcal{B}^n &:= \mathcal{B}(ℝ^n) \\
  \mathcal{B} &:= \mathcal{B}^1 \\
  \end{align*}
  #+end_defn
  #+begin_remark latex
  Die \(σ\)-Algebra die von den abgeschlossenen Mengen erzeugt wird, ist ebenfalls identisch mit der Borel \(σ\)-Algebra.
  #+end_remark
  #+ATTR_LATEX: :options [Messraum, Maß, Maßraum]
  #+begin_defn latex
  Eine Menge $X$ mit einer \(σ\)-Algebra $\mathcal{A} ⊂ \mathcal{P}(X)$ heißt *Messraum*. Ein *Maß* ist eine Abbildung $μ: \mathcal{A} \to [0, ∞]$ mit
  - $μ(\emptyset) = 0$
  - $μ(\bigcup_{k ∈ ℕ} A_k) = \sum_{k ∈ ℕ} μ(A_k)$ für disjunkte Mengen \hfill\(σ\)-Additivität
  Die Elemente in $\mathcal{A}$ heißen messbar, und $(X, \mathcal{A}, μ)$ heißt *Maßraum*.
  #+end_defn
  #+ATTR_LATEX: :options [\(σ\)-Finitheit]
  #+begin_defn latex
  Ein Mah heißt \(σ\)-finit, falls es eine abzählbare Überdeckung $\{X_k\}_{k ∈ ℕ} ⊂ \mathcal{A}$ von $X$ gibt, also
  \[X = \bigcup_{k ∈ ℕ} X_k\]
  sodass $μ(X_k) < ∞ ∀ k$. \\
  $μ$ heißt endlich falls $μ(X) < ∞$. Bei Wahrscheinlichkeitsmaß $μ(X) = 1$.
  #+end_defn
  #+begin_ex latex
  1. Zählmaß: Für $X$ und $\mathcal{A} = \mathcal{P}(X)$ setze für $A ∈ \mathcal{A}$:
	 \[μ(A) = \begin{cases} \# A & A \text{ endlich} \\ ∞ & \text{sonst}\end{cases}\]
	 $μ$ ist endlich falls $X$ endlich und \(σ\)-finit wenn $X$ abzählbar.
  2. Dirac-Maß: Für einen fest gewählten $x_0 ∈ X$ und $\mathcal{A} = \mathcal{P}(X)$ setzen wir für $A ⊂ X$
	 \[μ(A) := \begin{cases} 0 & x_0 \not∈ A \\ 1 & x_0 ∈ A\end{cases}\]
  3. Positive Linearkombination: $μ_1, μ_2$ Maße auf $(X, \mathcal{A})$. Dann ist $μ := α_1 μ_1 + α_2 μ_2$ für $α_1, α_2 \geq 0$ wieder
	 ein Maß
  #+end_ex
  #+begin_lemma latex
  Sei $(X, \mathcal{A}, μ)$ ein Maßraum und $Y ∈ \mathcal{A}$. Dann ist $μ\mid_Y(A) := μ(A \cap Y) ∀ A ∈ \mathcal{A}$ wieder ein Maß auf $(X, \mathcal{A})$.
  Durch Einschränken der \(σ\)-Algebra $\mathcal{A}$ auf $\mathcal{A}\mid_Y := \{A ∈ \mathcal{A} \mid A ⊂ Y\}$ wird $(Y, \mathcal{A}\mid_Y, μ\mid_Y)$ auch ein Maßraum.
  Falls $(X, \mathcal{A}, μ)$ \(σ\)-finit, dann $(Y, \mathcal{A}\mid_Y, μ\mid_Y)$ auch.
  #+end_lemma
  *Notation*: Zu $(A_k)_{k ∈ ℕ} ⊂ X$ schreiben wir
  - $A_k \nearrow A (k \to ∞)$ falls $A_k ⊂ A_{k + 1} ∀ k ∈ ℕ$ und $A = \bigcup_{k ∈ ℕ} A_k$
  - $A_k \searrow A (k \to ∞)$ falls $A_k \supset A_{k + 1} ∀ k ∈ ℕ$ und $A = \bigcap_{k ∈ ℕ} A_k$

  #+begin_thm latex
  Für jeden Maßraum $(X, \mathcal{A}, μ)$ und $(A_k)_{k ∈ ℕ} ⊂ \mathcal{A}$ gilt
  1. $A_1 ⊂ A_2 ⇒ μ(A_1) \leq μ(A_2)$ \hfill (Monotonie)
  2. $μ(\bigcup_{k ∈ ℕ} A_k) \leq \sum_{k ∈ ℕ} μ(A_k)$ \hfill (\(σ\)-Subadditivität)
  3. $A_k \nearrow A ⇒ μ(A_k) \nearrow μ(A)$ für $(k \to ∞)$ \hfill (Stetigkeit von Unten)
  4. $A_k \searrow A ⇒ μ(A_k) \searrow μ(A)$ für $(k \to ∞)$ und $μ(A_1) < ∞$ \hfill (Stetigkeit von Oben)
  #+end_thm
  #+begin_proof latex
  1. $A, B ∈ \mathcal{A}, A ⊂ B ⇒ B = A \dcup (B \setminus A), B \setminus A ∈ \mathcal{A} ⇒ μ(B) = μ(A) + μ(B\setminus A) \geq μ(A)$
  2. Wir definieren $(B_k)_{k ∈ ℕ} ⊂ \mathcal{A}$ durch
	 \begin{align*}
	 B_1 &:= A_1, B_{k + 1} := A_{k + 1} \setminus \bigcup_{j = 1}^k A_k
	 ⇒ \bigdcup_{k ∈ ℕ} B_k &= \bigcup_{k ∈ ℕ} A_k
	 \end{align*}
	 Nach Definition gilt
	 \[μ(\bigcup_{k ∈ ℕ} A_k) = μ(\bigcup_{k ∈ ℕ} B_k) = \sum_{k ∈ ℕ}μ(B_k) \leq \sum_{k ∈ ℕ} μ(A_k)\]
  3. Definieren $(C_k)_{k ∈ ℕ} ⊂ \mathcal{A}$ durch
	 \begin{align*}
	 C_1 &:= A_1 \\
	 C_{k + 1} &:= A_{k + 1} \setminus A_k
   	 \end{align*}
	 Es gilt
	 \begin{align*}
	 ⇒ \bigdcup_{k ∈ ℕ} C_k &= \bigcup_{k ∈ ℕ} A_k = A \\
	 μ(A_k) &= \sum_{j = 1}^{k} μ(C_j) \xrightarrow{k \to ∞} \sum_{k ∈ ℕ} μ(C_k) = μ(A) \leq \sum_{k ∈ ℕ} μ(A_k)
   	 \end{align*}
  4. $D_k := A_1 \setminus A_k ∀ k ∈ ℕ$. Damit ist $D_k \nearrow A_1 \setminus A$ und
	 \[μ(A_1) - μ(A_k) = μ(A_1 \setminus A_k) \xrightarrow{k \to ∞}[3.] μ(A_1 \setminus A) = μ(A_1) - μ(A)\]
	 Subtraktion von $μ(A_1) < ∞$ liefert die Behaptung.
  #+end_proof
  #+begin_ex latex
  $μ: \mathcal{P}(ℕ) \to [0, ∞], μ(A) := \# A$. Die Mengenfolge $A_n := \{n, n + 1, n + 2, \dots\}$ ist fallend gegen die leere Menge, aber es ist
  \[0 = μ(\emptyset) \neq \lim_{n \to ∞} μ(A_n) = ∞\]
  #+end_ex
  #+ATTR_LATEX: :options [Borel-Maß]
  #+begin_defn latex
  Set $X$ ein topologischer Raum. Ein Maß auf einer Borel-\(σ\)-Algebra $\mathcal{B}(X)$ heißt Borel-Maß, falls es auf Kompakta stets endlich Werte annimmt.
  #+end_defn
  #+begin_ex latex
  Für $X = ℝ$ ist das Dirac-Maß ein Brel-Maß, aber nicht das Zählmaß.
  #+end_ex
  #+ATTR_LATEX: :options [Regularität]
  #+begin_defn latex
  Sei $X$ ein topologischer Raum, $(X, \mathcal{A}, μ)$ ein Maßraum. Das Maß $μ$ heißt *regulär von außen*, wenn für $A ∈ \mathcal{A}$ gilt
  \[μ(A) = \inf \{μ(U) \mid A ⊂ U, U \text{ offen}\}\]
  $μ$ heißt *regulär von innen*, wenn für $A ∈ \mathcal{A}$ gilt
  \[μ(A) = \sup\{μ(K) \mid K ⊂ A, K \text{kompakt}\}\]
  #+end_defn
  #+begin_ex latex
  Das Zählmaß mit $X = ℝ, \mathcal{A} = \mathcal{B}$, ist regulär von inne, aber nicht von außen. Das Dirac-Maß ist regulär.
  #+end_ex
  \begin{defn*}[Kompaktheit]
  Sei $X$ ein topologischer Raum und $A ⊂ X$. Dann nennt man $A$ kompakt, wenn \textbf{jede} offene Überdeckung von $A$ eine \textbf{endliche} Teilüberdeckung besitzt.
  Das beutet:
  \[∀ I ∃ I' ⊂ I, \abs{I'} < ∞: A ⊂ \bigcup_{i ∈ I} A_i ⇒ A ⊂ \bigcup_{i ∈ I'} A_i\]
  \end{defn*}
  #+begin_remark latex
  In einem metrischen Raum isnd die bisherigen Definitionen der Kompaktheit mit der neu eingeführten äquivalent.
  #+end_remark
  *Konstruktion von Maßen* \\
  Strategie:
  1. Starte mit einem Prämaß $λ$ auf einer Algebra endlichen, disjunkten Vereinigungen von Intervallen, $λ$ = Summe der Längen
  2. Dieses Prämaß kann zu einem äußeren Maß auf $\mathcal{P}(ℝ)$ fortgesetzt werden (keine \(σ\)-Additivität)
  3. Einschränkung auf Borel-\(σ\)-Algebra liefert ein Maß.

  #+ATTR_LATEX: :options [Dynkin-System]
  #+begin_defn latex
  Eine Familie $\mathcal{D} ⊂ \mathcal{P}(X)$, $X$ Menge, heißt Dynkin-System, falls gilt:
  1. $X ∈ \mathcal{D}$
  2. $A ∈ \mathcal{D} ⇒ A^C ∈ \mathcal{D}$
  3. $\displaystyle{(A_k)_{k ∈ ℕ} ⊂ \mathcal{D}, A_k ∩ A_l = \emptyset ∀ k, l ∈ ℕ, k \neq l ⇒ \bigcup_{k ∈ ℕ A_k ∈ \mathcal{D}}}$
  #+end_defn
  #+begin_remark latex
  1. Ein Dynkin-System ist abgeschlossen bezüglich Mengensubtraktion:
	 \[A, B ∈ \mathcal{D}, B ⊂ A ⇒ A \setminus B = A ∩ B^C = (A^C ∪ B)^C ∈ \mathcal{D}\]
  2. Ist $S ⊂ \mathcal{P}(X)$, so ist
	 \[\mathcal{D}(S) = \bigcap \{\mathcal{D} \mid \mathcal{D} \text{ Dynkin-System}, S ⊂ \mathcal{D}\}\]
	 das von $S$ erzeugte Dynkin-System
  3. Das von $S$ erzeugte Dynkin-System ist	wohldefinieret, dass heiß, es ist eindeutig und tatsächlich ein Dynkin-System.
  #+end_remark
  #+begin_lemma latex
  Ist $\mathcal{D}$ ein Dynkin-System und abgeschlossen bezüglich endlicher Schnitte oder alternativ bezüglich beliebiger (also nicht disjunkter)
  endlicher Vereinigung, so ist $\mathcal{D}$ eine \(σ\)-Algebra
  #+end_lemma
  #+begin_proof latex
  Übungen
  #+end_proof
  #+begin_lemma latex
  Sei $S$ eine (nicht leere) Familie von Teilmengen einer Menge $X$, die abgeschlossen ist unter endlichen Schnitten sind, dann folgt $\mathcal{D}(S) = Σ(S)$
  #+end_lemma
  #+begin_proof latex
  Nach Definition gilt $\mathcal{D} ⊂ Σ(S)$. Die andere Inklusion folgt sofort, wenn wir zeigen, dass $\mathcal{D}(S)$ \(σ\)-Algebra ist.
  Nach Lemma 1.21 genügt es zu zeigen, dass $\mathcal{D}(S)$ abgeschlossen ist unter endlichen Schnitten. Definiere für ein	beliebiges $A ∈ \mathcal{D}(S)$
  \[D(A) := \{B ∈ \mathcal{D} \mid A ∩ B ∈ \mathcal{D}\} ⊂ \mathcal{D}\]
  wir müssen beweisen $D(A) = \mathcal{D}$ für alle $A ∈ \mathcal{D}$. Es gilt
  1. $X ∈ \mathcal{D}, A ∩ X = A ∈ \mathcal{D} ⇒ X ∈ D(A)$
  2. $B ∈ D(A) ⇒ B ∈ \mathcal{D}, A ∩ B ∈ \mathcal{D}$ woraus folgt
	 \[A ∩ B^C = A \setminus (B ∩ A) ∈ \mathcal{D} ⇒ B^C ∈ D(A)\]
  3. $B = \bigcup_{k ∈ ℕ} B_k, B_k ∈ D(A) ⇒ B_k ∈ \mathcal{D}, A ∩ B_k ∈ \mathcal{D}$ woraus folgt, dass $B ∈ \mathcal{D}$ und
	 \[B ∩ A = \bigcup_{k ∈ ℕ} (B_k ∩ A) ∈ \mathcal{D} ⇒ B ∈ D(A)\]
  Behauptung: $A ∈ S ⇒ S ⊂ D(A)$, denn: $B ∈ S ⇒ A ∩ B ∈ S ⇒ B ∈ D(A)$.
  Da $\mathcal{D} = D(S)$ das kleinste Dynkin-System ist, das $S$ enthätlt folgt $\mathcal{D} ⊂ D(A) ⇒ \mathcal{D} = D(A)$.
  Für beliebiges $U ∈ S, V ∈ \tilde{\mathcal{D}} = D(U)$ folgt nach Definition $U ∩ V ∈ \mathcal{D}$. Dies impliziert $U ∈ D(V)$, also $S ⊂ D(V) ∀ V ∈ \mathcal{D}$.
  Wie eben ist $D(V) ⊂ \mathcal{D}$, also $D(V) = \mathcal{D} ∀ V ∈ \mathcal{D}$.
  #+end_proof
  #+begin_remark latex
  Lemma 1.22 lässt sich wie folgt anwenden:
  1. Verifiziere eine Eigenschaft $ε$ auf einer Menge $S ⊂ \mathcal{P}(X)$, die abgeschlossen ist unter endlichen Schnitten ist.
  2. Zeige, dass die Menge aller Mengen, die $ε$ erfüllen ein Dynkin-System ist.
  3. Schließe, dass $ε$ auf $Σ(S)$ gilt.
  #+end_remark
  #+ATTR_LATEX: :options [Eindeutigkeit von Maßen]
  #+begin_thm latex
  Sei $(X, Σ, μ)$ ein Maßraum und $S ⊂ \mathcal{P}(X)$ Familie von Menge, die abgeschlossen unter endlichen Schnitten und $Σ = Σ(S)$.
  Weiter enthalte $S$ eine Folge aufsteigender Mengen $(X_k)_{k ∈ ℕ} ⊂ S$ mit $X_k \nearrow X$ und $μ(X_k) < ∞$ für alle $k ∈ ℕ$. Dann ist $μ$ auf $Σ = Σ(S)$ durch die Werte auf $S$ eindeutig bestimmt.
  #+end_thm
  #+begin_proof latex
  Sei $\tilde μ$ ein weiteres Maß mit $\tilde μ = μ$ auf $S$. Dann gilt
  \[\tilde μ(X) = \lim_{k \to ∞} \tilde μ(X_k) = \lim_{k \to ∞} μ(X_k) = μ(X)\]
  zunächst $μ(X) < ∞$. Idee:
  \[\mathcal{D}= \{A ∈ Σ \mid \tilde μ(A) = μ(A)\}\]
  ist ein Dynkin-System. \\
  $X ∈ \mathcal{D}$ bereits gezeigt. Für $A ∈ \mathcal{D}$ ist
  \[\tilde μ(A^C) = \tilde μ(X) - \tilde μ(A) = μ(X) - μ(A) = μ(A^C)\]
  $⇒ A^C ∈ \mathcal{D}$. Betrachte $(B_k)_{k ∈ ℕ}, B_k ∩ B_l = \emptyset ∀ k, l ∈ ℕ, k \neq l$ und $B_k ∈ \mathcal{D}$ sowie $B = \bigcup_{k ∈ ℕ} B_k$. Dann gilt
  \[\tilde μ(B) = \sum_{k ∈ ℕ} \tilde μ(B_k) = \sum_{k ∈ ℕ} μ(B_k) = μ(B)\]
  Nach Lemma 1.22 folgt also $Σ = Σ(S) = \mathcal{D}(S) ⊂ \mathcal{D} ⊂ Σ ⇒ \mathcal{D} = Σ$. \\
  Im allgemeinen Fall erhalten wir für $A ∈ Σ$:
  \[\tilde μ(A) = \lim_{k \to ∞}  \tilde μ(A ∩ X_k) = \lim_{k \to ∞} μ(X_k ∩ A)\]
  #+end_proof
  #+ATTR_LATEX: :options [Prämaß]
  #+begin_defn latex
  Sei $X$ eine Menge und $\mathcal{A} ⊂ \mathcal{P}(X)$ eine Algebra. Ein *Prämaß* auf $X$ ist eine \(σ\)-additive Abbildung $μ: \mathcal{A} \to [0, ∞]$ mit $μ(\emptyset) = 0$.
  #+end_defn
  #+begin_remark latex
  Man braucht nur die \(σ\)-Additivität für solche (paarweise disjunkte) Folgen $(A_k)_{k ∈ ℕ} ⊂ \mathcal{A}$ gewährleisten, deren Vereinigung
  \[\bigcup_{k ∈ ℕ} A_k ∈ \mathcal{A}\]
  Ein Prämaß auf einer \(σ\)-Algebra ist ein Maß.
  #+end_remark
  #+begin_korollar latex
  Sei $μ$ ein \(σ\)-finites Prämaß auf einer Algebra $\mathcal{A}$, dann gibt es höchstens eine Fortsetzung auf $Σ(\mathcal{A})$.
  #+end_korollar
  #+begin_proof latex
  Setze $S = \mathcal{A}$ wie im Satz 1.23. Offenbar ist abgeschlossen unter endlichen Schnitten. Da $X$ \(σ\)-finit ist, gibt es eine
  Folge $(X_k)_{k ∈ ℕ}$ mit $X = \bigcup_{k ∈ ℕ} X_k$ und $μ(X_k) < ∞ ∀ k ∈ ℕ$. Für $A_k := \bigcup_{j = 1}^k X_j$ ist $A_k \nearrow X$ und
  \[μ(A_k) \leq \sum_{j = 1}^{k} μ(X_k) < ∞\]
  Nach dem Setz 1.23 ist das auf $(X, Σ)$, so es denn existiert, eindeutig.
  #+end_proof
  #+begin_ex latex
  Die Menge $S$, sei die Menge, die alle Intervalle $[a, b\string), -∞ \leq a \_eq b \leq ∞$ erzeugt dann unter endlichen Vereinigungen eine Algebra $\mathcal{A}$.
  Wir setzen
  \begin{align*}
  μ(\emptyset) &= 0 \\
  μ([a, b\string)) &= ∞ \\
  \end{align*}
  Dieses $μ$ ist Prämaß auf $\mathcal{A}$. Es gibt (mindestens) zwei Fortsetzungen:
  1. Zählmaß ist eine Fortsetzung
  2. $μ(A) = ∞ ∀ A \neq \emptyset$
  #+end_ex
  #+ATTR_LATEX: :options [äußeres Maß]
  #+begin_defn latex
  EIne Funktion $μ^{\ast}: \mathcal{P}(X) \to [0, ∞]$ ist ein äußeres Maß auf $X$, falls für alle $(A_k)_{k ∈ ℕ} ⊂ \mathcal{P}(X)$ die folgenden Eigenschaften erfüllt sind:
  1. $μ^{\ast}(\emptyset) = 0$
  2. $μ^{\ast}(A_1) \leq μ^{\ast}(A_2)$, falls $A_1 ⊂ A_2$ \hfill (Monotonie)
  3. $\displaystyle{μ^{\ast}(\bigcup_{k ∈ ℕ} A_k) \leq \sum_{k ∈ ℕ} μ^{\ast}(A_k)}$ \hfill (\(σ\)-Subadditivität)
  #+end_defn
  #+begin_thm latex
  Sei $μ^{\ast}$ ein äußeres Maß auf eine Menge $X$. Wir sagen, die Menge $A ⊂ X$ erfüllt die Caratheodory-Bedingung (CB) falls
  \[μ^{\ast}(E) = μ^{\ast}(E ∩ A) + μ^{\ast}(E ∩ A^C) ∀ E ⊂ X\]
  Die Familie $Σ$ aller Mengen, die die Caratheodory-Bedingung erfüllen bildet eine \(σ\)-Algebra und $μ^{\ast}|_Σ$ ist ein Maß.
  #+end_thm
  #+begin_proof latex
  Wir zeigen zunächst, dass $Σ$ eine Algebra ist. Offenbar $X ∈ Σ$. Abgeschlossen unter Komplementbildung ist klar. Für endliche Vereinigungen wähle $A, B ∈ Σ$. Sei $E ⊂ X$ beliebig.
  \begin{align*}
  μ^{\ast}((A ∪ B) ∩ E) &\leq μ^{\ast}(A ∩ B^C ∩ E) + μ^{\ast}(A^C ∩ B ∩ E) + μ^{\ast}(A ∩ B ∩ E) \\
  \intertext{Nun wird die Caratheodory-Bedingung zweimal angewandt}
  μ^{\ast}(E) &= μ^{\ast}(E ∩ A) + μ^{\ast}(E ∩ A^C) \\
  &= μ^{\ast}(E ∩ A ∩ B) + μ^{\ast}(E ∩ A ∩ B^C) + μ^{\ast}(E ∩ A^C ∩ B) + μ^{\ast}(E ∩ A^C ∩ B^C) \\
  \intertext{Mit obiger Abschätzung erhalten wir}
  μ^{\ast}(E) &\geq μ^{\ast}((A ∪ B) ∩ E) + μ^{\ast}(E ∩ A^C ∩ B^C) = μ^{\ast}((A ∪ B) ∩ E) + μ^{\ast}((A ∪ B)^C ∩ E) \\
  \end{align*}
  Die andere Richtung folgt aus der \(σ\)-Subadditivität \\
  Sei nun also $(A_k)_{k ∈ ℕ} ⊂ Σ$. Wir können ohne Beschränkung der Allgemeinheit annehmen, dass die $A_k$ paarweise disjunkt sind. Nun ist für jedes $E ⊂ X$ und
  \begin{align*}
  B_k &= \bigcup_{j = 1}^k A_k ∈ Σ,\qquad B_k \nearrow \bigcup_{k ∈ ℕ} A_k \\
  μ^{\ast}(B_k ∪ E) &= μ^{\ast}(B_k ∩ E ∩ A_k) + μ^{\ast}(B_k ∩ E ∩ A_k^C) \\
  &= \sum_{j = 1}^{k} μ^{\ast}(E ∩ A_j) \\
  \intertext{Also haben wir}
  μ^{\ast}(E) &= μ^{\ast}(E ∩ B_k) + μ^{\ast}(E ∩ B_k^C) \\
  \intertext{Mit $k \to ∞$ erhält man}
  μ^{\ast}(E) &\geq \sum_{k ∈ ℕ} μ^{\ast}(E ∩ A_k) + μ^{\ast}(E ∩ A^C) \geq μ^{\ast}(\bigcup_{k ∈ ℕ} (A_k ∩ E) + μ^{\ast}(E ∩ A^C)) \\
  & \geq μ^{\ast}(E) \\
  \intertext{Also gilt}
  A &= \bigcup_{k ∈ ℕ} A_k ∈ Σ
  \end{align*}
  Damit $μ^{\ast}|_{Σ}$ ein Maß ist, betrachte Folge $(A_k)_{k ∈ ℕ}$ paarweise disjunkt. Da $Σ$
  eine \(σ\)-Algebra ist wähle in der Caratheodory-Bedingung $E = A = \bigcup_{k ∈ ℕ}A_k$.
  \begin{align*}
  μ^{\ast}(E) = μ^{\ast}(A) = \sum_{k ∈ ℕ} μ^{\ast}(A ∩ A_k) + μ^{\ast}(A ∩ A^C) = \sum_{k ∈ ℕ} μ^{\ast}(A_k)
  \end{align*}
  $μ^{\ast}(\emptyset) = 0$ gilt nach Definition des äußeren Maßes.
  #+end_proof
  #+begin_remark latex
  Das soeben konstruierte Maß $μ^{\ast}\mid_{Σ}$ ist vollständig, jede Teilmenge einer Nullmenge ist messbar.
  #+end_remark
  #+begin_proof latex
  Sei $A ∈ Σ$, $μ^{\ast}(A) = 0$ und $B ⊂ A$. Es gilt für $E = X$ in der Caratheodory-Bedingung
  \[μ^{\ast}(E ∩ B) \leq μ^{\ast}(A) + μ^{\ast}(E ∩ B^C) \leq μ^{\ast}(E)\]
  Insofern ist $B ∈ Σ$
  #+end_proof
  *Fahrplan für das Lebesgue-Maß* \\
  Für ein verallgemeinertes Intervall $I$ der Form $(a, b), \string(a,b], [a,b\string), [a, b]$ mit $-∞ \leq a \leq b \leq ∞$ setzen wir $λ(I) := b - a ∈ [0, ∞]$
  \begingroup
  \def\thedefn{1.31}
  #+begin_lemma latex
  Dies ergibt ein eindeutiges \(σ\)-finites Prämaß auf der Algebra $\mathcal{A}$, die aus endliches Vereinigungen disjunkter Intervalle besteßt
  \[λ(\bigcup_{j = 1}^k I_j) = \sum_{j = 1}^{k} λ(I_j)\]
  #+end_lemma
  Wir erhalten zunechst eine Fortsetzung von $λ$ zu einem äußeren Maß $λ^{\ast}$, also $λ = λ^{\ast}$ auf $\mathcal{A}$, wobei jede Menge aus $\mathcal{A}$ die Caratheodory-Bedingung erfüllt.
  Satz 1.27 liefert eine \(σ\)-Algebra $Λ \supset \mathcal{A}$, sodass $λ := λ^{\ast}\mid_Λ$ ein Maß ist
  \def\thedefn{1.32}
  #+begin_defn latex
  Die Elemente von $Λ$ nennt man Lebesque-messbare Mengen und $λ$ das Lebesque-Maß.
  #+end_defn
  \endgroup
  \begingroup

  #+begin_lemma latex
  Sei $μ$ ein Prämaß auf einer Algebra $\mathcal{A} ⊂ \mathcal{P}(X)$. Wir setzen für $A ⊂ X$
  \[μ^{\ast}(A) = \inf \{\sum_{k ∈ ℕ} μ(A_k) \mid (A_k)_{k ∈ ℕ} ⊂ \mathcal{A}, A ⊂ \bigcup_{k ∈ ℕ} A_k\}\]
  Dies ist ein äußeres Maß mit $μ^{\ast} = μ$ auf $\mathcal{A}$	und jede Menge aus $\mathcal{A}$ erfüllt die Caratheodory-Bedingung.
  #+end_lemma
  #+ATTR_LATEX: :options [Caratheodory-Eigenschaft]
  #+begin_proof latex
  Sei $E ⊂ X$ und $A ⊂ \mathcal{A}$. Zu zeigen:
  \[μ^{\ast}(E) = μ^{\ast}(E ∩ A^C) + μ^{\ast}(E ∩ A)\]
  "$\leq$" folgt aus Subadditivität. Noch zu zeigen: $\geq$. Wir betrachten eine beliebige Überdeckung von $E$ durch $(B_k)_{k ∈ ℕ} ⊂ \mathcal{A}, B := \bigcup_{k ∈ ℕ} B_k \supset E$.
  Dann ist zunächst auch $(B_k ∩ A)_{k ∈ ℕ}$ eine Überdeckung von $E ∩ A$ und entsprechend $(B_k ∩ A^C)_{k ∈ ℕ}$ von $E ∩ A^C$. Wir erhalten
  \begin{align*}
  \sum_{k ∈ ℕ} μ(B_k) &= \sum_{k ∈ ℕ} μ(B_k ∩ A) + \sum_{k ∈ ℕ} μ(B_k ∩ A^C) \\
  &\geq μ^{\ast}(E ∩ A) + μ^{\ast}(E ∩ A^C)
  \end{align*}
  Infimum über $(B_k)_{k ∈ ℕ}$ mit $\bigcup_{k ∈ ℕ} \supset E$ liefert
  \[μ(E^{\ast}) \geq μ^{\ast}(E ∩ A) + μ^{\ast}(E ∩ A^C)\]
  #+end_proof
  #+ATTR_LATEX: :options [von Lemma 1.31]
  #+begin_proof latex
  - $\mathcal{A}$ ist Algebra ($ℝ = (-∞, ∞)$, das Komplement einer endlichen Vereinigung disjunkter Intervalle besitzt wieder diese Form)
  -	Offenbar gilt $λ(\emptyset) = 0$
  zu zeigen (für \(σ\)-Algebra): für alle paarweise disjunkten Folgen $(I_k)_{k ∈ ℕ} ⊂ \mathcal{A}$
  \begin{align*}
  λ(\bigcup_{k ∈ ℕ} I_k) &= \sum_{k ∈ ℕ} λ(I_k) \\
  \intertext{Wir bekommen}
  \sum_{j= 1}^{k} λ(I_j) \underarrow[=]{Additivität} λ(\bigcup_{j = 1}^k I_j) \overarrow[\leq]{Monotonie} λ(\bigcup_{j = 1}^∞ I_j) = λ(I) \\
  \end{align*}
  "$\geq$": wür wählen $∀ k ∈ ℕ$ ein offenes $J_k \supset I_k$ mit
  \[λ(J_k) \leq λ(I_k) + \frac{ε}{2^k}\qquad \text{für ein } ε > 0\]
  Sei zunächst $I$ kompakt. Dann können wir endlich viele $J_k$ auswählen, sodass diese $I$ überdecken. Wir nehmen an, dass dies die ersten $K$ Elemente sind (Umnummerierung). Es
  gilt
  \[λ(I) \overarrow[=]{Monotonie} λ(\bigcup_{j = 1}^k J_j) \leq	\underarrow[=]{Subadditivität} \sum_{j = 1}^{k} λ(J_j) \overarrow[\leq]{aus Konstruktion} \sum_{j = 1}^{k} λ(I) + ε\]
  Mit $ε \searrow 0$ folgt \(σ\)-Additivität für kompakte $I$. Die Behauptung folgt auch für beschränkte $I$ (weil mit Additivität und $λ(\{x\}) = λ([x, x]) = 0 ∀ x ∈ ℝ$ können wir
  die Endpunkte an Intervalle hinzufügen oder entfernen).
  Sei $I$ ein unbeschränkts Intervall $λ(I) = ∞$. Zu zeigen
  \[\sum_{j = 1}^{∞} λ(I_j) = ∞\]
  Sei $ξ ∈ I, I ∩ [ξ - x, ξ + x]$ kompakt. $∀ x ∈ ℝ$ und von den ersten $K$ Elementen überdeckt. $K = K(ξ)$. Wir bekommen
  \begin{align*}
  \sum_{j = 1}^{∞} λ(I_j) &\geq \sum_{j = 1}^{k} λ(I_j) \underarrow[\geq]{Konstruktion} \sum_{j = 1}^{k} λ(J_i) - ε \\
  &\geq λ(I ∩ [ξ - x, ξ + x]) - ε \geq	x - \abs{ξ} - ε \\
  ⇒ \sum_{j = 1}^{∞} λ(I_j) &\geq x - \abs{ξ} - ε \xrightarrow{x \to ∞} ∞
  \end{align*}
  #+end_proof
** Messbare Funktionen
  #+begin_defn latex
  Seien $(X, Σ_X), (Y, Σ_Y)$, $f: X \to Y$ heißt *messbar* ($Σ_X - Σ_Y$ messbar) falls
  \[∀ A ∈ Σ_Y f^{-1}(A) ∈ Σ_X\]
  Ist $X$ ein topologischer Raum und $Σ_X$ die entsprechende Borel-\(σ\)-Algebra so nennen wir eine messbare Funktion die Borel-Funktion.
  #+end_defn
  #+begin_remark latex
  Es genügt, Messbarkeit für ein Messsystem $S ⊂ \mathcal{P}(Y)$ mit $Σ(S) = Σ_Y$ zu überprüfen. In der Tat ist $f^{-1}(A) ∈ Σ_X ∀ A ∈ S$ so folgt
  \begin{align*}
  f^{-1}(A^C) &= f^{-1}(Y \setminus A) = X \setminus f^{-1}(A) = (f^{-1}(A))^C ∈ Σ_x \\
  \intertext{weiter ist}
  f^{-1}(\bigcup_{k ∈ ℕ} A_k) &= \bigcup_{k ∈ ℕ} f^{-1}(A_k) ∈ Σ_x
  \end{align*}
  #+end_remark
  Wir werden häufig nutzen $(Y, Σ) = (ℝ^n, \mathcal{B}^n)$
  #+begin_lemma latex
  $f: (X, Σ) \to (ℝ^n, \mathcal{B}^n)$ ist genau dann messbar, wenn
  \[f^{-1}(I) ∈ Σ ∀ I = \bigtimes_{j = 1}^n (a_j, ∞), a_j ∈ ℝ\]
  insbesondere ist $f$ genau dann messbar, wenn jede seiner Komponenten $x \to \angl{f(x), e_i}, i = 1, \dots, n$ messbar ist
  und eine komplexwertige Funktion ist messbar genau dann wenn Real- und Imaginärteil messbar sind.
  #+end_lemma
  #+begin_proof latex
  Die \(σ\)-Algebra die von den verallgemeinerten Quadern erzeugt wird enthält die Quader der Form
  \[\bigtimes_{j = 1}^n (a_j, b_j)\]
  Diese bilden eine	Basis für die Topologie $⇒$ führen auf $\mathcal{B}^n$.
  #+end_proof
  #+begin_lemma latex
  Seien $(X, Σ_X), (Y, Σ_Y), (Z,Σ_Z)$ Messräume. Sind $f: X \to Y, g: Y \to Z$ messbar , dann ist auch $g \circ f: X \to Z$ messbar.
  Sind $X, Y$ topologische Räume, $Σ_X, Σ_Y$ \(\mathcal{B}\)-\(\mathcal{σ}\)-Algebren so ist jede stetige Funktion $f: X \to Y$ messbar.
  #+end_lemma
  #+begin_proof latex
  Das Urbild offener Mengen (diese erzeugen \(\mathcal{B}\)-\(σ\)-Algebra $Σ_Y$) ist aufgrund der stetigkeit offen, also messbar.
  Ist $C ∈ Σ_Z$ messbar, so ist es auch $B := g^{-1}(C) ∈ Σ_y$ und $A := f^{-1}(B) ∈ Σ_x$
  #+end_proof
  #+ATTR_LATEX: :options [1.36]
  #+begin_lemma latex
  Sind $f, g: (X, Σ) \to (ℝ, \mathcal{B})$ messbar, so auch $f + g, f - g$.
  #+end_lemma
  #+begin_proof latex
  Aus Stetigkeit von Addition und Subtraktion auf $(ℝ, \mathcal{B}) × (ℝ, \mathcal{B}) \to (ℝ, \mathcal{B})$ und Lemma 1.36.
  #+end_proof
  #+begin_remark latex
  Für $\bar ℝ := ℝ ∪ \{-∞, ∞\}$ ist $f: X \to \bar ℝ$ eine Borel-Funktion, wenn $f^{-1}(\{-∞;∞\})$ beiden Borel-Mengen sind und $f\big|_{X \setminus f^{-1}(\{\pm ∞\})}$ eine Borel-Funktion.
  #+end_remark
  #+ATTR_LATEX: :options [1.40]
  #+begin_lemma latex
  Sei $(f_k)$ eine Folge messbarer Funktionen $(X, \bar Z) \to (\bar ℝ, \bar{\mathcal{B}})$. Dann sind auch
  \[\sup_{k ∈ ℕ} f_k, \inf_{k ∈ ℕ} f_k, \limsup_{k \to ∞} f_k, \liminf_{k \to ∞} f_k\]
  messbar.
  #+end_lemma
** Integration
   #+begin_defn latex
   Eine messbare Funktion $f:(X, Σ) \to (ℝ, \mathcal{B})$ heißt *einfach*, wenn ihr Bild endlich ist, das heiß $∃ A_1, \dots, A_m ∈ Σ, α_1, \dots, α_m ∈ ℝ$ mit
   \[f = \sum_{j = 1}^{m} α_j χ_{A_j}\]
   wobei $χ_M$ die charakteristische Funktion ist.
   \[χ_M(x) = \begin{cases} 1 & x ∈ M \\ 0 & x \not ∈ M\end{cases}\]
   Wir können fordern, dass $A_j$ paarweise disjunkt	sind, $α_i \neq α_j, i \neq j$ und $\bigcup A_j = X$ gilt.
   \[⇒ f(x) = \{α_1, \dots, α_m\}, \qquad f^{-1}(\{α_j\})= A_j\quad ∀ j = 1, \dots, m\]
   und diese Darstellung ist eindeutig.	\\
   Den Vektorraum einfacher Funktionen bezeichnen wir mit $S(X,μ)$
   #+end_defn
   #+ATTR_LATEX: :options [Integral auf $S(X,μ)$]
   #+begin_defn latex
   Das Integral	einer nicht negativen einfachen	Funktion über die Menge $A ∈ Σ$ wird durch
   \[∫_A f \d μ := \sum_{j= 1}^{n} α_j μ(A_j ∩ A)\]
   erklärt, wobei wir $0 · ∞ = 0$ vereinbaren.
   #+end_defn
   #+begin_lemma latex
   Das Integral hat die folgenden Eigenschaften
   \begin{alignat*}{2}
   &1. \qquad ∫_A f \d ψ &&= ∫_X χ_A f \d μ \qquad \text{für } f ∈ S(X, μ) \\
   &2. \qquad ∫_{\bigcup_{k ∈ ℕ} B_k} f\d μ &&= \sum_{k ∈ ℕ} ∫_{B_k} f \d μ \qquad B_k \text{ paarweise disjunkt}, (B_k)_{k ∈ ℕ} ∈ Σ \\
   &3. \qquad ∫_A α f \d μ &&= α ∫_A f \d μ \qquad \text{für } α \geq 0 \\
   &4. \qquad ∫_A (f + g) \d μ &&= ∫_A f \d μ + ∫_A g \d μ \qquad \text{für } g \geq S(X,μ) \\
   &5. \qquad A ⊂ B, B ∈ Σ ⇒ ∫_A f \d μ &&\leq ∫_B f \d μ \\
   &6. \qquad f \leq g ⇒ ∫_A f \d μ &&\leq ∫_A g \d μ, g ∈ S(Σ,μ), g \geq 0
   \end{alignat*}
   #+end_lemma
   #+begin_proof latex
   1. aus Definition
   2. $\displaystyle{μ(A_j ∩ \bigcup_{n ∈ ℕ} B_n) = \sum_{k ∈ ℕ} μ(A_j ∩ B_k)}$ (man darf die Reihe über nichtnegative Zahlen umsortieren)
   3. klar
   4. Für
      \begin{align*}
	  f &= \sum_{j = 1}^{n} α_j χ_{A_j} \\
      g &= \sum_{k = 1}^{n} β_k χ_{B_k} \\
	  \intertext{gilt mit $C_{jk} = A_j ∩ B_k$}
	  ∫_A (f + g) \d μ &= \sum_{j,k} ∫_{C_{jk}} (f + g) \d μ = \sum_{j,k} (α_j + β_k) μ(C_{jk}) \\
	  &= \sum_{j,k} α_j μ(C_{jk}) + \sum_{j,k} β_k μ(C_{jk}) = ∫_A f\d μ + ∫_A g \d μ
      \end{align*}
   5. Aus Monotonie von $μ$
   6. Wie in 4. mit
	  \[∫_A f \d μ = \sum_{j,k} α_j μ(C_{jk}) \leq \sum_{j,k} β_k μ(C_{jk}) = ∫_A g \d μ\]
   #+end_proof
   #+ATTR_LATEX: :options [Integral  von nichtnegativen Funktionen]
   #+begin_defn latex
   Sei $(X, Σ, μ)$ Maßraum, $A ∈ Σ, f:(X,Σ) \to (ℝ, \mathcal{B})$ messbar und nichtnegtiv. Dann ist
   \[∫_A f \d μ := \sup \{∫_a g \d μ \mid g ∈ S(X, μ), g \leq f, g \geq 0\}\]
   #+end_defn
   #+begin_remark latex
   Bis auf 2. und 4. übertragen sich die Eigenschaften des Integrals über einfache Funktionen.
   #+end_remark
   #+ATTR_LATEX: :options [Monotone Konvergenz / Beppo Levi]
   #+begin_thm latex
   Sei $(f_k)_{k ∈ ℕ}$ eine Folge messbarer nichtnegativer Funktionen
   \[f_k:(X, Σ) \to (ℝ, \mathcal{B}) \quad\text{mit}\quad f_k \nearrow f\]
   ($f_k \nearrow f ⇒ f_k \xrightarrow{k \to ∞} f$ punktweise und (implizit aus Nichtnegativität) $\sum_{k = 1}^n f_k$ monoton) \\
   Dann ist für $A ∈ Σ$
   \[∫_A f_k \d μ \to ∫_A f \d μ\]
   #+end_thm
   #+begin_proof latex
   $f$ messbar,	damit erhält man die Monotonie von
   \[∫_A f_k \d μ\]
   und hieraus Konvergenz gegen $φ ∈ [0, ∞]$. Aus $f_k \leq f$ und Monotonie den Integral:
   \[φ \leq ∫_A f \dμ\]
   Für "\(\geq\)" nehmen wir $g ∈ S(X, μ), g \geq 0, g \leq f$ mit
   \[A_k := \{x ∈ A \mid f_k(x) \geq θ · g(x)\}\]
   für ein festes $θ ∈ (0,1)$ und hierraus
   \begin{align*}
   φ \xleftarrow{k \to ∞} ∫_A f_k \d μ &\geq ∫_{A_k} f_k \d μ \geq ∫_A θ g \d μ \\
   &\geq θ ∫_{A_k} g \d μ \to θ ∫_A g \d μ
   \end{align*}
   Insbesondere gilt für $θ = 1$
   \begin{align*}
   ⇒ φ &\geq ∫_A g \d μ \\
   ⇒ φ &= ∫_A f \d μ
   \end{align*}
   #+end_proof
   #+begin_remark latex
   $∀ f \geq 0$, mit einer monoton steigenden Folge nicht negativer einfacher Funktionen $(g_k)_{k ∈ ℕ}, g_k \nearrow f$ ist
   \[∫_A g_k \d μ \nearrow ∫_A f \d μ\]
   Eine geeignete Funktion ist
   \begin{align*}
   g_k(x) &:= \sum_{j = 0}^{k 2^k} \frac{j}{2^k} χ_{f^{-1}(A_j)}(x)
   \intertext{mit}
   A_j &= \{[\frac{j}{2^k}, \frac{j + 1}{2^k}\string) \mid j = 0, \dots, k 2^k - 1\}
   \end{align*}
   Ist $f$ gleichmäßig beschränkt $⇒$ $(g_k)_{k ∈ ℕ}$ konvergiert gleichmäcßig (denn $0 \leq f - g_k \leq \frac{1}{2^k}$ für $k$ groß genug)
   Mit Satz von Beppo Levi erhält man somit
   \begin{align*}
   2. \qquad ∫_{\bigcup_{k ∈ ℕ} B_k} f\d μ &= \sum_{k ∈ ℕ} ∫_{B_k} f \d μ \qquad B_k \text{ paarweise disjunkt}, (B_k)_{k ∈ ℕ} ∈ Σ \\
   4. \qquad ∫_A (f + g) \d μ &= ∫_A f \d μ + ∫_A g \d μ \qquad \text{für } g \geq S(X,μ) \\
   \end{align*}
   #+end_remark
   #+begin_lemma latex
   Ist $f \geq 0$ messbar, so wird durch
   \[ν(A) := ∫ f \d μ\]
   ein Maß mit
   \[∫ d \d ν = ∫ g f \d μ\]
   für jedes messbare $g \geq 0$ definiert (Bezeichnung: $\d ν = f \d μ$)
   #+end_lemma
   #+begin_proof latex
   \begin{align*}
   ν(\emptyset) &= ∫_{\emptyset} f \d μ = ∫ χ_{\emptyset} f \d μ = 0 · ∫ f \d μ = 0 \\
   ν(A ∪ B) &= ∫_{A ∪ B} f \d μ = ∫_A f \d μ + ∫_B \d μ = ν(A) + ν(B) \quad\text{für } A ∩ B = \emptyset \\
   \intertext{Für abzählbare Vereinigungen äquivalent}
   ν(\bigdcup_{k ∈ ℕ} A_k) &= \sum_{k ∈ ℕ} ν(A_k) \\
   \end{align*}
   Ist $g$ einfach und $\geq 0$
   \[⇒ g = \sum_{i = 1}^{n} α_j χ_{B_j}\]
   für disjunkte $B_j ∈ Σ, \bigcup B_j = X, α_j \geq 0$
   \begin{align*}
   ∫ g \d ν &= \sum_{j = 1}^{n} α_j ν(A_j) = \sum_{j = 1}^{n} α_j ∫_{B_j} f \d μ = \sum_{j = 1}^{n} ∫ α_j f χ_{B_j} \d μ \\
   &= ∫ \sum_{j = 1}^{n} \underbrace{(α_j χ_{B_j})}_{= g} f \d μ = ∫ g f \d μ
   \end{align*}
   Appoximation liefert die Behauptung für beliebigte $g \geq 0$.
   #+end_proof
   #+ATTR_LATEX: :options [Fatou Lemma]
   #+begin_thm latex
   Sei $(X, Σ, μ)$ ein Maßraum. Ist $f_k$ eine Folge nicht-negativer Funktionen $(X, Σ) \to (ℝ, \mathcal{B})$ so gilt $∀ A ∈ Σ$
   \begin{align*}
   ∫_A \liminf_{k \to ∞} f_k \d μ &\leq \liminf_{k \to ∞} ∫_A f_k \d μ
   \end{align*}
   #+end_thm
   #+begin_proof latex
   Wir setzen $g_k := \inf_{j \geq k} f_j$, also
   \[g_k \nearrow \liminf_{j \to ∞} f_j\]
   Weiterhin $g_k \leq f_k ∀ k ∈ ℕ$
   \[⇒ ∫_A g_k \d μ \leq ∫_A f_k \d μ\]
   Übergang zum $\liminf$
   \begin{align*}
   ⇒ \liminf ∫ g_k \d μ &= \lim_{k \to ∞} ∫ g_k \d μ = ∫_A \lim_{k \to ∞} g_k \d μ \\
   &= ∫_A \liminf_{k \to ∞} f_k \d μ
   \end{align*}
   #+end_proof
   #+begin_remark latex
   Im Allgemeinen können wir keine Gleichheit erwarten. Zum Beispiel ist für $f_x := χ_{(k,k + 1)}, k ∈ ℕ$ einerseits $f_k(x) \to 0$ punktweise,
   andererseits
   \[∫_ℝ f_k \d x = 1, f_k = k χ_{(0,\frac{1}{k})} \text{ und } f_k = \frac{1}{k} χ_{(0,k)}\]
   #+end_remark
   #+begin_defn latex
   Sei $(X, Σ, μ)$ ein Maßraum, $A ∈ Σ$ und $f:(X, Σ) \to (ℝ, \mathcal{B})$ messbar. Ist
   \[∫_A f^{\pm} \d μ < ∞\]
   so nennen wir $f$ integrierbar über $A$ und wir setzen
   \[∫A f \d μ = ∫_A f^{+} \d μ - ∫_A f^{-} \d μ ∈ ℝ\]
   Die Menge der über $A$ integrierbaren Funktionen bezeichnen wir mit $\mathcal{L}^1(A,μ)$
   #+end_defn
   #+begin_lemma latex
   Unter den Bedingungen der Defininiton ist das Integral linear und es erfüllt sämtlich Eigenschaften von Lemma 1.39.
   Eine	Funktion ist genau dann integrierbar, wenn ihr Betrag integrierbar ist. Darüber hinaus gilt für integrierbare Funktionen $f,g: X \to ℝ$
   \[\abs{∫_A f \d μ} \leq ∫_A \abs{f} \d μ \quad\text{und}\quad ∫_A \abs{f + g} \d μ \leq ∫_A \abs{f} \d μ + ∫_A \abs{g} \d μ\]
   #+end_lemma
   #+begin_proof latex
   Die Linearität und die Eigenschaften aus dem Lemma 1.39 wird dem geneigten Leser überlassen. Setze $φ := ∫_A f \d μ$, dann ist
   \[\abs{φ} = (\sgn φ) φ = ∫_A (\sgn φ) f \d μ \leq ∫_A \abs{f} \d μ\]
   Die Dreiecksungleichung folgt aus $\abs{f + g} \leq \abs{f} + \abs{g}$ und der Linearität des Integrals.
   #+end_proof
   #+begin_lemma latex
   Sei $(X, Σ, μ)$ ein Maßraum, $f: X \to ℝ$ messbar.
   1. $∫_X \abs{f} \d μ = 0 ⇔ f(x) = 0$ für \(μ\)-fast alle $x ∈ X$
   2. Ist $f$ außerdem integrierbar oder nicht negativ  und $A ∈ Σ$ so gilt
	  \[μ(A) = 0 ⇒ ∫_A f \d μ = 0\]
   #+end_lemma
   #+begin_proof latex
   Übungen.
   #+end_proof
   #+begin_lemma latex
   Sei $(X, Σ, μ)$ ein Maßraum, $A ∈ Σ, (f_k)_{k ∈ ℕ}$ eine Folge aus messbaren Funktionen mit $f_k: X \to ℝ ∀ k ∈ ℕ$ und $g: X \to ℝ$ integrierbar, dann gilt
   \begin{align*}
   ∫_A \liminf_{k \to ∞} f_k \d μ &\leq \liminf_{k ∈ ∞} ∫_A f_k \d μ \quad\text{falls } g \leq f_k ∀ k ∈ ℕ \\
   \limsup_{k \to ∞} f_k \d μ &\leq ∫_A \limsup_{k ∈ ∞} f_k \d μ \quad\text{falls } f_k \leq g ∀ k ∈ ℕ \\
   \end{align*}
   #+end_lemma
   #+begin_proof latex
   Man wende für die erste Ungleichung das Fatou-Lemma auf $f_k - g$ an und subtrahiere $∫_A g \d μ$ auf beiden Seiten. Die zweite Ungleichung folgt mit $\liminf(-f_k) = - \limsup f_k$.
   #+end_proof
   #+ATTR_LATEX: :options [Satz von der dominierten Konvergenz]
   #+begin_thm latex
   Sie $(X, Σ, μ)$ ein Maßraum, $A ∈ Σ, (f_k)$ ein Folge messbarer Funktionen von $X$ nach $ℝ$, die punktweise fast überall gegen ein $f: X \to ℝ$ konvergiere.
   (Punktweise fast überall bedeutet: $f_k(x) \to f(x)$ für \(μ\)-fast alle von $X$).
   Gibt es eine Majorante, dah heißt eine integrierbare Funktion $g: X \to ℝ$ mit $\sup_{k ∈ ℕ} \abs{f_k} \leq g$ so ist auch $f$ integrierbar und wir erhalten
   \[∫_A f_k \d μ \xrightarrow{k \to ∞} ∫_A f \d μ\]
   #+end_thm
   #+begin_proof latex
   Nach Vorraussetzung ist $-g \leq f_k \leq g$ für alle $k ∈ ℕ$ und folglich erhalten wir mit dem erweiterten Fatou-Lemma
   \[∫_A f = ∫A \liminf_{k \to ∞} f_k \d μ \leq \liminf_{k \to ∞} ∫_a f_k \d μ \leq \limsup_{k \to ∞} ∫_A f_k \leq ∫_A \limsup_{k \to ∞} f_k \d μ = ∫_A f \d μ\]
   #+end_proof
   #+begin_remark latex
   Für stetige und Lebesgue-integrierbare Funktionen auf reellen Intervallen stimmen Riemann- und Lebesgue-Integrierbarkeit überein. Ist $f$ stetig auf einem kompakten Intervall, so ist $f$
   beschränkt und messbar, also Lebesgue-Integrierbar. \\
   Allgemeiner ist jede beschränkte, messbare Funktion auf einem kompakten Intervall genau dann Riemann-integrierar, wenn die Menge ihrer Unstetigkeiten eine Lebesgue-Nullmenge ist.
   In diesem Fall stimmen die beiden Integralbegriffe überein. Diese Aussage gilt nicht für verallgemeinerte Intervalle.
   #+end_remark
   #+begin_ex latex
   \[∫_0^∞ \frac{\sin(x)}{x}\d x\]
   existiert als Riemann-Integral
   \[\lim_{R \to ∞} ∫_0^R \frac{\sin(x)}{x} \d x\]
   andererseits
   \[∫_0^∞ \abs{\frac{\sin(x)}{x}} \d x = ∞\]
   also keine Lebesgue-Integrierbarkeit.
   #+end_ex
** Produktmaße
   Notation: Für Messräume $(X_1, Σ_1),(X_2,Σ_2)$ bezeichnen wir die \(σ\)-Algebra, die alle "Rechtecke" der $A_1 × A_2$ mit $A_1 ∈ Σ_1, A_2 ∈ Σ_2$ enthält mit $Σ_1 \otimes Σ_2$.
   #+begin_lemma latex
   Für Messräume $(X_1, Σ_1), (X_1, Σ_2)$ und $A ∈ Σ_1 \otimes Σ_2$ liegen die Schnitte
   \begin{align*}
   A_1(x_2) &:= \{x_1 ∈ X_1 \mid (x_1, x_2) ∈ A\} \\
   A_2(x_1) &:= \{x_2 ∈ X_2 \mid (x_1, x_2) ∈ A\}
   \end{align*}
   in $Σ_1$	beziehungsweise $Σ_2$
   #+end_lemma
   #+begin_proof latex
   Setze $S := \{A ∈ Σ_1 \otimes Σ_2 \mid A_1(x_2) ∈ Σ_1\}$. Natürlich gilt $A_1 × A_2 ∈ S$ für
   alle $A_1 ∈ Σ_1, A_2 ∈ Σ_2$. Isofern genügt es zu zeigen, dass $S$ eine \(σ\)-Algebra bildet. In der Tat ist $X_1 × X_2 ∈ S$ und für $A ∈ S$ ist
   \[(A^C)_1 (x_2) = \{x_1 ∈ X_1 \mid (x_1, x_2) ∈ A^C\} = \{x_1 ∈ X_1 \mid (x_1, x_2) ∈ A\}^C = (A_1(x_2))^C ∈ Σ_1\]
   Für $(A_k)_{k ∈ ℕ} ⊂ S$ haben wir
   \[(\bigcup_{k ∈ ℕ} A_k)_1 (x_2) = \{x_1 ∈ X_1 \mid (x_1, x_2) ∈ \bigcup_{k ∈ ℕ} A_k\} = \bigcup_{k ∈ ℕ} \{x_1 ∈ X_1 \mid (x_1, x_2) ∈ A_k\} = \bigcup_{k ∈ ℕ} (A_k)_1(x_2) ∈ Σ_1\]
   Für $A_2(x_1)$ argumentiert man analog.
   #+end_proof
   #+begin_korollar latex
   Seien $(X_1, Σ_2), (X_2, Σ_2)$ Messräume und sei $f:(X_1 × X_2, Σ_1 \otimes Σ_2) \to (ℝ, \mathcal{B})$ messbar. Dann ist auch $x_1 ↦ f(x_1, x_2)$ für jedes $x_2 ∈ X_2$ auf $X_1$ messbar und
   entsprechend $x_2 ↦ f(x_1, x_2)$ für jedes $x_1 ∈ X_1$ auf $X_2$
   #+end_korollar
   #+begin_proof latex
   Für $B ∈ \mathcal{B}$ und $x_2 ∈ X_2$ ist $f^{-1}(·,x_2)(B) ∈ Σ_1$, denn für $A = f^{-1}(B), A ∈ Σ_1 \otimes Σ_2$ ist
   \[f^{-1}(·,x_2)(B) = \{x_1 ∈ X_1 \mid f(x_1, x_2) ∈ B\} = \{x_1 ∈ X_1 \mid (x_1, x_2) ∈ A\} = A_1(x_2)\]
   #+end_proof
   Ziel: Definition Produktmaß $μ_1 \otimes μ_2$ auf $Σ_1 \otimes Σ_2$ mit
   \[(μ_1 \otimes μ_2)(A_1 × A_2) = μ_1(A_1) · μ_2(A_2) ∀ A_1 ∈ Σ_1, A_2 ∈ Σ_2\]
   #+begin_thm latex
   Sind $(X_1, Σ_1, μ_1), (X_2, Σ_2, μ_2)$ Maßräume mit \(σ\)-finiten Maßen und $A ∈ Σ_1 \otimes Σ_2$. Dann sind die Abbildungen
   \begin{align*}
   x_1 &↦ μ_2(A_2(x_1)) \\
   x_2 &↦ μ_2(A_1(x_2)) \\
   \end{align*}
   messbar und
   \[∫_{X_1} μ_2(A_2(x_1)) \d μ_1(x_1) = ∫_{X_2} μ_1(A_1(x_2)) \d μ_2(x_2)\]
   #+end_thm
   #+begin_proof latex
   ohne Beweis
   #+end_proof
   #+begin_defn latex
   Seien $(X_1, Σ_1, μ_1), (X_2, Σ_2, μ_2)$ Maßräume mit \(σ\)-finiten Maßen, für $A ∈ Σ_1 \otimes Σ_2$ setzen wir
   \[(μ_1 \otimes μ_2)(A) := ∫_{X_1} \underbrace{μ_2(A_2(x_1)) \d μ_1(x_1)}_{∫_{X_2} χ_A(x_1, x_2) \d μ_2(x_2)} = ∫_{X_2} \underbrace{μ_1(A_1(x_2)) \d μ_2(x_2)}_{∫_{X_1} χ_A(x_1, x_2) \d μ_1(x_1)}\]
   #+end_defn
   #+begin_proof latex
   \[χ_{A_1(x_2)}(x_1) = χ_A(x_1, x_2) = χ_{A_2(x_1)}(x_2)\]
   #+end_proof
   #+begin_lemma latex
   Das Produktmaß ist für \(σ\)-finite Maße ebenfalls ein Maß und es ist eindeutig bezüglich
   \[(μ_1 \otimes μ_2)(A_1 × A_2) = μ_1(A_1) · μ_2(A_2) ∀ A_1 ∈ Σ_1, A_2 ∈ Σ_2\]
   #+end_lemma
   #+begin_proof latex
   - Eindeutigkeit aus Satz 1.23
   - $(μ_1 \otimes μ_2)(\emptyset) = 0$ klar
   - \(σ\)-Additivität folgt aus dem Satz über monotone Konvergenz
   \begin{align*}
   \string(μ_1 \otimes μ_2\string)(\bigdcup_{k = 1}^τ A_k) &:= ∫_{X_1} μ_2((\bigdcup_{k = 1}^τ)_2(x_1)) \d μ_1(x_1) \\
   &= ∫_{X_1} μ_2(\bigdcup_{k = 1}^τ (A_k)_2(x_1)) \d μ_1(x_1) \\
   &= ∫_{X_1} \sum_{k = 1}^{τ} μ_2((A_k)_2(x_1)) \d μ_1(x_1) = \sum_{k = 1}^{τ} (μ_1 \otimes μ_2)(A_k)
   \end{align*}
   #+end_proof
   #+ATTR_LATEX: :options [Fubini]
   #+begin_thm latex
   Seien $(X_1, Σ_1, μ_1), (X_2, Σ_2, μ_2)$ Maßräume mit \(σ\)-finiten Maßen und $f:(X_1 × X_2, Σ_1 \otimes Σ_2) \to (ℝ, \mathcal{B})$ messbar.
   1. (Tonelli) Ist $f$ nicht-negativ, so sind
	  \begin{align*}
	  &∫_{X_2} f(·, x_2) \d μ_2(x_2) \\
	  \text{und } &∫_{X_1} f(x_1, ·) \d μ_1(x_1)
      \end{align*}
	  als Funktion auf $X_1$ beziehungsweise $X_2$ messbar und es gilt
	  \begin{align*}
	  ∫_{X_1 × X_2} f(x_1, x_2) \d (μ_1 \otimes μ_2) (x_1, x_2) &= ∫_{X_1} (∫_{X_2} f(x_1, x_2) \d μ_2(x_2)) \d μ_1(x_1) \\
	  &= ∫_{X_1}(∫_{X_1} f(x_1, x_2) \d μ_1(x_1)) \d μ_2(x_2)
      \end{align*}
   2. Allgemein ist $f ∈ \mathcal{L}(X_1 × X_2, μ_1 \otimes μ_2)$ äquivalent zu
	  \begin{align*}
	  ∫_{X_1} \abs{f(x_1, ·)} \d μ_1(x_1) & ∈ \mathcal{L}(X_2, μ_2) \\
	  ∫_{X_2} \abs{f(·, x_2)} \d μ_2(x_2) & ∈ \mathcal{L}(X_1, μ_1) \\
      \end{align*}
	  und 1. gilt.
   #+end_thm
   #+begin_proof latex
   Aufgrund deer Linearität bekommen wir für eine einfach Funktion
   \[f = \sum_{j = 1}^{k} α_j χ_{A_j}, α_j \geq 0, A_j ∈ Σ_1 \otimes Σ_2, A_i ∩ A_j = \emptyset, X = \bigcup_{j = 1}^k A_j\]
   \begin{align*}
   ∫_{X_2} f(·, x_2) \d μ_2(x_2) &= \sum_{j = 1}^{k} α_j μ_2((A_j)_2(·)) \\
   \intertext{Weiterhin,}
   ∫_{X_1 × X_2} f(x_1, x_2) \d (μ_1 \otimes μ_2)(x_1, x_2) &= \sum_{j = 1}^{k} α_j ∫_{X_1 × X_2} χ_{A_j} (x_1, x_2) \d (μ_1 \otimes μ_2)(x_1, x_2) \\
   &= \sum_{j = 1}^{k} α_j ∫_{X_1}(∫_{X_2} χ_{A_j}(x_1, x_2) \d μ_2(x_2)) \d μ_1(x_1) \\
   &= ∫_{X_1} (∫_{X_2} f(x_1, x_2) \d μ_2(x_2)) \d μ_1(x_1) \\
   \text{analog: } &= ∫_{X_2} ∫_{X_1} \dots
   \end{align*}
   Sei $(f_k)_{k ∈ ℕ} ⊂ S(X_1 × X_2, μ_1 \otimes μ_2)$ mit $0 \leq f_k \nearrow f$.
   \begin{align*}
   ⇒ ∫_{X_2} f_k(·, x_2) \d μ_2(x_2) &\leq ∫_{X_2} f(·,x_2) \d μ_2(x_2) ∀ k ∈ ℕ \\
   \text{und } \lim_{k \to ∞} ∫_{X_2} f_k(·, x_2) \d μ_2(x_2) &\underarrow[=]{Beppo-Levi} ∫_{X_2} f(·, x_2) \d μ_2(x_2)
   \end{align*}
   Wir erhalten auch
   \begin{align*}
   \lim_{k \to ∞}  ∫_{X_1} ∫_{X_2} f_k(x_1, x_2) \d μ_2(x_2) \d μ_1(x_1) = ∫_{X_1} ∫_{X_2} f(x_1, x_2) \d μ_2(x_2) \d μ_1(x_1) \\
   \intertext{Genauso mit $1$ und $2$ vertauscht, auch}
   \lim_{k \to ∞} ∫_{X_1 × X_2} f_k(x_1, x_2) \d (μ_1 \otimes μ_2)(x_1, x_2) = ∫_{X_1 × X_2} f(x_1, x_2) \d (μ_1 \otimes μ_2)(x_1, x_2)
   \end{align*}
   Man erhält 2. aus 1. mit $f = f^{+}  - f^{-}$ und $\abs{f} = f^{+} + f^{-}$.
   \[f ∈ \mathcal{L}^1 (X_1 × X_2) ⇔ ∫_{X_1 × X_2} \abs{f} \d (μ_1 \otimes μ_2) (x_1, x_2) < ∞\]
   #+end_proof
   #+begin_ex latex
   \[X = ℝ^2, Σ = \mathcal{B}^2, f(x, y) = \frac{x - y}{(x + y)^3}\]
   Wir betrachten das Riemann-Integral
   \[∫_0^1 ∫_0^1 f(x, y) \d x \d y\]
   Dazu
   \begin{align*}
   \dd{}{x}(\frac{x}{(x + y)^2}) &= \frac{1}{(x + y)^2} - 2 \frac{x}{(x + y)^3} = \frac{x - y}{(x + y)^3} \\
   ⇒ ∫_0^1 ∫_0^1 f(x, y) \d x \d y &= ∫_0^1 \frac{1}{(1 + y)^2} \d y = - \frac{1}{2} \\
   \intertext{aber}
   ∫_0^1 ∫_0^1 f(x, y) \d y \d x = \frac{1}{2}
   \end{align*}
   Wäre $f ∈ \mathcal{L}^1 ([0, 1]^2)$, so folge aus Satz von Fubini die Integrierbarkeit
   \[∫_{(0,1)} f(x_1, ·) \d λ(x_1), ∫_{(0,1)} f(·, x_2) \d λ(x_2)\]
   $f$ auf $(0,1) × (0,1)$ stetig ist, erhalten wir Übereinstimmung von \(\mathcal{L}\)-Integral und Riemann-Integral und
   \[∫_{X_2} ∫_{X^1} f \d x_1 \d x_2 = ∫_{X_1} ∫_{X_2} f \d x_2 \d x_1 \lightning\]
   #+end_ex
   #+begin_lemma latex
   Seien $(X_1, Σ_1), (X_2, Σ_2)$ Messräume und $S_1 ⊂ Σ_1, S_2 ⊂ Σ_2$ mit $Σ_{X_1}(S_1) = Σ_1, Σ_{X_2}(S_2) = Σ_2$. Dann gilt
   \[Σ_1 \otimes Σ_2 = Σ_{X_1 × X_2}(S_1 × S_2) =: Σ\]
   wobei
   \[S_1 × S_2 = \{A_1 × A_2 \mid A_1 ∈ S_1, A_2 ∈ S_2\}\]
   #+end_lemma
   #+begin_lemma latex
   Gegeben sind $(X_j, Σ_j, μ_j), j = 1, 2, 3$ mit \(σ\)-finiten Maßen. Dann gilt
   \begin{align*}
   \string(Σ_1 \otimes Σ_2\string) \otimes Σ_3 &= Σ_1 \otimes (Σ_2 \otimes Σ_3) \\
   \text{und } (μ_1 \otimes μ_2) \otimes μ_3 &= μ_1 \otimes (μ_2 \otimes μ_3)
   \end{align*}
   #+end_lemma
   #+ATTR_LATEX: :options [Lebesgue-Maß]
   #+begin_lemma latex
   Das durch $λ^n := λ_1 \otimes \dots \otimes λ_n$ definierte Lebesgue-Maß auf $ℝ^n$ besitzt die Eigenschaften.
   1. Durch die Werte auf der Menge $I$
	  \[I = \bigtimes_{j = 1}^n I_j\]
	  wobei $I_j$ Intervalle sind, ist es eindeutig definiert.
   2. $∀ B ∈ \mathcal{B}^n$ gilt
	  \[λ^n(B) = \inf \{\sum_{k ∈ ℕ} λ^n(A_k) \mid (A_k)_{k ∈ ℕ} ⊂ I, B ⊂ \bigcup_{k ∈ ℕ} A_k\}\]
   3. $λ^n$ ist translationsinvariant und bis auf Normierung das einzige Borelmaß mit diesen Eigenschaften:
   #+end_lemma
   #+begin_remark latex
   Produktmaß zweier vollständiger Maße	ist im Allgemeinen nicht vollständig. \\
   \(A\)-nichtmessbar in $ℝ$, \(1\)-Nullmenge in $ℝ$ \\
   $A × \{1\}$ ist eine	Teilmenge der Nullmenge $ℝ × \{1\}$
   #+end_remark
   #+ATTR_LATEX: :options [Cantormenge]
   #+begin_ex latex
   Wir behalten $I_0 = [0,1]$. Wir entfernen aus $I_0$ das mittleren offene Intervall $J_{1,1} = (1/3, 2/3)$. Wir bekommen
   $I_{1,2} = [0, 1/3], I_{1,2} = [2/3, 1]$. Dann entfernen wir $(1/9,2/9)$ und $(7/9,8/9)$, usw. Induktiv erhalten wir die kompakte Intervalle $I_{n,k}$ $n ∈ ℕ, k = 1, \dots, 2^n$. Wir definieren
   \[C_0 := I_0, C_n := \bigcup_{k = 1}^{2^n} I_k, C := \bigcap_{n = 0}^∞ C_n\]
   $C$ heißt *Cantormenge*. Es  gilt
   1. $C ⊂ [0,1]$ ist kompakt (und damit Borelmenge)
   2. $λ^n(C) = 0$
   3. $C$ ist gleichmächtig mit $ℝ$ (insbesondere überabzählbar)
   #+end_ex
   #+begin_proof latex
   1. $C$ ist offenbar beschränkt und abgeschlossen (als Vereinigung abgeschlossener Mengen) $⇒ C$ kompakt
   2. $C_n$ ist die Vereinigung von $2^n$ disjunkten Intervallen der Länge $3^{-n}$
	  \[⇒ λ^n(C_n) = 2^n e^{-m} = (\frac{2}{3})^n\]
	  Aus der Monotonie des Lebesguemaßen
	  \[⇒ λ^n(C) \leq \lim_{n \to ∞} λ^n (C_n) = 0\]
   #+end_proof
   #+begin_korollar latex
   Sei $n \geq 1$. Dann gibt es überabzählbare \(λ^n\)-Nullmengen in $ℝ^n$
   #+end_korollar
   #+begin_proof latex
   Für $n > 1$ zeigt man leicht, dass die Menge $\{0\} × R^{n - 1} ⊂ ℝ^n$ eine überabzählbare Nullmenge ist. Für $n = 1 \to$ Cantormenge $C ⊂ ℝ$
   #+end_proof
   #+begin_remark latex
   Das Lebesgque-Maß $λ^n$ ist vollständig.
   #+end_remark
** Transformation
   #+ATTR_LATEX: :options [Bildmaß]
   #+begin_lemma latex
   Sei $(X, Σ_X), (Y,Σ_Y)$ Messräume, $f: X \to Y$ messbar. Ist $μ$ ein Maß auf $(X, Σ_X)$ so wird durch
   \[(f \ast μ)(B) := μ(f^{-1}(B)), B ∈ Σ_Y, f^{-1}(B) := \{x ∈ X \mid f(x) ∈ B\}\]
   ein Maß auf $Y$ definiert (Bildmaß von $μ$ bezüglich $f$). Es gilt $(f \ast μ)(B) = 0 ∀ B ∈ Σ_Y$ mit $B ∩ f(X) = \emptyset$
   #+end_lemma
   #+begin_proof latex
   Es gilt $(f \ast μ)(\emptyset) = μ(f^{-1}(\emptyset)) = 0$, da $f^{-1}(\emptyset) = \emptyset$ und
   \[(f \ast μ)(\bigdcup_{k ∈ ℕ} B_k) = μ(f^{-1} (\bigdcup_{k ∈ ℕ} B_k))\]
   für $(B_k)_{k ∈ ℕ} ∈ Σ_Y$, paarweise disjunkt $⇒ f^{-1}(B_k) =: A_k$ ebenfalls eine Folge paarweise disjunkter Mengen und

   \[(f \ast μ)(\bigdcup_{k ∈ ℕ} B_k) = μ(\bigdcup_{k ∈ ℕ} f^{-1}(B_k)) = \sum_{k ∈ ℕ} μ(f^{-1}(B_k)) = \sum_{k ∈ ℕ} (f \ast μ)(B_k)\]
   Ist $B ∈ Σ_Y$ mit $B ∩ f(X) = \emptyset$
   \[⇒ (f \ast μ)(B) = μ(f^{-1}(B)) = μ(\emptyset) = 0\]
   #+end_proof
   #+begin_thm latex
   Sei $(X, Σ, μ)$ ein Maßraum, $Y$ topologischer Raum. $f: (X, Σ) \to (Y, \mathcal{B}(Y)), g:(Y, \mathcal{B}(Y)) \to (ℝ, \mathcal{B}(ℝ))$ messbar.
   $g \circ f: X \to ℝ$ genau dann \(μ\)-fast überall nicht negativ oder integrierbar, wenn das auf $g$ bezüglich $f \ast μ$ zutrifft und in diesem Fall gilt:
   \[∫_Y g \d (f \ast μ) = ∫_X (g \circ f) \d μ\]
   #+end_thm
   #+begin_proof latex
   Für $A := \{x ∈ X \mid (g \circ f) > 0\}$ und $B = \{y ∈ Y \mid g(y) > 0\}$ gilt
   \[(f \ast μ)(B) = μ(f^{-1}(B)) = μ(\{x ∈ X \mid f(x) ∈ B\}) = μ(A)\]
   Also $(f \ast μ)(B^C) = μ(A^C)$. Für das Integral nehmen wir zuerst einfache Funktion
   \begin{align*}
   g &= \sum_{j = 1}^{k} α_j χ_{B_j}, α_j \geq 0, B_j ∈ \mathcal{B}(Y), B_i ∩ B_j = \emptyset ∀ i \neq j, Y = \bigcup_{j = 1}^k B_j \\
   χ_{B_j} \circ f &= χ_{f^{-1}(B_j)} \\
   ⇒ ∫_Y g \d (f \ast μ) &= \sum_{j = 1}^{k} α_j ∫_Y χ_{B_j} \d (f \ast μ) = \sum_{j = 1}^{k} α_j μ(f^{-1}(B_j)) \\
   &= \sum_{j = 1}^{k} α_j ∫_X χ_{f^{-1}(B_j)} \d μ = \sum_{j = 1}^{k} α_j ∫_X χ_{B_j} \circ f \d μ ∫_X (g \circ f) \d μ
   \end{align*}
   Sei $g$ eine	messbare nichtnegative Funktion. Wir konstruieren Folge nicht genativer Funktionen $(g_k)_{k ∈ ℕ} ⊂ \mathcal{S}(Y, f \ast μ)$ mit $g_k \nearrow g$.
   Dann ist auch $g \circ f$ eine Folge nichtnegativer Funktionen mit $g_k \circ f \nearrow g \circ f$. Satz von Beppo-Levi liefert
   \begin{align*}
   ∫_X g_k \circ f \d μ \circ f \d μ &\nearrow ∫_X g \circ f \d μ \\
   ∫_Y g_k \d (f \ast μ) &\nearrow ∫_Y g \d (f \ast μ)
   \end{align*}
   Mit $g = g^{+} - g^{-}$ folgt der allgemeine Fall.
   #+end_proof
   #+begin_remark latex
   1. Verkettung von Bildmaßen $f: X \to Y, g: Y \to Z$
	  \begin{align*}
	  \string(g \circ f\string) \ast μ(C) &= μ((g \circ f)^{-1})(C) = μ((f^{-1} \circ g^{-1})(C))	\\
	  &= μ(f^{-1}(g^{-1}(C))) = f \ast μ(g^{-1}(C)) = g \ast f \ast μ(C)
      \end{align*}
   2. Sei $f: X \to M x + b ∈ ℝ^{n × m}$ invertierbar. Für $b ∈ ℝ$ gilt
	  \[f \ast λ^n = \frac{1}{\abs{\det M}} λ^n\]
	  Zunächst $f \ast λ^n$ ist translationsinvariant und damit	ist $f \ast λ^n$ ein Vielfaches von $λ^n$. Weiter nutzt man, dass da $M$ invertierbar $∃ V_1, V_2 ∈ O(n)$, $D$ Diagonalmatrix sodass
	  $M = V_1 D V_2$. Jede invertierbare Matirx $M$ kann man als Produkt $U_1 D U_2$ mit $U_1, U_2 ∈ \mathcal{O}(n)$ und $D$ diagonal schreiben. ($M$ invertierbar $⇒$ $M^T M$ symmetrisch, positiv definit
      $⇒$ $∃  U ∈ \mathcal{O}(n), D$ diagonal mit positiven Einträgen $M^T M = U^T D^2 U$). Setze $U_1 := M U^T D^{-1}, U_2 := U ∈ \mathcal{O}(n)$
	  \[⇒ U_1^T U_1 = (D^{-1})^T U M^T M U^T D^{-1} = D^{-1} D^{2} D^{-1} = \mathbb{1}\]
	  $⇒ U_1 ∈ \mathcal{O}(n)$ und $U_1 D U_2 = M U^T D^{-1} D U = M$
   4.
       \begin{align*}
	   ∫_A g \underbrace{(M x + b)}_{=: f} \d λ^n &= ∫_A (g \circ f) \d λ^n = ∫_{M A + b} g \circ f_x \d λ^n \\
	   &= \frac{1}{\abs{\det M}} ∫_{M A + b} g \d λ^n
       \end{align*}
   #+end_remark
   #+ATTR_LATEX: :options [Transformationssatz]
   #+begin_thm latex
   Seien $U, V ⊂ ℝ$ und $f ∈ C^1 (U, V)$, $f:$ Diffeomorphismus. Dann gilt
   \[f^{-1} \ast λ^n = \abs{J f} λ^n, J f = \det\underarrow[(J)]{Jacobi Matrix} f\]
   Es gilt
   \[∫_U (g \circ f) \abs{J f} \d λ^n = ∫_V g \d λ^n\]
   $∀$ nichtnegative Funktionen $g: V \to ℝ$
   #+end_thm
   #+begin_proof latex
   zu zeigen:
   \[∫_U (g \circ f) \abs{J f} \d λ^n = ∫_V g \d λ^n\]
   Vorraussetzung: $f$ ist *Diffeomorphismus*:
   \[f ∈ C^1(U, V), f^{-1} ∈ C^1 (V, U)\]
   (also auch $f$ bijektiv) \\
   Schritt 1: Wir betrachten $g = 1$ und offene Quader $R ⊂ U$.	Zu zeigen:
   \[∫_R \abs{J f} f \d λ^n = ∫_{f(R)} \d λ^n = λ^n(f(R))\]
   Wir setzen
   \[φ = \frac{χ_{B_1}(0)}{λ^n (B_1(0))}\]
   und damit
   \[φ_ε(y) = ε^{-n} φ(\frac{y}{n})\]
   \[∫_{ℝ^n} φ_ε(y) \d λ^n (y) = 1\]
   nach Translationsinvarianz, mit $M = \begin{pmatrix} \frac{1}{ε} & 0 \\ 0 & \frac{1}{ε} \end{pmatrix}$. Wir definieren
   \begin{align*}
   I_ε :&= ∫_{f(R)} \abs{Jf (f^{-1} y)} \underbrace{∫_R φ_ε(f(z) - y) \d λ^n z}_{h_ε(y)} \d λ^n y \\
   &= ∫_{f(R)} \abs{J f(f^{-1}(y))}	h_ε(y) \d λ^n y \\
   \end{align*}
   Für $ε < ε_0$ ist $h_ε \neq 0$ nur für $z ∈ K := f^{-1}(\overline{B_ε(y)})$ kompakt. Setze $x := f^{-1}(y) ∈ K$, dann erhalten wir mit Transformation $z \to x + ε z$ und $W_ε(x) := \{\frac{1}{ε}(y - x) \mid y ∈ K\}$
   \begin{align*}
   ⇒ h_ε(y) &= ∫_K φ_ε(f(z) - y) \d λ^n (z) = ε^{-n} ∫_K φ(\frac{f(z) - y}{ε}) \d λ^n(z) \\
   &= ∫_{W_ε(x)} φ(\frac{f(x + ε z) - f(x)}{ε}) \\
   \text{wegen} \quad \abs{\frac{f(x + ε z) - f(x)}{ε}} &\geq \frac{\abs{z}}{c} \quad\text{für}\quad c := \sup_{K} \abs{D(f^{-1})} \\
   \intertext{$x + ε z ∈ U$ ist der Integrand nur für $B_C(0)$ von Null verschieden. Mit $ε \searrow 0$ wird das Gebiet $B_C(0)$ überdecken}
   ⇒ \lim_{ε \to 0} h_ε(y) &= \lim_{ε \to 0} ∫_{B_C(0)} φ(\frac{f(x + ε z) - f(x)}{ε}) \d λ^n(z) \\
   &= ∫_{B_C(0)} \lim_{ε \to 0} φ(\frac{f(x + ε z) - f(x)}{ε}) \d λ^n(z) \\
   \frac{f(x + ε z) - f(x)}{ε} &\to D f(x) z ⇒ φ(\frac{f(x + ε z) - f(x)}{ε}) \to φ(D f(x) z)
   \end{align*}
   $∀ z ∈ B_C(0)$ mit $\abs{D f(x) z} \neq 1$ (wegen Unstetigkeit von $φ$). \\
   Da $\{z ∈ ℝ^n \mid \abs{D f(x) z} = 1\}$ eine Nullmenge ist, gilt die Konvergenz fast überall.
   \[\lim_{ε \to 0} I_ε = ∫_{f(R)} 1 \d λ^n = λ^n (f(R))\]
   \begin{align*}
   \lim_{ε \to 0} I_ε &= \lim_{ε \to 0} \abs{∫_{f(R)} Jf(f^{-1}(y))} φ_ε(f(z) - y) \d λ^n (z) \\
   &= \lim_{ε \to 0} ∫_{B_ε(F(z))} (\abs{J f(f^{-1}(y))}  - \abs{J f(f^{-1}(f(z)))} + \abs{J_f f^{-1}(f(z))}) φ_ε(f(z) - y) \d λ^n(z) \\
   &= \lim_{ε \to 0} (\abs{Jf(f^{-1}(f(z)))} + ∫_{B_ε(f(z))} \abs{Jf(f^{-1}(y))} - \abs{Jf(f^{-1}(f(z)))}) φ_ε(f(z) - y) \d λ^n y \\
   \abs{Jf(f^{-1}(y))} - &\abs{Jf(f^{-1}(f(z)))} \leq \sup_{\mathclap{η ∈ B_ε(f(x))}} \abs{J f(f^{-1}(n))} - \abs{Jf(f^{-1}(f(z)))} \\
   \lim_{ε \to 0}  I_ε &= ∫_R \abs{J f(z)} \d λ^n(z)
   \end{align*}
   Schritt 2: Für $B ∈ \mathcal{B}(U), μ(B) = ∫_B \abs{J f} \d λ^n$ definiert ein neues Maß.
   \[⇒ μ(·) = λ^n(f(·)) = (f^{-1}) \ast (λ^n) \text{ auf } B(U)\]
   Dann gilt Transformationssatz für $g = χ_B, B ∈ \mathcal{B}(U)$ $⇒$ Für einfache Funktionen $⇒$ nichtnegative messbare Funktionen $⇒$ $g = g^{+} - g^{-}$
   #+end_proof

   $f^{-1} ∈ C^1$
   \begin{align*}
   \abs{x + ε z - x} &\leq \sup \abs{D f^{-1}} \abs{f(x + ε z) - f(x)} \\
   \frac{\abs{z}}{c} &\leq \frac{\abs{f(x + ε z) - f(x)}}{ε}
   \end{align*}
* \(L^p\)-Räume
  #+ATTR_LATEX: :options [\(L^p\)-Norm]
  #+begin_defn latex
  Für einen Maßraum $(X, Σ, μ)$ definieren wir \(L^p\)-Norm einer messbaren	Funktion $f: (X, Σ) \to (ℝ, \mathcal{B})$ durch
  \[\norm{f}_{L^p} = (∫_X \abs{f}^p \d μ)^{1/p} \quad p ∈ [1,∞\string)\]
  und mit $\mathcal{L}^p(X,μ)$ bezeichnen wir die Menge aller reelwertigen messbaren Funktionen, deren
  \(L^p\)-Norm endlich ist.
  - $\mathcal{L}^p(X, μ)$ ist ein Vektorraum:
	\[\abs{f + g}^p \leq 2^p \max(\abs{f}^p, \abs{g}^p) \leq 2^p (\abs{f}^p + \abs{g}^p)\]
  zu zeigen: $\norm{·}_{L^p}$ ist eine Norm (Problem: Nullmenge, Lösung: einfach rausteilen)
  - Dreiecksungleichnug ($\leftarrow$ Minkowski Ungleichung) $\to$ \(L^p\)-Räume
  -	\(L^p\)-Räume sind Banachräume (vollständig)
  #+end_defn
  #+begin_lemma latex
  Sei $f: (X, Σ) \to (ℝ, \mathcal{B})$ messbar. Dann gilt
  \[∫ \abs{f}^p \d μ = 0 ⇔ f = 0 \quadμ\text{-fast überall}\]
  #+end_lemma
  #+begin_proof latex
  Mit $g:= \abs{f}^p$
  \[⇒ ∫_X g \d μ = 0 ⇔ g = 0 \quad μ\text{-fast überall } ⇔ f = 0 \quad μ\text{-fast überall}\]
  #+end_proof
  Wir setzen $\mathcal{N}(X, μ) = \{f: (X, Σ) \to (ℝ, \mathcal{B}) \mid f\text{ messbar, } f(x) = 0\quad μ\text{-fast überall}\}$.
  $\mathcal{N}(X, μ)$ ist ein linearer Unterraum von $\mathcal{L}^p$. Wir bilden den Quotientenraum
  \[L^p (X, μ) := \faktor{\mathcal{L}^p(X, μ)}{\mathcal{N}(X, μ)}\]
  Für $X ⊂ ℝ^n, L^p(X) := L^p(X, λ^n)$. Die Elemente von $L^p(X, μ)$ sind Äquivalenzklassen von Funktionen. Wohldefiniertheit der \(L^p\)-Norm auf $L^p(X, μ)$ folgt aus Lemma 2.2.
  - Im Fall	$p = 2$ haben wir einen Hilbertraum, das heißt einen vollständig normierten Raum (Banach Raum) mit Skalarprodukt
	\[\angl{f, g}_{L^2(X, μ)} := ∫_X f(x) \overline{g(x)} \d μ(x)\]
  -	Wir können auch $p = ∞$	betrachten,
	\begin{align*}
	\norm{f}_{L^∞(X, μ)} &= \inf \{s > 0 \mid μ(\{x ∈ X \mid \abs{f(x)} \geq s\}) = 0\} \\
	&= \sup \{s \geq 0 \mid μ(\{x ∈ X \mid \abs{f(x)} \geq s\}) > 0\}
   	\end{align*}
  Wir bezeichnen mit $B(X, μ)$ die Menge der essentiell beschriebenen Funktionen und setzen $L^∞(X, μ) = \faktor{B(X, μ)}{\mathcal{N}(X, μ)}$
  #+begin_ex latex
  \begin{align*}
  \norm{χ_{ℚ}}_{L^∞(ℝ, λ)} &= 0 \\
  \norm{χ_{ℚ}}_{L^∞(ℝ, δ_0)} &= 1 \\
  δ_0(\{x ∈ ℝ \mid χ_ℚ(x) \geq s\}) &= 1
  \end{align*}
  #+end_ex
  #+begin_defn latex
  Sei $X$ ein metrischer Raum, der lokal kompakt ist (das heißt jeder Punkt aus $X$ besitzt eine kompakte Umgebung). Dann heißt $f: (X, Σ) \to (ℝ, \mathcal{B})$ *lokal \(p\)-integrierbar* falls
  \[f ∈ L^p(K, μ) ∀ K ⊂ X\]
  Bezeichnung: $L^p_{\text{loc}}(X, μ)$
  #+end_defn
  *Ungleichnugen (Jemen, Hölder, Minkowski)* \\
  *Erinnerung*: Konvexe Funktion:
  \[f:(a, b) \to ℝ: φ(λ x + (1 - λ) y) \leq λφ(x) + (1 - y) φ(y) ∀ x, y ∈ (a, b), λ ∈ (0, 1)\]
  strikt konvex für "$<$". \\
  Jede Norm auf einem Vektorraum ist konvex. denn für $f, g ∈ X, λ ∈ (0,1)$ gilt:
  \[\norm{λ f + (1 - λ) g}_X \leq λ\norm{f}_X + (1 - λ) \norm{g}_X\]
  $∀$ konvexe $φ$ auf $a < x < z < y < b$ ($z = λ x + (1 - λ)y$ für ein $λ ∈ (0,1)$)
  \begin{align*}
  \frac{φ(z) - φ(x)}{z - x} &\leq \frac{φ(y) - φ(x)}{y - x} \leq \frac{φ(y) - φ(z)}{y - z} \tag{\(\ast\)} \\
  \frac{φ(λ x + (1 - λ)y) - φ(x)}{(λ - 1)x + (1 - λ)y} &\leq \frac{(λ - 1)φ(x) + (1 - λ)φ(y)}{(1 - λ)(y - x)} = \frac{φ(y) - φ(x)}{y - x} \\
  \end{align*}
  Wir erhalten "$<$" für strikte Konvexität.
  #+begin_lemma latex
  Die folgende Aussagen gelten für alle konvexe $φ:(a, b) \to ℝ$:
  1. $φ$ ist lokal Lipschitz-stetig, das heißt für alle kompakte $I ⊂ (a, b) ∃ L_1 < ∞$ mit
	 \[\abs{φ(x) - φ(y)} \leq L_1 \abs{x - y} ∀ x, y ∈ I\]
  2. Die Ableitungen
	 \[φ'_{\pm} = \lim_{h\searrow 0} \frac{φ(x + h) - φ(x)}{\pm h}\]
	 existieren und sind monoton fallend.
	 Darüber hinaus existiert $φ'$ bis auf Nullmenge.
  3. Für ein festes $\bar x ∈ (a, b) ∀ α ∈ [φ'_{-}(\bar x), φ'_{+}(\bar x)]$ gilt
	 \[φ(y) \geq φ(\bar x) + α(y - \bar x) \quad ∀ y ∈ (a, b)\]
	 "$>$" für strikte Konvexität von $φ$ und $y \neq \bar x$
  #+end_lemma
  #+begin_proof latex
  Wir setzen
  \begin{align*}
  \frac{φ(y) - φ(x)}{y - x} &=: D(x, y) = D(y, x) \\
  \xRightarrow{(\ast)} D(x, z) &\leq D(x, y) \leq D(y, z) \quad\text{für } x < z < y
  \end{align*}
  Damit ist $ε \to D(x + ε, x)$ monoton steigend (und beschränkt) (Für $ε_1 < ε_2 ⇒ D(x + ε_1, x) \leq D(x + ε_2, x)$) \\
  $⇒ ∃ φ_{+}'(x)$ und $φ_{-}'(x)$
  \begin{align*}
  D(x - ε, x) \leq D(x+ ε, x) ⇒ φ_{-}'(x) &\leq φ'_{+}(x) \\
  φ_{+}'(x) &\leq φ_{-}'(y) \text{ für } x < y \\
  ⇒ φ_{-}'(x) &\leq φ_{+}'(x) \leq φ_{-}'(y) \leq φ_{+}'(y) \quad\text{für}\quad x < y
  \end{align*}
  Da eine monotone Funktione nur eine abzählbare Anzahl von Sprüngen enthalten kann (jedes Sprungintervall enthält eine rationale Zahl und sie sind paarweise disjunkt) $⇒$ 2.
  Aus $(\ast)$ $⇒$
  \begin{gather*}
  φ_{+}'(x) \leq D(x, y) \leq φ_{-}'(y) \quad\text{für}\quad x < y \\
  \begin{aligned}
  ⇒ y > x &⇒ φ(y) \geq φ(x) + φ_{+}'(x)(y - x) \\
  y < x &⇒ φ(y) \geq φ(x) + φ_{-}'(x)(y - x)
  \end{aligned} \\
  φ_{-}'(x)(y - x),	φ_{+}'(x)(y - x) \to α (y - x)
  \end{gather*}
  $⇒$ 3. \\
  Für $a < α < x < y < β$ ist $φ_{+}'(α) \leq D(x, y) \leq φ_{-}'(β)$ $⇒$ 1. mit
  \[L_{[α, β]} := \max(\abs{φ_{+}'(α)}, \abs{φ_{-}'(β)})\]
  #+end_proof
  #+ATTR_LATEX: :options [Jensen'sche Ungleichung]
  #+begin_thm latex
  Sei $ϕ: (a, b) \to ℝ$ konvex für $- ∞ \leq a < b \leq ∞$. Ist $μ$ ein W'maß auf $(X, Σ)$ mit $μ(X) = 1, f ∈ \mathcal{L}^1(X, μ)$ mit $a < f(x) < b$ für alle $x ∈ X$, dann
  ist der negtive Teil von $ϕ \circ f$ integrierbar und
  \[ϕ(∫_X f \d μ) \leq ∫_X (ϕ \circ f) \d μ\]
  Ist $ϕ \geq 0$ nicht fallend, $f \geq 0$ und
  \[ϕ(b) := \lim_{x \to b} ϕ(x)\]
  so gilt die Aussage für nicht	integrierbare $f$.
  #+end_thm
  #+begin_proof latex
  Eigenschaft 3. des Lemma 2.5 impliziert
  \[ϕ(f(x)) \geq ϕ(\bar x) + α(f(x) - \bar x) ∀ x ∈ X, \bar x = ∫_X f \d μ ∈ (a, b)\]
  Damit ist $(ϕ \circ f)_{-}$ integrierbar und wir erhalten
  \[∫_X ϕ(f(x)) \d μ(x) \geq ϕ(\bar x) + α (∫_X f(x) \d μ(x) - \bar x) = ϕ(\bar x)\]
  Sei nun $f \geq 0$, aber $f \not ∈ \mathcal{L}^1(X, μ)$, so setze
  \[X_n := \{x ∈ X \mid f(x) \leq n\}\]
  und erhalten wir aus dem bisher gezeigten
  \[ϕ(\frac{1}{μ(X_n)} ∫_{X_n} f \d μ) \leq \frac{1}{μ(X_n)} ∫_{X_n} ϕ \circ f \d μ\]
  für $n \to ∞$ erhlaten wir $X_n \nearrow X$ einerseits und $μ(X_n) \nearrow μ(X)$ andererseits. Die Konvergenz der Integrale erhalten wir mit dem Satz über monotone Konvergenz.
  #+end_proof
  #+ATTR_LATEX: :options [Hölder-Ungleichung]
  #+begin_thm latex
  Seien $p, p' ∈ [1, ∞]$ dual, das heißt
  \[\frac{1}{p} + \frac{1}{p'} = 1\]
  Ist $f ∈ L^p(X, μ)$ und $g ∈ L^{p'}(X, μ)$, so folgt $f · g ∈ L^1(X, ψ)$ und es gilt
  \[\norm{f · g}_{L_1} \leq \norm{f}_{L^p} \norm{g}_{L^{p'}}\]
  #+end_thm
  #+begin_proof latex
  Übungen
  #+end_proof
  #+begin_korollar latex
  Für jedes $f ∈ L^p(X, μ)$ mit $p ∈ [1, ∞\string)$ gilt
  \[\norm{f}_{L^p} = \sup \{∫_X f · g \d μ \mid g ∈ L^{p'}(X, μ), \norm{g}_{L^{p'}} = 1\}\]
  #+end_korollar
  #+begin_proof latex
  "$\geq$" folgt unmittelbar aus Hölder. \\
  "$\leq$" Wähle geeignetes $g$, nämlich
  \[g := \frac{\sgn(f) \abs{f}^{p - 1}}{\norm{\abs{f}^{p - 1}}_{L^p}}, f \neq 0\]
  Für $p = 1$ wähle $g = \sgn (f)$
  #+end_proof
  #+begin_lemma latex
  Sei $μ$ ein \(σ\)-finites Maß, $f:(X, Σ) \to (ℝ, \mathcal{B})$ messbar und $p ∈ [1, ∞\string)$.
  Gilt $f · s ∈ L^1(X, μ)$ für jedes $s ∈ S(X, μ) ∩ \mathcal{L}^1(X, μ)$ so folgt $f ∈ L^p(X, μ)$ und
  \[\norm{f}_{L^p} = \sup \{∫_X f · s \d μ \mid s ∈ S(X, μ) ∩ \mathcal{L}^1(X, μ), \norm{s}_{L^{p'}} = 1\}\]
  #+end_lemma
  #+ATTR_LATEX: :options [Minkowski-Ungleichnug]
  #+begin_thm latex
  Seien $μ, ν$ zwei \(σ\)-finite Maße auf den Maßräumen $(X, Σ, μ), (Y, Υ, ν)$ und $f$ sei \((μ \otimes ν)\)-messbar. Dann haben wir für $p ∈ [1, ∞\string)$
  \[\norm{∫_Y f(·, y) \d ν(y)}_{L^p} \leq ∫_Y \norm{f(·, y)}_{L^p} \d ν(y)\]
  #+end_thm
  #+begin_proof latex
  Sei $g ∈ L^p(X, μ)$ mit $g \geq 0$ und $\norm{g}_{L^{p'}} = 1$. Aus Fubini folgt
  \[∫_X g(x) ∫_Y \abs{f(x, y)} \d ν(y) \d μ(x) \overarrow[=]{Fubini} ∫_Y ∫_X \abs{f(x, y)} g(x) \d μ(x) \d ν(y)\]
  Durch Anwendung des Korollar 2.8 schließen wir, dass die linke Seite gerade die \(L^p\)-Norm von
  \[∫_Y f(·, y) \d ν(y)\]
  ist. Außerdem gilt mit Hölder
  \[∫_Y ∫_X \abs{f(x, y)} g(x) \d μ(x) \d ν(y) \leq ∫_Y \norm{f(·, y)}_{L^p} \norm{g}_{L^{p'}} \d ν(y)\]
  #+end_proof
  #+begin_remark latex
  Aus Fatous Lemma erhalten wir die Unterhalbsstetigkeit der \(L^p\)-Normen. Gilt $f_n \to f$ punktweise \(μ\)-fast überall so haben wir
  \[\norm{f}_{L^p}^p = ∫_X \liminf_{k \to ∞} \abs{f_k}^p \d μ \leq \liminf_{k \to ∞} ∫_X \abs{f_k}^p \d μ = \liminf_{k \to ∞} \norm{f_k}_{L^p}^p\]
  #+end_remark
  #+begin_lemma latex
  Sei $p ∈ [1, ∞\string)$ und $(f_k)_{k ∈ ℕ} ⊂ L^p(X, μ)$ konvergiere punktweise \(μ\)-fast überall gegen ein $f$. Gibt es also eine Funktion $g ∈ L^p(X, μ), \abs{f_k} \leq g$ für jedes $k ∈ ℕ$,
  so ist auch $f ∈ L^p(X, μ)$ und die Folge $(f_k)_{k ∈ ℕ}$ konvergiert in $L^p(X, μ)$.
  #+end_lemma
  #+begin_proof latex
  Zunächst ist $\abs{f} \leq g$ und damit
  \[\norm{f}_{L^p}^p = ∫_X \abs{f}^p \d μ \leq ∫_X g^p \d μ < ∞\]
  Da die Folge $(f_k)_{k ∈ ℕ}$ punktweise \(μ\)-fast überall gegen $f$ konvergiert
  \[\abs{f_k - f}^p \xrightarrow{k \to ∞} 0\]
  \(μ\)-fast überall. Außerdem ist $\abs{f_k - f}^p \leq 2^p g^p$. $2^p g^p$ ist integrierbar
  und so liefert der Satz von Lebesgue
  \[\lim_{k \to ∞} \norm{f_k - f}_{L^p} = \lim_{k \to ∞}(∫_X \abs{f_k - f}^p \d μ)^{\frac{1}{p}} = 0\]
  #+end_proof
  #+ATTR_LATEX: :options [Fischer-Riesz (Vollständigkeit)]
  #+begin_thm latex
  Der Raum $L^p(X, μ)$ ist für $p ∈ [1, ∞]$ vollständig und somit ein Banachraum.
  #+end_thm
  #+begin_proof latex
  Wir verwenden die Vollständigkeit von $ℝ$. Sei $p < ∞$ und $(f_k)_{k ∈ ℕ} ⊂ L^p(X, μ)$ sei eine Cauchyfolge, das heißt
  \[∀ ε > 0 ∃ k = k(ε) ∀ t, k \geq K: \norm{f_j -  f_k}_{L^p} < ε\]
  Wir möchten zeigen, dass es ein $f ∈ L^p(X, μ)$ gibt mit $\norm{f_k - f}_{L^p} \to 0$. Es genügt dies für eine Teilfolge zu verifizieren.	Durch
  Auswahl von Elementen der Folge können wir
  \[\norm{f_{k + 1} - f_k} \leq 2^{-k} ∀ k ∈ ℕ\]
  erreichen. Mit $f_0 = 0, g_k := f_k - f_{k - 1} ∀ k ∈ ℕ$ und
  \[G := \sum_{k ∈ ℕ} \abs{g_k}\]
  erhalten wir
  \[\norm{\sum_{j = 1}^{k} \abs{g_j}}_{L^p} \leq \sum_{j = 1}^{k} \norm{g_j}_{L^p} \leq \norm{g_1}_{L^p} + \sum_{j = 1}^{k} 2^{-j} \leq \norm{g_1}_{L^p} + 1\]
  Aus dem Satz über monotone Konvergenz gewinnen wir $G ∈ L^p$ und wir erhalten insbesondere $G(x) < ∞$ für fast alle $x ∈ X$. An diesen Punkten konvergiert
  \[\tilde f = \sum_{k ∈ ℕ} g_k = \lim_{k \to ∞} \sum_{j = 1}^{k} g_j = \lim_{k \to ∞} f_k\]
  absolut. Dort ist
  \[\abs{f_k(x) - \tilde f(x)}^p \xrightarrow{k \to ∞} 0\]
  und zusätzlich in den Punkten wo $G(x) < ∞$
  \[\abs{f_k - \tilde f}^p = \abs{\sum_{j = 1}^{k} g_j - \sum_{j = 1}^{∞} g_j}^p = \abs{\sum_{j = k + 1}^{∞} g_j}^p \leq \abs{\sum_{j = 1}^{∞} \abs{g_j}}^p \leq \abs{G}^p\]
  Nun ist $\abs{G}^p ∈ L^1(X, μ)$ mit $f= \liminf_{k \to ∞} f_k$ erhalten wir eine messbare Funktion $f = \tilde f$ \(μ\)-fast überall. Nun folgt aus dem Satz über dominierte Konvergenz
  \[\norm{f_k - f}_{L^p}^p = ∫_X \abs{f_k - f}^p \d μ \xrightarrow{k \to ∞} 0\]
  Im Fall $p = ∞$ gilt für die Cauchyfolge $(f_k)_{k . ℕ} ⊂ L^∞$
  \[∀ m ∈ ℕ ∃ M(m) ∈ ℕ ∀ j, k \geq M: \norm{f_k - f_j}_{L^∞} < \frac{1}{m}\]
  Also existiert eine Nullmenge $A_{j,k,m} ∈ Σ$ mit
  \[\abs{f_j(x) - f_k(x)} \leq \frac{1}{m} ∀ x ∈ X \setminus A_{j,k,m}\]
  Definiere
  \[A = \bigcup_{m ∈ ℕ} \bigcup_{j,k \geq M} A_{j,k,m}\]
  $A$ ist eine Nullmenge. Folglich ist $(f_k(x))_{k ∈ ℕ} ⊂ ℝ$ für jedes $x ∈ X \setminus A$ eine Cauchyfolge. Somit
  \[f(x) := \liminf_{k \to ∞} f_k(x)\]
  Damit haben wir $\abs{f_j(x) - f(x)} \leq \frac{1}{m} ∀ x ∈ X \setminus A, j \geq M$. Weiterhin ist $f$ messbar. Nun gilt
  \begin{align*}
  \norm{f_k - f}_{L^∞} &= \sup \{s \geq 0 \mid μ(\{x ∈ S \mid \abs{f_k(x) - f(x)} \geq 0\}) > 0\} \\
  &= \sup \{s \geq 0 \mid μ(\{x ∈ X \setminus A \mid \abs{f_k(x) - f(x)} \geq s\}) > 0\} \\
  &\leq \frac{1}{m} \quad\text{für } k = M
  \end{align*}
  Also folgt
  \[\norm{f_k - f}_{L^∞} \xrightarrow{k \to ∞} 0\]
  #+end_proof
  #+begin_korollar latex
  Konvergiert eine Folge in $L^P(X, μ), p ∈ [1, ∞\string)$, so gibt es eine Teilfolge, die punktweise \(μ\)-fast überall konvergiert. Die Grenzwerte einer in $L^p$ und $L^q, p, q ∈ [1,∞]$ konvergierende Folge
  stimmen fast überall überein.
  #+end_korollar
  #+begin_ex latex
  $\underbrace{χ_{[0, \frac{1}{2}]}, χ_{[\frac{1}{2}, 1]}}_{\norm{·}_{L^p} = \frac{1}{2}}, \underbrace{χ_{[0, \frac{1}{3}]}, χ_{[\frac{1}{3}, \frac{2}{3}]}, χ_{[\frac{2}{3}, 1]}}_{\norm{·}_{L^p} = \frac{1}{3}}, \dots$
  Also konvergiert diese Folge in $L^p$ gegen $0$, aber nicht punktweise fast überall.
  #+end_ex
** Approximation
  #+ATTR_LATEX: :options [Dichtheit]
  #+begin_defn latex
  Eine Teilmenge $A$ eines topologischen Raums $X$ heißt *dicht*, falls es zu jedem Punkt $x ∈ X$ eine Folge $(x_n)_{n ∈ ℕ}$ aus $A$ gibt mit $x_n \to x$.
  #+end_defn
  #+begin_thm latex
  Sei $X$ ein lokal kompakter, metrischer Raum (jeder Punkt liegt in einer kompakten Umgebung) und $μ$ ein reguläres Borelmaß (endliche Werte auf Kompakta).
  - Regulär von innen: $μ(A) = \sup\{μ(K) \mid K ⊂ A \text{ kompakt}\}$
  - Regulär von außen: $μ(A) = \inf\{μ(K) \mid A ⊂ U \text{ offen}\}$
  Dann ist die Menge $C_c^0(X)$ aller stetigen Funktionen mit kompakten Träger dicht in $L^p(X, μ)$.
  Dabei ist der Träger eine Funktion $f: A \to ℝ$ $\supp(f)$ definiert als
  \[\succ(f) = \overline{\{x ∈ A\mid f(x) \neq 0\}}\]
  #+end_thm
  #+begin_proof latex
  Wir können nicht-negative Funktionen durch eine Folge von einfachen Funktionen bezüglich der \(L^1\)-Norm approximieren. Man überträgt leicht dieses Argument auf beliebige integrierbare Funktionen
  und Funktionen aus $\mathcal{L}^p$ beziehungsweise $L^p, p ∈ [1, ∞\string)$. Da die einfachen Fuktionen durch die Linearkombination von charakteristischen Funktionen auf Urbilder halboffener Mengen
  und da das Maß regulär ist von innen können wir diese Mengen beliebig gut durch Kompakta approximieren. Folglich genügt es zu zeigen, dann $χ_K, K ⊂ X$ kompakt bezüglich der \(L^p\)-Norm beliebig gut
  durch stetige Funktionen approximierbar ist. Ausgrund der äußeren Regularität des Maßes finden wir für $ε > 0$ eine offene Menge $U$ mit $K ⊂ U$ und $μ(U \setminus K) = μ(U) - μ(K) < ε$. Wir setzen
  \[f_ε(x) := \frac{\dist(x, U^C)}{\dist(x, K) + \dist(x, U^C)}\]
  Dies liefert eine stetige Funktion mit $f_ε(x) ∈[0, 1]$ und
  \begin{align*}
  \dist(x, A) := \inf_{y ∈ A} \abs{x - y} \\
  f_ε(x) &= 0 ⇔ \dist(x, U^C) = 0 ⇔ x ∈ U^C \\
  f_ε(x) &= 1 ⇔ \dist(x, K) = 0 ⇔ x ∈ K \\
  ∫_X \abs{f_ε(x) - χ_K(x)}^p \d μ(x) &= ∫_{U \setminus K} \abs{(f_ε(x) - χ_k)}^p \d μ(x) \leq μ(U \setminus K) < ε
  \end{align*}
  #+end_proof
  #+begin_remark latex
  Diese Aussage gilt nicht für $p = ∞$, da für stetige Funktionen die \(L^∞\)-Norm der Supremumsnorm entspricht und somit die Grenzfunktion stetig ist.
  #+end_remark
  #+ATTR_LATEX: :options [Faltung]
  #+begin_defn latex
  Für integrierbare Funktionen $f, g: ℝ^n \to ℝ$ setzen wir
  \[(f \ast g)(x) = ∫_{ℝ^n} f(x - y) g(y) \d λ^n(y) = ∫_{ℝ^n} g(x - y) f(y) \d λ^n(y)\]
  und bezeichnen den Ausdruck $f \ast g$ als Faltung. Die Faltung selbst ist integrierbar, denn es gilt
  \begin{align*}
  ∫_{ℝ^n} \abs{f \ast g} \d λ^n &\leq ∫_{ℝ^n} ∫_{ℝ^n} \abs{f(x - y)}\abs{g(y)} \d λ^n(y) \d λ^n(x) \\
  &= ∫_{ℝ^n} ∫_{ℝ^n} \abs{f(x - y)} \d λ^n(x) \abs{g(y)} \d λ^n(y) = \norm{f}_{L^1} \norm{g}_{L^1} < ∞
  \end{align*}
  #+end_defn
  #+begin_lemma latex
  Die Faltung besitzt folgende Eigenschaften:
  1. Für $x ∈ ∮ℝ^n$ ist die Funktion $f(x - ·) g(·)$ genau dann integrierbar, wenn $f(·)g(x - ·)$ integrierbar ist und es gilt in diesem Fall $(f \ast g)(x) = (g \ast f)(x)$
  2. Für $ϕ ∈ C_c^k(ℝ^n), k ∈ ℕ$ und $f ∈ L^1_{\text{loc}}(ℝ^n)$ folgt $f \ast ϕ ∈ C^k(ℝ^n)$ und $\partial_α (ϕ \ast f) = \partial_α ϕ \ast f$ für jede partielle Ableitung einer Ordnung $\leq k$.
  3. Für $ϕ ∈ C_c^k(ℝ^n), k ∈ ℕ$ und $f ∈ L_c^1$ (es gibt einen Repräsentanten mit kompaktem Träger) ist $ϕ \ast f ∈ C_c^k(ℝ^n)$
  4. Für $ϕ ∈ L^1(ℝ^n), f ∈ L^p(ℝ^n), p ∈ [1, ∞]$ gilt auch $f \ast ϕ ∈ L^p(ℝ^n)$ und wir haben die Young-Ungleichnug:
	 \[\norm{f \ast ϕ}_{L^p} \leq \norm{ϕ}_1 \norm{f}_1\]
  #+end_lemma
  #+begin_proof latex
  1. Folgt unmittelbar aus dem Transformationssatz
  2. Folgt induktiv durch vertauschen von Differentation und Integration.
  3. Ist $\supp f ∪ \supp ϕ ⊂ B_R(0)$ für $R > 0$, so erhalten wir für $x ∈ ℝ^n$:
	 \begin{align*}
	 \string(f \ast ϕ\string)(x) &= ∫_{ℝ^n} f(y) ϕ(x - y) \d λ^n(y) \neq 0 \\
	 ⇒ y, x - y &\overset{!}{∈} B_R(0) ⇒ x = (x - y) + y ∈ B_{2R}(0)
   	 \end{align*}
	 Demnach ist $\supp f \ast ϕ ⊂ B_{2R}(0)$.
  4. $p = ∞$
	 \[\norm{f \ast ϕ}_{L^∞} = \norm{∫_{ℝ^n} f(y) g(x - y) \d λ^n(y)} \leq \norm{f}_{L^∞} \norm{ϕ}_{L^1}\]
	 Sei nun $p < ∞$. Wir können ohne Beschränkung der Allgemeinheit annehmen $\norm{ϕ}_{L^1} = 1$. Anwendung der Jensen-Ungleichnug (mit $φ(ξ) = \abs{ξ}^p, \d μ = \abs{ϕ} \d λ^n$)
	 \begin{align*}
	 \norm{f \ast ϕ}_{L^p}^p &\leq ∫_{ℝ^n} \abs{∫_{ℝ^n} \abs{f(x - y)}\abs{ϕ(y)} \d λ^n(y)}^p \d λ^n(x) \\
	 &= ∫_{ℝ^n} φ(∫_{ℝ^n} \abs{f(x - y)} \abs{ϕ(y)} \d λ^n(y)) \d λ^n(x) \leq ∫_{ℝ^n} ∫_{ℝ^n} \abs{f(x - y)}^p \abs{ϕ(y)}^p \d λ^n(y) \d λ^n(x) \\
   	 &\leq ∫_{ℝ^n} ∫_{ℝ^n} \abs{f(x - y)}^p \d λ^n(x) = \norm{f}_{L^p}^p
   	 \end{align*}
  #+end_proof
  #+begin_defn latex
  Eine Familie $(ϕ_ε)_{ε >}$ integrierbarer Fuktionen von $ℝ^n$ nach $ℝ$ heißt *approximative Identität* falls
  1. $\displaystyle{\sup_{ε > 0} \norm{ϕ_ε}_{L^1} < ∞}$ (manchmal wir auch $ϕ_ε \geq 0 ∀ ε > 0$ vorrausgesetzt)
  2. $\displaystyle{∫_{ℝ^n} ϕ_ε \d λ^n = 1 ∀ ε > 0}$
  3. $∫_{ℝ^n \setminus B_R(0)} \abs{ϕ_ε} \d λ^n \xrightarrow{ε \to 0} 0 ∀ r > 0$
  Ein Glättungskern ist eine nicht-negative Funktion $ϕ ∈ C_c^∞(ℝ^n)$ mit $\norm{ϕ}_{L^1} = 1$.
  #+end_defn
  #+begin_remark latex
  Aus jedem Glättungskern $ϕ ∈ C_c^∞(ℝ^n)$ erhält man durch
  \[ϕ_ε(x) := ε^{-n} ϕ(\frac{x}{ε})\]
  eine appoximative Identität. Standard-Glättungskern
  \[x ↦ \begin{cases} \exp(\frac{1}{\abs{x}^2 - 1}) & \abs{x} < 1 \\ 0 & \text{sonst}\end{cases}\]
  #+end_remark
  #+ATTR_LATEX: :options [2.20]
  #+begin_lemma latex
  Sei $(ϕ_ε)_{ε > 0}$ eine approximative Identität und $f ∈ L^p(ℝ^n), p ∈ [1, ∞\string)$. Dann gilt
  \[\norm{f \ast ϕ_ε - f}_{L^p} \xrightarrow{ε \to 0} 0\]
  #+end_lemma
  #+begin_proof latex
  Sei $f ∈ C_c^0(ℝ^n)$. Wir nehmen ein $δ$. \\
  $\abs{f(x - y) - f(x)} \xrightarrow{\abs{y} \searrow 0} 0$ gleichmäßig in $x$ aufgrund von gleichmäßiger Stetigkeit (nach dem Satz von Heine). Weiterhin, aufgrund des
  kompakten Trägers für $\abs{y} < r$ ($r$ hinreichend klein)
  \begin{align*}
  \norm{f(· - y) - f(·)}_{L^p} &= (∫_{B_r(\supp f)} \abs{f(x - y) f(x)}^p \d λ^n)^{1/p} \\
  B_r(E) &:= \bigcup_{ξ ∈ E} B_r(ξ) \\
  \norm{f(· - y) - f(·)}_{L^p} &\leq \norm{f(· - y) - f(·)}_{L^∞} (∫_{B_r(\supp f)} 1^p \d λ^n(x))^{1/p} &\leq \frac{δ}{2 \sup_{ε > 0} \norm{ϕ_ε}_{L^1}}
  \end{align*}
  (für $r$ hinreichend klein). Mit Minkowski Ungleichung:
  \begin{align*}
  \string(f \ast ϕ_ε\string)(x) - f(x) &= ∫_{ℝ^n} ϕ_ε(y)(f(x - y) - f(x)) \d λ^n(y) \\
  \norm{(f \ast ϕ_ε) - f}_{L^p} &\leq \norm{∫_{B_r(0)} ϕ_ε(y)(f(· - y) - f(·)) \d λ^n(y)}_{L^p} +	\norm{∫_{ℝ^n \setminus B_r(0)} ϕ_ε(y)(f(· - y) - f(·)) \d λ^n(y)}_{L^p} \\
  &\leq ∫_{B_r(0)} \abs{ϕ_ε(y)} \underbrace{\norm{f(· - y) - f(·)}_{L^p}}_{\leq \frac{δ}{2 \sup \norm{ϕ_ε}_{L^1}}} \d λ^n(y) + ∫_{ℝ^n \setminus B_r(0)} \abs{ϕ_ε(y)} \norm{f(· - y) - f(·)}_{L^p} \d λ^n(y) \\
  &\leq \frac{δ}{2} + \underbrace{2	\norm{f}_{L^p} ∫_{ℝ^n \setminus B_r(0)} \abs{ϕ_ε(y)} \d λ^n(y)}_{\leq \frac{δ}{2} \text{ für hinreichend kleine } ε > 0}
  \end{align*}
  Somit ist die Behauptung für $f ∈ C_c^0(ℝ^n)$ gezeigt. Da $C_c^0(ℝ^n)$ dicht in $L^p(ℝ^n)$ sind (Satz 2.16), wählen wir für ein $f ∈ L^p(ℝ^n)$ eine Folge $(f_k)_{k ∈ ℕ} ∈ C_c^0(ℝ^n)$ mit $\norm{f_k - f}_{L^p} \xrightarrow{k \to ∞} 0$
  \begin{align*}
  ⇒ \norm{f\ast ϕ_ε - f}_{L^p} &\leq \overbrace{\norm{f\ast ϕ_ε - f_k \ast ϕ_ε}_{L^p}}^{\norm{(f - f_k) \ast ϕ_ε}} + \underbrace{\norm{f_k \ast ϕ_ε - f_k}_{L^p}}_{ε \to 0 \nearrow 0 \text{ für festes } k} + \underbrace{\norm{f_k - f}_{L^p}}_{\xrightarrow{k\to ∞} 0} \\
  &\leq \underbrace{\norm{f - f_k}_{L^p}}_{\xrightarrow{k \to ∞} 0} \underbrace{\norm{ϕ_ε}_{L^1}}_{\leq M}
  \end{align*}
  Wir nehmen $k$ hinreichend groß und dann $ε$ hinreichend klein.
  #+end_proof
  #+begin_thm latex
  Sei $Ω ⊂ ℝ^n$ offen. Dann liegt die Menge $C_c^∞(Ω)$ aller glatten Funktionen mit kompakten Träger dicht in $L^p(Ω)$ für $p ∈ [1, ∞\string)$.
  #+end_thm
  #+begin_proof latex
  Nach dem Satz 2.16 genügt es zu zeigen, dass $C_c^∞(ℝ^n)$ dicht in $C_c^0(ℝ^n)$ ist. (denn wir können $f\big|_{ℝ^n \setminus Ω} = 0$ setzen). Wir wählen einen Glättungskern $ϕ$
  $⇒ f\ast ϕ_ε$ kompakter Träger und $C^∞$ $⇒$ mit Lemma 2.18.3 und aus Satz 2.20 folgt die Behauptung.
  #+end_proof
* Fourier-Transformation
  #+begin_defn latex
  Für $f ∈ L^1(ℝ^n)$ definieren wir
  \[\hat f(p) = \frac{1}{(2π)^{n/2}} ∫_ℝ e^{-i\braket{p,x}} f(x) \d λ^n(x) \qquad p ∈ ℝ^n\]
  mit $\braket{·,·}$: Skalarprodukt. \\
  $\mathcal{F}: f \to \hat f$ heißt Fourier-Transformation. $\mathcal{F}$ ist eine lineare Abbildung die beschränkt ist.
  Eine lineare Abbildung \(A: X \to Y, X, Y\)-normierte Räume, heißt beschränkt falls $∃ C > 0, \text{ sodass } \norm{A x}_Y \leq C \norm{x}_X$
  \[\norm{A} := \sup_{\norm{x}_X} \frac{\norm{A x}_Y}{\norm{x}_X} \leq C\]
  Mit $C_b^0$ bezeichnen wir den Raum der stetigen und beschränkten Funktionen. (also $C_b^0 = C^0 ∩ L^∞$)
  #+end_defn
  #+begin_lemma latex
  Die Fourier-Transformation $\mathcal{F}$ ist eine beschränkte Abbildung $L^1(ℝ)\to C_b^0(ℝ^n)$ mit
  \[\norm{\hat f}_{L^∞} \leq \frac{1}{(2π)^{n/2}}\norm{f}_{L^1}\]
  "$=$" für $f$ nichtnegativ.
  #+end_lemma
  #+begin_proof latex
  Die Abschätzung aus der Definition. Stetigkeit von $\hat f$: Wir wählen eine Folge $(p_k)_{k ∈ N} ⊂ ℝ^n, p_k \to p$ für $k \to ∞$. Wegen
  \[\abs{e^{-i\braket{p,x}}} = 1\]
  ist $\abs{f}$ eine Majorante. Ausdem Satz über dominierte Konvergenz folgt die Behauptung. Ist $f \geq 0$
  \begin{align*}
  ⇒ \norm{f}_{L^1} &= ∫_{ℝ^n} \abs{f} \d λ^n = ∫_{ℝ^n} e^{-i\braket{0,x}} f(x) \d λ^n(x) \\
  &= (2π)^{n/2} \hat f(0) \leq (2π)^{n/2} \norm{\hat f}_{L^∞} \leq \norm{f}_{L^1}
  \end{align*}
  #+end_proof
  #+begin_lemma latex
  Für $f, g ∈ L^1(ℝ^n), a,p ∈ ℝ^n, λ > 0$ gilt
  1. $\widehat{f(· + a)}(p) = e^{-i\braket{a,p}} \hat f(p)$
  2. $\widehat{e^{-i\braket{·,a}}f}(p) = \hat f(p - a)$
  3. $\widehat{f(λ ·)}(p) = \frac{1}{λ^n} \hat f(\frac{p}{λ})$
  4. $\widehat{f(-·)}(p) = \hat f(-p)$
  5. $\hat f g, f\hat g ∈ L^1$ mit
	 \[∫ \hat f g = ∫ f \hat g\]
  #+end_lemma
  #+begin_remark latex
  $\mathcal{F}: L^1(ℝ^n) \to C_b^0(ℝ^n)$
  $ℝ^1$
  \begin{align*}
  \hat f(p) &= ∫_{ℝ} e^{-ipx} f(x) \d λ(x) \qquad \hat f(p) = \widehat{\hat f(p)} \\
  \intertext{wenn $f(x) = \overline{-f(-x)}$:}
  \overline{\hat f(p)} ∫_{ℝ} e^{ipx} \overline{f(x)} \d λ(x) = - ∫ e^{-ipx} f(-x) \d λ(x)
  \end{align*}
  #+end_remark
  #+begin_lemma latex
  Sei $f ∈ C^1(ℝ^n)$ mit $\lim_{\abs{x} \to ∞} f(x) = 0$ und $f, \partial_j f ∈ L^1(ℝ^n)$ für ein $j ∈ \{1, \dots, n\}$. Dann ist
  \[\widehat{\partial_j f}(p) = i p_j \hat{f}(p) ∀ p ∈ ℝ^n\]
  Sind umgekehrt $f$ und $x \to x_j f(x)$ integrierbar, so ist $\hat f$ nach $p_j$ partiell differenzierbar und es gilt
  \[\widehat{·_j f(·)}(p) = i \partial_j \hat f (p) ∀ p ∈ ℝ^n\]
  #+end_lemma
  #+begin_proof latex
  \begin{align*}
  \string(2π\string)^{n/2} \widehat{\partial_j f}(p) &= ∫_{ℝ^n} e^{-i \braket{p,x}} \pp{f}{x_j}(x) \d λ^n(x) = -∫_{ℝ^n} \pp{e^{-i \braket{p,x}}}{x_j} f(x) \d λ^n(x) \\
  &= i p_j ∫_{ℝ^n} e^{-i \braket{p,x}} f(x) \d λ^n(x) &= (2π)^{n/2} i p_j \hat f(p) \\
  \widehat{·_j f(·)}(p)&= \frac{1}{(2π)^{n/2}} ∫_{ℝ^n} x_j f(x) e^{-i\braket{x,p}} \d λ^n (x) \\
  &= \frac{1}{(2π)^{n/2}} ∫_{ℝ^n} i \pp{e^{-i\braket{x,p}}}{p_j} f(x) \d λ^n(x) = i \pp{}{p_j} \hat f(p)
  \end{align*}
  #+end_proof
  #+begin_remark latex
  Partielle	Differenzierbarkeit gilt auch für höhere Ableitungen (Beweis induktiv) für $f ∈ C^k(ℝ^n)$
  \[\partial_{α} f:= \frac{\partial^{\abs{α}} f}{\partial_{x_1}^{α_1} \dots \partial_{x_n}^{α_n}}\]
  wobei $\abs{α} = α_1 + \dots + α_n, α ∈ (ℕ ∪ \{0\})^n$, \(α\)-Multiindex, $\abs{α} \leq k$
  #+end_remark
  #+ATTR_LATEX: :options [Schwartz-Raum]
  #+begin_defn latex
  \[S(ℝ^n) := \{f ∈ C^∞(ℝ^n) \mid ∀ α, β ∈ (ℕ ∪ \{0\})^n: \sup_{x ∈ ℝ^n} \abs{x^α (\partial_β f)(x)} < ∞\}\]
  $x^α := x_1^{α_1} x_2^{a_2} \dots x_n^{α_n}$. $f ∈ S(ℝ^n)$ heißen schnell-fallende (Schwartz) Funktion.
  #+end_defn
  #+begin_remark latex
  - $S(ℝ^n) ⊂ L^p(ℝ^n)$ für $p ∈ [1, ∞]$
  - $S(ℝ^n)$ ist dicht in $L^p(ℝ^n)$ für $p ∈ [1,∞\string)$ weil
	\[C_c^∞(ℝ^n) ⊂ S(ℝ^n)\]
	(insbesondere $S(ℝ^n) \neq \emptyset$)
  -	Mit $f ∈ S(ℝ^n)$, auch $x \to x^α f(x)$ und $\partial_α f ∈ S(ℝ^n)$
  #+end_remark
  #+begin_lemma latex
  Die Fourier-Transformation ist ein Operator
  \[\mathcal{F}: S(ℝ^n) \to S(ℝ^n)\]
  Insbesondere gilt $∀ α ∈ (ℕ_0)^n, f ∈ S(ℝ^n), p ∈ ℝ^n$.
  \[\widehat{\partial_α f}(p) = (ip)^α \hat f(p) \quad\text{und}\quad \widehat{·^α f(·)}(p) = i^{\abs{α}} \partial_α \hat f(p)\]
  #+end_lemma
  #+begin_proof latex
  Die Formeln erhält man induktiv aus Lemma 3.4. Zu zeigen $\hat f ∈ C_c^∞(ℝ)$, verwenden wir zunächst das $\hat f$ beschränkt ist (Lemma 3.2). Da mit $f ∈ S(ℝ^n)$ laut Bewerkung 3.7 auch
  $x \to \partial_{α} (x^β f(x)) ∈ S(ℝ^n)$ gilt und dessen Fourier-Transformation auch beschränkt ist, bekommen wir eine gleichmäßige Schranke aus
  \[p^α \partial_{β} \hat f(p) = i^{-\abs{β}} p^α \widehat{·^β f(·)}(p) = i^{-\abs{β} - \abs{α}} \underbrace{\partial_α (\widehat{·^β f(·)})(p)}_{\mathclap{∈ S(ℝ^n) \text{ gleichmäßig beschränkt in $p$ nach Lemma 3.2}}}\]
  $∀ α,β ∈ (ℕ_0)^n$
  #+end_proof
  #+begin_remark latex
  Das Abklingverhalten einer Funktion $f$ korrespondiert mit der Glattheit der Fourier-Transformation $\hat f$ und umgekehrt. Insbesondere verschwindet die Fourier-Transformation einer $L^1$ Funktion
  in $\pm ∞$
  #+end_remark
  #+ATTR_LATEX: :options [Riemann-Lebesgue]
  #+begin_korollar latex
  Die Fourier-Transformation bildet $L^1(ℝ^n)$ auf $C_0^0(ℝ^n)$
  \[C_0^0(ℝ^n) = \{f ∈ C^0(ℝ^n) \mid \lim_{\abs{x} \to ∞} f(x) = 0\}\]
  #+end_korollar
  #+begin_proof latex
  Sei $f ∈ C_c^∞(ℝ^n)$. Dann ist für $p ∈ ℝ$ mit $p_j \neq 0$
  \begin{align*}
  \abs*{\hat f(p)} &= \abs{\frac{1}{i p_j} \widehat{\partial_j f}(p)} \leq \frac{\norm{\partial_j f}_{L^1}}{(2π)^{n/2} \abs{p_j}} \\
  ⇒ \abs*{\hat f(p)} &\leq \min{\substack{j ∈ \{1, \dots, n\} \\ p_j \neq 0}} \frac{\norm{p_j f}_{L^1}}{(2π)^{n/2} \max \abs{p_j}} \xrightarrow{\norm{p} \to ∞} 0
  \end{align*}
  Für beliebiges $f ∈ L^1(ℝ)$ finden wir eine Folge
  \[(f_k)_{k ∈ ℕ} ⊂ C_c^∞(ℝ^n)\]
  (nach Satz 2.21)
  \begin{align*}
  \norm{f_k - f}_{L^1} \xrightarrow{k \to ∞} 0 ⇒ \abs*{\hat f(p)} &\leq \underbrace{\abs*{\hat{f_k} (p)}}_{\xrightarrow{\abs{p} \to ∞} 0} + \norm*{\hat{f_k}(p) - \hat f(p)}_{L^∞} \\
  &= \norm*{\widehat{f_k - f}}_{L^∞} \leq C \norm{f_k - f}_{L^1} \xrightarrow{k \to ∞} 0
  \end{align*}
  #+end_proof
  #+ATTR_LATEX: :options [Fourierinversion]
  #+begin_thm latex
  Die Fourier-Transformation $\mathcal{F}: L^1(ℝ^n) \to C_0^0(ℝ^n)$ iste ine invertierbare Abbildung. Die Inverse its durch
  \[f(x) = \lim_{ε \to 0} \frac{1}{(2π)^{n/2}} ∫_{ℝ^n} e^{i\braket{p,x} - ε^2 \abs{p}^2 / 2} \hat f(p) \d λ^n (p)\]
  wobei der Grenzwert bezüglich der \(L^1\)-Norm zu verstehen ist.
  #+end_thm
  #+begin_proof latex
  Wir betrachten $ϕ ∈ C^∞(ℝ^n)$,
  \[ϕ(x) = \frac{1}{(2π)^{n/2}} e^{- \frac{x^2}{2}} \quad\text{und}\quad ϕ_ε = \frac{1}{ε^n} ϕ(\frac{·}{x})\]
  $(ϕ_ε)_{ε>0}$ ist eine approximative Identität $∫ ϕ \d x = 1$
  \[\widehat{ϕ(ε ·)}(p) = \frac{1}{ε^n} \hat ϕ( \frac{p}{ε}) = \frac{1}{ε_n} ϕ(\frac{p}{ε}) = ϕ_ε(p)\]
  Wir bekommen $∀ x ∈ ℝ^n$
  \begin{align*}
  \frac{1}{(2π)^{n / 2}} ∫_{ℝ^n} e^{i \braket{x, p} - ε^2 \abs{p}^2 / 2} \hat f(p) \d λ^n (p) &= ∫_{ℝ^n} e^{i \braket{x,p}} ϕ(ε p) \hat f(p) \d λ^n (p) \\
  &= ∫_{ℝ^n} \widehat{f(· + x)}(p) ϕ(ε p) \d λ^n(p) \\
  &= ∫_{ℝ^n} f(p + x) \widehat{ϕ(ε · )}(p) \d λ^n (p) \\
  \intertext{Sei $y= - p$}
  ∫_{ℝ^n} f(x - y) \underbrace{ϕ_ε(-y)}_{= ϕ_ε(y)} \d λ^n(y) &= (f \ast ϕ_ε) (x)
  \end{align*}
  Nach Lemma 2.20 konvergiert $f \ast ϕ_ε \xrightarrow[L^1]{ε \to 0} f$
  #+end_proof
  #+begin_korollar latex
  Für $f ∈ L^1(ℝ^n)$ mit $\hat f ∈ L^1 (ℝ^n)$ gilt
  \[\string(\check{\hat{f}}\string) = f\]
  wobei
  \[\check f(p) := \hat f(-p)\]
  Also
  \[\check f(p) = \frac{1}{(2π)^{n/2}} ∫_{ℝ^n} e^{i \braket{p,x}} f(x) \d λ^n(x)\]
  $\mathcal{F}$ ist eine Bijkektion auf $F^1(ℝ^n) = \{f ∈ L^1(ℝ^n) \mid \hat f ∈ L^1(ℝ^n)\}$
  und insbesondere ist $\mathcal{F}\big|_{S(ℝ^n)}: S(ℝ^n) \to S(ℝ^n)$ eine Bijektion
  #+end_korollar
  #+begin_proof latex
  \begin{gather*}
  ϕ(ε p) \xrightarrow{ε \to 0} \frac{1}{(2π)^{n/2}} ∀ p ∈ ℝ^n \\
  ⇒ \abs{e^{i \braket{p,x}} ϕ(ε p) \hat f(p)} \leq \frac{\abs*{\hat f(p)}}{(2π)^{n/2}}
  \end{gather*}
  Dies leifert eine integrierbare Majorante für die Formel aus Satz 3.10 $⇒$ wir dürfen in der Formel Genzwert und Integral vertauschen. Die punktweise Konvergenz folgt zunächst aus Konvergenz
  einer Teilfolge ($L^p$ Konvergenz $⇒$ punktweise Konvergenz) und dann unabhängig von Teilfolge aus Teilfolgenprinzip
  \[⇒ \string(\check{\hat f}\string) = f\]
  #+end_proof
  #+ATTR_LATEX: :options [Plancherel Identiät]
  #+begin_lemma latex
  Sei $f ∈ F^1(ℝ^n)$. Dann ist $f, \hat f ∈ L^2(ℝ^n)$ und
  \[\norm{f}^2_{L^2} = \norm*{\hat f}_{L^2}^2 \leq (2π)^{- n/2} \norm{f}_{L^1} \norm*{\hat f}_{L^1}\]
  #+end_lemma
  #+begin_proof latex
  \begin{align*}
  ∫_{ℝ^n} \abs*{\hat f(p)}^2 \d λ^n(p) &= \frac{1}{(2π)^{n/2}} ∫_{ℝ^n} ∫_{ℝ^n} f(x) e^{-i \braket{p,x}} \overline{\hat f(p)} \d λ^n(x) \d λ^n(p) \\
  &\underarrow[=]{Fubini} \frac{1}{(2π)^{n/2}} ∫_{ℝ^n} f(x) \underbrace{∫_{ℝ^n} \overline{e^{i\braket{p,x}} \hat f(p)} \d λ^n(p)}_{= (2π)^{n/2} \overline{\string(\check{\hat f}\string)} = (2π)^{n/2} \overline{f(x)}} \d λ^n(x) \\
  &= ∫_{ℝ^n} f(x) \overline{f(x)} \d λ^n(x) = ∫_{ℝ^n} \abs{f(x)}^2 \d λ^n(x) \\
  \intertext{Insbesondere:}
  \norm*{\hat f}_{L^2}^2 &\leq \frac{1}{(2π)^{n/2}} ∫_{ℝ^n} \abs{f(x)} \d λ^n(x) ∫_{ℝ^n} \underbrace{\abs{e^{i\braket{p,x}}}}_{=1} \abs*{\hat f(p)} \d λ^n(p) = \frac{1}{(2π)^{n/2}} \norm{f}_{L^1} \norm*{\hat f}_{L^1}
  \end{align*}
  #+end_proof
  *Fortsetzbarkeit auf $L^2$*
  #+ATTR_LATEX: :options [Fortsetzung linearer Abbildungen]
  #+begin_thm latex
  Sei $X$ ein normierter Raum mit dichter Teilmenge $U$ und $Y$ ein Banachraum. Ist $A: O \to Y$ eine lineare und beschränkte Abbildung, das heißt $∃ C_A > 0:$
  \[\norm{A(x)}_Y \leq C_A \norm{x}_X ∀ x ∈ O\]
  so gibt es genau eine Fortsetzung $\tilde A$, das heißt eine lineare und beschränkte Abbildung $\tilde A: X \to Y$ mit $\tilde A\big|_O = A$ und dem selben $C_A ∀ x ∈ X$.
  #+end_thm
  #+begin_proof latex
  Sei $(X_k)_{k ∈ ℕ} ⊂ O$ eine Cauchy-Folge. Dann ist $(A x_k)_{k ∈ ℕ} ⊂ Y$ eine Cauchy-Folge in $Y$, weil
  \[\norm{A x_j - A x_k}_Y= \norm{A(x_j - x_k)}_Y \leq C_A \underbrace{\norm{x_j - x_k}_X}_{\to 0} \to 0\]
  und diese besitzt einen eindeutigen Grenzwert.
  \[\tilde A x_0 := \lim_{k \to ∞} A x_k \quad\text{sofern}\quad x_0 := \lim_{k \to ∞} x_k \text{ existiert}\]
  Damit ist $\tilde A: X \to Y$ eindeutig gegeben, denn für Folgen $(x_k)_{k ∈ ℕ}, (y_k)_{k ∈ ℕ} ⊂ U$ mit $x_k \xrightarrow{k \to ∞} x_0, y_k \rightarrow{k \to ∞} x_0$
  \[\norm{A x_k - A y_k}_Y = \norm{A(x_k - y_k)}_Y \leq C_A \norm{x_k - x_0} + C_A \norm{y_k - k_0} \xrightarrow{k \to ∞} 0\]
  Linearität von $\tilde A$ bekommen wir aus der Stetigkeit von Vektoraddition und skalarer Multiplikation. Stetigkeit der Normen liefert die Behauptung.
  #+end_proof
  #+ATTR_LATEX: :options [Plancherel]
  #+begin_thm latex
  Die Fourier Transformation $\mathcal{F}$ lässt sich zu einer beschränkten Abbildung $\mathcal{F}:L^2(ℝ^n) \to L^2(ℝ^n)$ fortsetzen, die unitär ist, das heißt $\braket{\tilde{\mathcal{F}}(f), \tilde{\mathcal{F}}(g)}_{L^2} = \braket{f,g}_{L^2} ∀ f,g ∈ L^2(ℝ^n)$
  #+end_thm
  #+begin_proof latex
  Nach Satz 2.31 liegt $C_c^∞(ℝ^n) ⊂ S(ℝ^n)$ dicht in $L^2(ℝ^n)$. Nach Korollar 3.11 ist $\mathcal{F}$ eine lineare bijektive Selbstabbildung des $S(ℝ^n) ⊂ F^1(ℝ^n) ⇒$ Beschränktheit aus der Plancherel Identität.
  Nach Satz 3.13 existiert eine eindeutige Fortsetzung $\tilde{\mathcal{F}}: L^2(ℝ^n) \to L^2(ℝ^n)$ mit
  \[\norm*{\tilde{\mathcal{F}}(f)}_{L^2} \leq \norm{f}_{L^2}\]
  $\tilde{\mathcal{F}}$ ist unitär nach Lemma 3.12, weil $∀ f,g ∈ L^2(ℝ^n)$
  \begin{align*}
  4 \braket{f,g}_{L^2} &= 4 ∫_{ℝ^n} f(x) \overline{g(x)} \d λ^n(x) \\
  &= \norm{f + g}_{L^2}^2 - \norm{f - g}_{L^2}^2 + i \norm{f - ig}_{L^2}^2 - i \norm{f + ig}_{L^2}^2 \\
  &= 4 \braket{\tilde{\mathcal{F}}(f), \tilde{\mathcal{F}}(g)}_{L^2}
  \end{align*}
  #+end_proof
  #+begin_remark latex
  Solange der Integrand von $\hat f$ in $L^1(ℝ^n)$ liegt lässt sich $\tilde{\mathcal{F}}(f)$ direkt mit der Formel aus Definition 3.1 ausdrücken. In der Regel lässt sich $\tilde{\mathcal{F}}$ für $f ∈ L^2(ℝ^n)$
  nur als Grenzwert einer Folge \(\hat f_k, (f_k)_{k ∈ ℕ} ⊂ S(ℝ^n), f_k \xrightarrow{k \to ∞}[\text{in $L^2$}]\) darstellen.
  #+end_remark
  #+ATTR_LATEX: :options [3.15]
  #+begin_lemma latex
  Es gilt
  \[\norm*{\tilde{\mathcal{F}}(f)}_{L^∞} \leq (2π)^{-n/2} \norm{f}_{L^1} ∀ f ∈ L^1 ∩ L^2\]
  #+end_lemma
  #+begin_proof latex
  Sofern $f ∈ L^1_c(ℝ^n)$, folgt $f ∈ L^2(ℝ^n)$ und nach Lemma 2.20 $f \ast ϕ_ε$ konvergiert für eine geeignetes $ϕ$ in $C_c^∞(ℝ^n)$ ($f \ast ϕ_ε ∈ C_c^∞(ℝ^n) ⊂ S(ℝ^n)$)
  bezüglich $L^1$ und $L^2$ Norm gegen $f$.
  \[\norm{f \ast ϕ_ε -  f}_{L^2} \to 0\]
  Die Abschätzung gilt für $f \ast ϕ_ε$ nach Lemma 3.2. Die Behauptung folgt für $ε \searrow 0$ aus Stetigkeit der Norm. Für allgemeine $f ∈ L^1(ℝ^n) ∩ L^2(ℝ^n)$ betrachten wir $f_R = f χ_{B_R(0)}$.
  Dann $f_R \nearrow f$ in $L^1$ und $L^2$ (dominierte Konvergenz) und wir erhalten die Behauptung durch Approximation.
  #+end_proof
  #+begin_remark latex
  Insbesondere gilt für $f ∈ L^2(ℝ^n)$ ($⇒ f_R ∈ L^2$)
  \[\tilde{\mathcal{F}}(f)(p) = \lim_{R \nearrow ∞} \frac{1}{(2π)^{n/2}} ∫_{B_R(0)} e^{-i \braket{p,x}} f(x) \d λ^n(x)\]
  (wobei der Grenzwert bezüglich \(L^2\)-Norm zu verstehen ist)
  #+end_remark
* Differenzierbare Mannigfaltigkeiten
** Implizite Funktionen und Untermannigfaltigkeiten
   #+begin_defn latex
   1. Seien $X, Y$ topologische Räume. Eine stetige Funktion $f:X \to Y$ die bijektiv ist und deren Inverse ebenfalls stetig ist, heißt Homöomporphismus.
   2. Seien $X, Y$ normierte Räume. EIn Homöomorphismus $f: X \to Y$ heißt (\(C^1\)-)Diffeomorphismus, wenn $f ∈ C^1(X, Y)$ und $f^{-1} ∈ C^1(Y, X)$. Entsprechend \(C^k\)-Diffeomorphismus falls
   	 $f, f^{-1} ∈ C^k$
   #+end_defn
   #+ATTR_LATEX: :options [Umkehrsatz]
   #+begin_thm latex
   Sei $Ω ⊂ ℝ^n$ eine nichtleere, offene Menge und $f ∈ C^1(Ω, ℝ^n)$. Dann ist die Invertierbarkeit der Jacobimatrix $D f(ξ)$ in $ξ ∈ Ω$ äquivalent zur Existienz einer *lokalen* \(C^1\)-Umkehrfunktion
   von $f$ in der Umgebung von $f(ξ)$. Genauer, gibt es eine offene Teilmenge $O ⊂ Ω, W ⊂ ℝ^n$ mit $ξ ∈ O$ und $f(ξ) ∈ W$ sodass $f\big|_{O}$ ein Diffeomorphismus $O \to W$ ist. Insbesondere gilt
   \[(D(f\big|_{O})^{-1})(f(x)) = (D f(x))^{-1} ∀ x ∈ O\]
   #+end_thm
   #+begin_proof latex
   Analysis 2
   #+end_proof
   #+ATTR_LATEX: :options [Globaler Umkehrsatz]
   #+begin_korollar latex
   Sei $Ω ⊂ ℝ^n$ offen und nichtleer, $f ∈ C^1(Ω, ℝ^n)$. Ist die Jacobimatrix $D f(x) ∀ x ∈ Ω$ invertierbar und ist $f$ injektiv, so liefert $f$ einen
   Diffeomorphismus $Ω \to W = \im f ⊂ ℝ^n$. Insbesondere ist $W$ offen und die Idetität aus Satz 4.2 gilt $∀ x ∈ Ω$
   #+end_korollar
   #+begin_proof latex
   Nach Vorraussetzung und $f:Ω \to W$ bijektiv und und $C^1$. Satz 4.2 impliziert, dann $D f(x) ∀ x ∈ Ω$ invertierbar und dass $f^{-1}$ in jedem Punkt
   \[y = f(f^{-1}(y)) = W\]
   stetig differenzierbar ist.
   #+end_proof
   #+begin_remark latex
   Wir können die Sphere
   \[\mathbb{S} = \{(x_1, x_2, x_3) \mid x_1^2 + x_2^x + x_3^2= 1\}\]
   mit $x_3 > 0$ als Graph die Funktion
   \[x_3 = g(x_1, x_2) = \sqrt{1 - x_1^2-  x_2^2} \quad (x_1, x_2) ∈ B_1(0) ∈ ℝ^2\]
   darstellen. \\
   Allgemein möchten wir eine (Hyper-) Fläche der Form
   \[M = \{(x, y) ∈ ℝ^{k + m} \mid f(x, y) = 0\}\]
   lokal als Graph einer Funktion $x \to g(x) ∈ ℝ^m$ schreiben ($(x, g(x)) ∈ M$)
   #+end_remark
   #+ATTR_LATEX: :options [Implizite Funktionen Satz]
   #+begin_thm latex
   Seien $k, m ∈ ℕ, Ω ⊂ ℝ^{k + m}$ eine offene Menge und $f ∈ C^1(Ω, ℝ^m)$. Es gibt ein $(ξ, η) ∈ Ω$ und $f(ξ, η) = 0$ und $D_y f(ξ, η) \neq 0$, wobei
   \[D_y f(x, y) = (\pp{f_j}{y_i} (x, y))_{j,l = 1, \dots, m}\]
   Dann gibt es offene Umgebungen $U ⊂ ℝ^n$ von $ξ$, und $V ⊂ ℝ^m$ von $η$ und ein $ϕ ∈ C^1(U, V)$ mit
   \[\{(x, y) ∈ U × V \mid f(x, y) = 0\} = \{(x, ϕ(x)), x ∈ M\}\]
   und
   \[D ϕ(x) = -(D_y f(x, ϕ(x)))^{-1} D_x f(x, ϕ(x)) \quad x ∈ U\]
   #+end_thm
   #+begin_proof latex
   Analysis 2
   #+end_proof
   #+ATTR_LATEX: :options [Immersion]
   #+begin_defn latex
   Seien $Ω ⊂ ℝ^n$ nichtleer und offen, $ϕ ∈ C^1(Ω, ℝ^m), m \geq n$. Die Abbildung $ϕ$ heißt Immersion, falls der Rand von $Dϕ(x) ∀ x ∈ Ω$ maximal ist
   (Alternativ: $D ϕ(x): ℝ^n \to ℝ^m$ linear und injektiv)
   #+end_defn
   #+ATTR_LATEX: :options [Untermannigfaltigkeit]
   #+begin_defn latex
   Seien $m, n ∈ ℕ ∪ \{0\}, m \leq n$. Eine \(C^1\)-Untermannigfaltigkeit mit der Dimension $m$ ist eine nichtleere Menge $M ⊂ ℝ^n$ mit der folgenden Eigenschaft:
   $∀ ξ ∈ M ∃$ eine offene Umgebung $Ω ⊂ ℝ^n$ von $ξ ∈ Ω$ eine offene Menge $U ⊂ ℝ^m$ und eine Immersion $ϕ ∈ C^1(U, ℝ^n)$ die $U$ homöomorph auf $\im ϕ = M ∩ Ω$ abbildet.
   Die Abbildung $ϕ$ heißt (lokale) Parametrisierung von $M$ und $ξ$, ihre Umkehrung $ϕ^{1}: M ∩ Ω \to U$ beziehungsweise das Paar $(ϕ^{-1}, U)$ heißt Karte und eine Familie von Karten deren Urbild ganz $M$ überdecken bildet einen Atlas.
   #+end_defn
   #+begin_remark latex
   Die Dimensionei ner Untermannigfaltigkeit ist wohldefiniert. Eine nichtleere Teilmenge des $ℝ^n$ sti genau dann ein \(m\)-dimensionale Untermannigfaltigkeit, wenn  sie offen ist.
   Jede abzählbare nichtleere Menge von Punkten in $ℝ^n$ ohne Häufingspungkt ist dann eine \(0\)-dimensionale Untermannigfaltigkeit.
   #+end_remark
   #+begin_notation latex
   Sei $X$ eine endlich-dimensionaler Vektorraum mit innerem	Produkt $\braket{·,·}$. Wir definieren das orthogonale Komplement eines Untervektorraums $V ⊂ X$
   \[V^{\perp} = \{x ∈ V \mid \braket{x, v} = 0 ∀ v ∈ V\}\]
   Es gilt
   \[V \oplus V^{\perp} = X\]
   Ist $Y$ ein weiterer endlichdimensionaler Vektorraum und $A: X \to Y$ linear, dann
   \[\ker A = \{x ∈ X \mid A x = 0\} ⊂ X \qquad \im A = \{A x \mid x = X\} ⊂ Y\]
   #+end_notation
   #+begin_thm latex
   Für $m, n ∈ ℕ, m \leq n$ und eine nichtleere Menge $M ⊂ ℝ^n$ sind die folgenden Aussagen äquivalent:
   1. (Untermannig) $∀ ξ ∈ M ∃$ offene Menge $Ω ⊂ ℝ^n$ von $ξ$, eine Menge $U ⊂ ℝ^n$ und Immersion $ϕ ∈ C^1(U, ℝ^n)$, die $U$ homöomorph auf $M ∩ Ω = ϕ(U)$ abbildet.
   2. (Gleichungsdefinierte Mannigfaltigkeit) $∀ ξ ∈ M ∃$ Umgebung $U ⊂ ℝ^n$ von $ξ$ und eine Abbildung $f ∈ C^1(Ω, ℝ^{n - m})$ mit $\Rang D f(x) = n - m ∀ x ∈ Ω$ und $M ∩ W = f^{-1}(\{0\})$
   3. (Graphendarstellung) Zu jedem $ξ ∈ M$ gibt es eine offene Umgebung $Ω ⊂ ℝ^n$ von $ξ$, eine offene Menge $U ⊂ ℝ^m$ und ein $g ∈ C^1(U, ℝ^{n - m})$ mit
   	 \[M ∩ W = π(\Graph g)\]
   	 wobei $π ∈ \GL(n)$ eine Permutationsmatrix ist.
   #+end_thm
   #+begin_proof latex
   1. $⇒$ 2.: Wir konstruieren eine Funktion $f$ mithilfe des Umkehrsatzes. Sei also $M$ eine \(m\)-dimensionale Untermannigfaltigkeit des $ℝ^n$ wie in 1. und
   	 $η = ϕ^{-1}(ξ) ∈ U$. Da $ϕ$ eine Immersion ist, besitzt $Dϕ(η)$ eine vollen Rang und die Spalten von
   	 $D ϕ$ spannen eine linearen Unterraum $T$ auf. Mit $P_T$ bezeichnen wir die orthogonale Projektion $ℝ^n \to T ⊂ ℝ^n$. Weiterhin setzen wir
   	 $ϕ_T := P_T \circ ϕ: U \to T ⊂ ℝ^n$. Insbesondere gilt $\Rang ϕ_T = m$, denn
   	 \[D ϕ_T = D(P_T \circ ϕ) = \underbrace{((D P_T) \circ ϕ)}_{= P_T} D ϕ\]
   	 Entsprechend ist
   	 \[D ϕ_T(ℝ^n) = P_T \underbrace{Dϕ(R^n)}_{=T} = T\]
   	 Nach einem Koordinatenwechsel können wir $T = R^m × \{0\}$ annehmen und setzen außerdem $N = \{0\} × ℝ^{n - m}$ und $ϕ_N = P_N \circ ϕ: U \to N$, wobei $P_N$
   	 die orthogonale Projektion auf $N$ bezeichnet. Der Umkehrsatz liefert nun eine offene Umgebung $\tilde U ⊂ U$ von $η$, sodass
   	 \[ϕ_T \big|_{\tilde U}: \tilde U \to ϕ_T(\tilde U) =: \tilde V\]
   	 ein Diffeomorphismus ist. Insbesondere gibt es eine inverse Abbildung
   	 \[ψ := (ϕ_T \big|_{\tilde U})^{-1} ∈ C^1(\tilde V, \tilde U)\]
   	 Wir wählen $\tilde Ω ⊂ Ω$ mit $ξ ∈ Ω$ und $ϕ^{-1}(\tilde Ω ∩ M) ⊂ \tilde U$. Weiter setzen wir
   	 $Ω^{\ast} = (\tilde V \oplus N) ∩ \tilde Ω ⊂ Ω$, das heißt für jedes $x ∈ Ω^{\ast}$ gibt es eine Zerlegung $x = x_T + x_N$ wobei $x_T ∈ \tilde V ⊂ T$ und
   	 $x_N ∈ N$. Mit
   	 \[f(x) = f(x_T + x_N) = x_N - ϕ_N(ψ(x_T))\]
   	 erhalten wir eine Abbildung $f ∈ C^1(Ω^{\ast}, N)$. Aus $D_N f = \mathcal{1}_{n - m}$ erhalten
   	 wir $\Rang D ψ(x) = \dim N = n - m ∀ x ∈ Ω^{\ast}$. Somit bleibt $Ω^{\ast} ∩ M = \{x ∈ Ω^{\ast} | f(x) = 0\}$ zu zeigen.
   	 Sei hierzu $x ∈ Ω^{\ast}$, das heißt $x ∈ \tilde Ω$ mit $x = x_T + x_N, x_T ∈ \tilde V ⊂ T, x_N ∈ N$. Nun setzen wir $u = ψ(x_T) ∈ \tilde U$, also
   	 $x_T = ϕ_T(u)$. Wir haben $f(x) = 0 ⇔ x_N = ϕ_N(u) ⇔ x = ϕ(u) ∈ M ∩ Ω$.
   2. $⇒$ 3.: Sei $M$ eine gleichungsdefinierte Mannigfaltigkeit. Zu $x ∈ M$ wählen wir $Ω$ und $f$ aus 2. Nach Umnummerierung der Koordinaten
   	 (was auf die Permutationsmatrix $π$ führt) erhalten wir $D_z f(ξ) ∈ \GL(n - m)$, wobei $x = (y, z) ∈ ℝ^m × ℝ^{n - m}$.
   	 Aus dem Satz über implizite Funktionen gewinnen wir eine offene Umgebung $U × V ⊂ ℝ^m × ℝ^{n - m}$ von $ξ = (η, ζ)$ und eine Funktion $g ∈ C^1(U, V)$ mit
   	 \[\Graph g = \{(y, z) ∈ U × V | f(y, z) = 0\} = M ∩ (U × V)\]
   3. $⇒$ 1.: Unter den Voraussetzungen von 3. erhalten wir mit $ϕ: y ↦ π(y,g(y))$ eine Abbildung
   	 aus $C^1(U, ℝ^n)$. Folgilch ist $ϕ(U) = M ∩ Ω$ und es bleibt zu zeigen, dass $ϕ$ eine Immersion ist und einen Homöomorphismus liefert.
   	 Aus der Definition liest man unmittelbar die Injektivität von $ϕ$ sowie $\Rang Dϕ = m$ ab.
   	 Nach Vorraussetzung ist $ϕ$ stetig und die Stetigkeit von $ϕ^{-1}$ sieht man wie folgt:
   	 Eine konvergente Folge in $\im ϕ$ lässt sich durch eine Folge $(y_k)_{k ∈ ℕ} ⊂ U$ mit
   	 \[ϕ(y_k) = π(y_k, g(k_y)) \to w ∈ \im ϕ ⊂ ℝ^n\]
   	 darstellen. Mit $(y, z) = π^{-1}(w)$ ergibt sich $(y_k, g(y_k)) \to (y, z)$ und insbesondere $y_k \to y$.
   	 Somit ist $M$ eine Mannigfaltigkeit.
   #+end_proof
   #+ATTR_LATEX: :options [Tangentialraum und Normalraum]
   #+begin_defn latex
   Sei $M ⊂ ℝ^n$ eine \(m\)-dimensionale Mannigfaltigkeit und $ξ ∈ M$. Ein Vektor $v ∈ ℝ^n$ heißt
   *Tangentialvektor* an $M$ im Punkt $ξ$, falls es eine Kurve $γ ∈ C^1((-ε, ε), M), ε > 0$ mit $γ(0) = ξ, ξ'(0) = v$ gibt.
   Die Menge aller Tangetialvektoren wird *Tangentialraum* an $M$ im Punkt $ξ ∈ M$ genannt und mit $T_ξ M$ bezeichnet.
   Der Normalraum an $M$ in $ξ$ ist das orthogonale Komplement $N_ξ M = (T_ξ M)^{\perp}$
   #+end_defn
   #+begin_thm latex
   Sei $M ⊂ r^n$ eine \(m\)-dimensionale Mannigfaltigkeit, $ξ ∈ M, m \leq n$. Sei $ϕ ∈ C^1(U, ℝ^n)$ eine
   lokale Parametrisierung von $M$ um $ξ$ mit $ϕ(0) = ξ$ und sei $f$ wie in Satz 4.6.2. Dann gilt
   \begin{align*}
   T_ξ M &= \im D ϕ(0) = \ker D f(ξ) \\
   N_ξ M &= (\im D ϕ(0))^{\perp} = \Lin(∇ f_1(ξ), \dots, ∇ f_{n - m}(ξ))
   \end{align*}
   Insbesondere ist $T_ξ M$ wirklich ein Vektorraum und wir haben
   \begin{align*}
   \dim T_ξ M &= m \\
   \dim N_ξ M &= n - m
   \end{align*}
   #+end_thm
   #+begin_proof latex
   Wir können ohne Beschränkung der Allgemeinheit $ϕ(0) = ξ$ annehmen. Wir zeigen zunächst $\im D ϕ(0) ⊂ T_ξ M$.
   Für $w ∈ \im D ϕ(0)$ gibt es ein $u ∈ ℝ^m$ mit $w = D ϕ(0) u$. Für $γ(t) = ϕ(t u)$ gilt $γ(0) = ϕ(0) = ξ$ und $γ'(0) = D ϕ(0)u = w$.
   Damit ist $w ∈ T_ξ M$. Weiterhin ist $T_ξ M ⊂ \ker D f(ξ)$. Sei hierzu $v ∈ T_ξ M$. Definitionsgemäß gibt es eine Kurve $γ: (-ε, ε) \to M$ mit $γ(0) = ξ$
   und $γ'(0) = v$. Wir können $ε > 0$ so klein wählen, dass $\im γ$ in $M ∩ Ω$ enthalten ist, wobei $Ω$ die in Satz	4.6.2 angegebene offene Menge bezeichnet.
   Wegen $\im γ ⊂ M$ gilt insbesondere $f \circ γ \equiv 0$, also
   \[0 = (f \circ γ)'(0) = D f(γ(0)) γ'(0) = D f(ξ) v\]
   folglich ist $v ∈ \ker D f(ξ)$. Damit haben wir insgesamt:
   \[\im D ϕ(0) ⊂ T_ξ M ⊂ \ker D f(ξ)\]
   Wegen $\dim \im D ϕ(0) = \Rang D ϕ(0) = m$ und
   \[\dim \ker D f(ξ) = n - \Rang D f(ξ) = n - (n - m) = m\]
   folgt die behauptete Identität. Insbesondere ist $T_ξ M$ ein \(m\)-dimensionaler Vektorraum. Wir erhalten nach Definition
   $N_ξ M = (T_ξ M)^{\perp} = (\im D ϕ(0))^{\perp}$. Sei nun $w = ∇ f_j (ξ)$ für $j = 1, \dots, n - m$ und $v ∈ T_ξ M$. Wir erhalten
   \[\braket{w, v} = \sum_{k = 1}^n \pp{f_j}{x_k}(ξ) v_k = (D f(ξ) v)_j = 0\]
   da $T_ξ M = \ker D f(ξ)$. Nun folgt $w \perp  T_ξ M$, also $w ∈ N_ξ M$ und mithin
   \[\Lin(∇ f_i(ξ), \dots, ∇ f_{n - m}(ξ)) ⊂ N_ξ M\]
   Wegen $\Rang D f(ξ) = n - m$ handelt es sich bei beiden Mengen um Vektorräume der Dimension $n - m$ und diese sind folglich gleich.
   #+end_proof
   #+ATTR_LATEX: :options [Tangetialebene]
   #+begin_thm latex
   Für jeden Punkt $ξ$ einer Mannigfaltigkeit $M$ ist mit $Ξ = ξ + T_ξ M$
   \[\frac{1}{r} \sup \{\dist(x, Ξ) | x ∈ M ∩ B_r(ξ)\} \xrightarrow{x \searrow 0} 0\]
   #+end_thm
   *Motivationsfragen*:
   - Was ist oben und was ist unten? (Orientierbarkeit)
   -	Wie sieht es mit Rändern aus, wann sind sie "glatt", wass sind sie selbst Mannigfaltigkeiten
** Integration auf Mannigfaltigkeiten
   Ziel: Verallgemeinerung des Lebesgue-Integrals auf Mannigfaltigkeiten. \\
   Strategie:
   1. Nach Definition können wir uns eine Mannigfaltigkeit $M$ lokal mit einer Immersion $φ: U ⊂ ℝ^n \to ℝ^n$ parametrisieren - also betrachten wir zunächst Stücke von
	  Mannigfaltigkeiten.
   2. Eine "beliebige" Mannigfaltigkeit zerlegen wir in endlich viele überlappende Teilstücke mit lokalen Parametrisierungen (wir setzen also voraus, dass $M$ einen endlichen Atlas besitzt).
	  Der Wert des Integrals ist unabhängig vom gewählten Atlas. Wichtigstes Hilfsmittel: Partition der Eins.
  Zunächst der lineare Fall. Für eine lineare  abbildung $T: ℝ^m \to ℝ^n, n \geq m$ und eine messbare Menge $U ⊂ ℝ^m$ möchten mir den "\(m\)-dimensionalen Flächeninhalt" von $T(U)$ angeben.
  Wir erwarten, dass der "\(n\)-dimensionale Flächeninhalt" von $T(U)$ im Fall $m \geq n$ Null beträgt.
  #+begin_lemma latex
  Sei $T ∈ ℝ^{n × m}$ (charaktisiert lineare Abbildung $(ℝ^m \to ℝ^n)$) mit Rang $m, n \geq m$. Dann gibt es $Q ∈ ℝ^{n × m}$ und $S ∈ ℝ^{m × m}$ mit $T = Q S$, wobei $Q$
  eine Isometrie ist, das heißt
  \[\abs{Q v}= \abs{v} ∀ v ∈ ℝ\]
  und $\abs{\det S} = \sqrt{T^T T}$
  #+end_lemma
  #+begin_proof latex
  Mit $e_1, \dots, e_m$ bezeichnen wir die Standard-Einheitsbasis des $ℝ^m$. Weiter wählen wir eine Orthonormalbasis $\{f_1, \dots, f_n\}$ des $R^n$ mit $T(ℝ^m) = \Lin\{f_1, \dots, f_m\}$.
  Nun können wir $Q ∈ ℝ^{n × m}$ durch $Q e_j = f_j, j = 1,\dots,m$ eindeutig definieren und für
  \[v = \sum_{j = 1}^m v_j e_j, w = \sum_{k = 1}^m w_k e_k\]
  erhalten wir
  \[\braket{Q v, Q w} = \sum_{j,k} v_j v_k δ_{jk} = \sum_{j = 1}^m v_j w_j = \braket{v, w}\]
  also $\abs{Q v} = \abs{v} ∀ v ∈ ℝ^m$ und
  \[\braket{Q^T Q v, w} = w^T Q^T Q v = (Q w)^T Q v = \braket{Q v, Q w} = \braket{v, w}\]
  woraus $Q^T Q = \id$ ersichtlich ist. Nach Konstruktion ist $Q$ auf $T(ℝ^m)$ invertierbar, somit $S = Q^{-1} T ∈ ℝ^{m × n}$ wohldefiniert, und $\Rang S = m$. Wir haben $Q S = T$ und
  \begin{align*}
  \det(T^T T) &=	\det((Q S)^T Q S) = \det(S^T Q^T Q S) = \det(S^T S) \\
  &= \det(S) \det(S^T) = \abs{\det S}^2
  \end{align*}
  #+end_proof
  Wir möchten einen Flächeninhalt definieren, der invariant unter Isometrien (Translation, Rotation, Spiegelung) ist. Insofern sollte der Flächeninhalt von $T(U)$
  mit dem von $Q^{-1} T(U) = S(U)$ übereinstimmen. Wegen $S(U) ⊂ ℝ^m$ können wir das \(m\)-dimensionale Lebesgue-Maß verwenden und erhallten:
  \[λ^m(S(U)) = ∫_{S(U)} \mathbb{1} \d λ^m = \abs{\det S} ∫_U \mathbb{1} \d λ^m = \sqrt{\det(T^T T)} λ^m(U)\]

  #+ATTR_LATEX: :options [Integral auf lokaler Parametrisierung]
  #+begin_defn latex
  Seien $m,n ∈ ℕ, m \leq n, U ⊂ ℝ^n$ offen, $φ ∈ C^1(U, ℝ^n)$ eine Immersion, die $U$ homöomphr auf $\im φ$ abbildet. Der Flächeninhalt von von $\im φ$ definieren wir durch
  \[\vol^m(\im φ) = ∫_U \sqrt{\det((Dφ)^T (Dφ))} \d λ^m\]
  wobei $\det((Dφ)^T (Dφ))$ als Gram-Determinante bezeichnet wird.

  Eine Funktion $f:\im φ \to ℝ$ heißt *integrierbar*, falls
  \[(f \circ φ) \sqrt{\det((Dφ)^T(Dφ))}\]
  auf $U$ integrierbar ist.
  \[∫_{\im φ} f \underarrow[\d A^m]{Flächeninhalt} := ∫_U (f \circ φ) \sqrt{\det((Dφ)^T(Dφ))} \d λ^m\]
  #+end_defn
  #+begin_remark latex
  Falls $m = n$
  \[∫_U f \d A^n = ∫ f \d λ^n\]
  #+end_remark
  #+ATTR_LATEX: :options [Wohldefiniertheit des Flächeninhalts]
  #+begin_lemma latex
  Seien $n, m . N, m \leq n, U_1, U_2 . ℝ^m$ offen, $φ_1 ∈ C^1(U_1, ℝ^n), φ_2 ∈ C^1(U_2, ℝ^n)$ Immersionen, die $U_1$ (beziehungsweise $U_2$) homöomorph auf eine Menge $W ⊂ ℝ^n$ abbilden.
  $f: W \to ℝ$ messbar. Dann ist
  \[(f \circ φ_1) \sqrt{\det((Dφ_1)^F(Dφ_1))}\]
  integrierbar genau dann wenn
  \[(f \circ φ_2) \sqrt{\det((Dφ_2)^F(Dφ_2))}\]
  integrierbar ist und
  \[∫_{U_1} (f\circ φ_1) \sqrt{\det((Dφ_1)^T(D φ_1))} \d λ^m = ∫_{U_2} (f\circ φ_2) \sqrt{\det((D φ_2)^T (D φ_2))} \d λ^m\]
  #+end_lemma
  #+begin_proof latex
  Wir setzen $ψ = φ_1^{-1} \circ φ_2: U_2 \to U_1$. Zu zeigen: $ψ$ ist ein Diffeomorphismus. Dann mit Transformationssatz folgt
  \[∫_{U_1} (f\circ φ_1) \sqrt{\det((Dφ_1)^T(D φ_1))} \d λ^m = ∫_{U_2} (f\circ φ_2) \sqrt{\det((D φ_2)^T (D φ_2))} \abs{\det Dψ} \d λ^m\]
  Es gilt
  \begin{align*}
  D φ_2 &= D(φ_1 \circ ψ) = (Dφ_1 \circ ψ) D ψ \\
  ⇒ \det((Dφ_2)^T D φ_2) &= \det((Dψ)^T(Dφ_1\circ ψ)^T(Dφ_1 \circ ψ)(Dψ)) \\
  &= \det(Dψ) \det((Dφ_1 \circ ψ)^T (Dφ_1 \circ h)) \det(Dψ) \\
  &= (\det(Dψ))^2 \det((Dφ_1 \circ ψ)^T (D φ_1 \circ ψ))
  \end{align*}
  $ψ$ ist ein Diffeomorphismus, weil:
  - $ψ$ ist Homöomorph (als Verkettung von Homöomorphismen)
  Wir nehmen ein $u_2 ∈ U_2$ und $x := φ_2(u_2), u_1 :t φ_1^{-1}(x) = ψ(u_2)$. Mit $P: ℝ^n \to T_x W \simeq ℝ^m$ (Projection
  \begin{align*}
  D(P \circ φ_1)(u_1) &= D P(\underbrace{φ(u_1)}_{= x}) D φ_1(u_1) = P(Dφ_1(u_1)) \underarrow[=]{Die Spalten von $D φ_1(u_1)$ spannen $T_x W$} D φ_1(u_1)
  \end{align*})
  Insbesondere
  \[\Rang D(P \circ φ_1)(u_1) = \Rang D φ_1(u_1) = m\]
  Aus dem Umkehrsatz ist $P \circ φ_1$ invertierbar in einer Umgebung $\tilde U_1 \supset u_1$ $⇒ ∃ \tilde U_1 ⊂ ℝ^m, \tilde W ⊂ T x W$ mit $u_1 ∈ \tilde U_1$ und $g . C^1(\tilde W, \tilde U_1)$ sodass
  $g \circ P \circ \id_{\tilde U_1}$. Wir setzen $\tilde U_2 = φ_2^{-1}(\tilde W)$
  \[⇒ ω = φ_1^{-1} \circ φ_2 = g \circ P \circ φ_2\]
  auf $\tilde U_2, ψ ∈ C^1(\tilde U_2, ℝ^m)$. Weil die Konstruktion für beliebige $u_2$ gilt $⇒ ψ ∈ C^1(U_2, ℝ^m)$
  #+end_proof
  #+ATTR_LATEX: :options [Partition der Eins]
  #+begin_defn latex
  Gegeben sei eine Überdeckung der Mannigfaltigkeit $M ⊂ ℝ^n$ durch Mengen $W_1, \dots, W_l$, das heißt
  \[M = \bigcup_{j = 1}^l W_j\]
  Eine Familie $(α_j)_{j = 1, \dots, l}$ messbarer FUnktionen $α_i: M \to ℝ$ heißt eine der Überdeckung $(W_j)_{j = 1, \dots, l}$ untergeordnete Partition der Eins, wenn
  1. $\im α_j ⊂ [0,1]$ für $j = 1, \dots, l$
  2. $α_j \cong 0$ auf $M \setminus W_j\quad j = 1, \dots, l$
  3. $\sum_{j = 1}^{l} a_j = 1$ auf $M$
  #+end_defn
  #+ATTR_LATEX: :options [Integral auf Mannigfaltigkeit]
  #+begin_defn latex
  Sei $M ⊂ ℝ^n$ eine \(m\)-dimensionale Mannigfaltigkeit mit endlichen Atlas $(φ_{j}^{-1}: W_j \to U_j)_{j = 1, \dots, d}$. Eine Funktion $f: M \to ℝ$ heißt integrierbar, wenn
  $f χ_{W_j}$ integrierbar $∀ j = 1, \dots, d$ (im Sinne von Definiton 4.14). Ist $(α_j)_{j = 1, \dots, d}$ eine Partition der Eins (für Überdeckung $(W_j)_{j = 1, \dots j}$)
  und $α_j \circ φ_j$ messbar $∀ j = 1, \dots, d$, so definieren wir das Integral von $f$ über $M$ durch
  \[∫_M f \d A^n = \sum_{j = 1}^{l} ∫_M α_j f \d A^M = \sum_{j = 1}^{l} ∫_{U_j} (α_j \circ φ_j)(f \circ φ_j)\sqrt{\det((D φ_j)^T (Dφ_j))} \d λ^m\]
  #+end_defn
  #+begin_lemma latex
  Das Integral auf Mannigfaltigkeiten ist wohldefiniert und hängt insbesondere nicht vom gewählten Atlas ab.
  #+end_lemma
  #+begin_proof latex
  $α_j f χ_{W_j} = α_j f$ integrierbar (weil $f χ_{W_j}$ integrierbar, $α ∈ [0,1]$). Sei $(φ_{j}^{-1}: W_j \to U_j)_{j = 1, \dots, d}$ und $(\tilde φ_{k}^{-1}: \tilde W_k \to \tilde U_k)_{k = 1, \dots, \tilde d}$ Atlasen
  und $(α_j)_{j = 1, \dots, d}$ beziehungsweise $(\tilde α_k)_{k = 1, \dots, \tilde d}$ eine Partition der Eins. Nach Definition 4.14 ist auch
  \[f χ_{\tilde W_k} = \sum \tilde a_k f χ_{W_k}\]
  integrierbar und
  \[\sum_{j = 1}^{d} ∫_M α_j f \d A^m = \sum_{j = 1}^{d} \sum_{k = 1}^{\tilde d} ∫_M α_j \tilde α_j f \d A^m = \sum_{k = 1}^{\tilde d} ∫_M \tilde α_k f \d A^m\]
  #+end_proof
  #+begin_defn latex
  Sei $M ⊂ ℝ^n$ eine \(m\)-dimensionale Mannigfaltigkeit mit endlichen Atlas. Ist $S ⊂ ℝ^n$ eine Teilmenge und $χ_S$ integrierbar so nennen wir $S$ integrierbar und definieren
  \[\vol^m(S) = ∫_M χ_S \d A^m\]
  Falls $\vol^M(S) = 1$ ist $S$ eine \(n\)-dimensionale Nullmenge.
  und $f:S \to ℝ$ heißt über $S$ integrierbar falls $f χ_S$ integrierbar ist und
  \[∫_S f \d A^m = ∫_M χ_s \d A^m\]
  #+end_defn
  #+begin_lemma latex
  Sei $M ⊂ ℝ^n$ eine \(m\)-dimensionale Nullmenge. ist $f$ integrierbar, so ist auch $\hat f$ integrierbar und wir haben
  \[∫_M f \d A^m = ∫_M \hat f \d A^m\]
  #+end_lemma
  #+begin_proof latex
  Ist $S ⊂ M$ eine \(m\)-dimensionale Nullmenge, so gilt für jede Karte $φ^{-1}: W \to U$
  \begin{align*}
  0 &= \vol^m(S) &\geq ∫_M χ_{S ∩ W} \d A^m = ∫_U (χ_S \circ φ) \sqrt{\det((D φ)^T Dφ)} \d λ^m \\
  &= ∫_{U ∩ φ^{-1}(S)} \sqrt{\det((D φ)^T D φ)} \d λ^m
  \end{align*}
  Da der Radikand positiv ist ($φ$ ist Immersion) folgt $λ^m(U ∩ φ^{-1}(S)) = 0$. Gilt nun $f = \hat f$ auf $M \setminus S$ so haben wir $\hat f \circ φ = f \circ φ$ fast überall in $U$ für jede Karte $φ^{-1}: W \to U$.
  #+end_proof
  Motivation \\
  Oft ist bei Integration wichtig eine Orientierung des Integrationsbereich zu berücksichtigen \\
  $∫_i f = F \big|_{\partial F}$
** Orientierung
   #+begin_defn latex
   Sei $M$ eine \(m\)-dimensionale Mannigfaltigkeit in $ℝ^n, n \geq m \geq 1$. Zwei Karten $φ_1^{-1}: W_1 \to U_1, φ_2^{-1}: W_2 \to U_2$ heißen *gleichorientiert*, wenn für $W_1 ∩ W_2 \neq \emptyset$ der
   Kartenwechsel
   \[ψ := φ_2^{-1} \circ φ_1: φ_1^{-1}(W_1 ∩ W_2) \to φ_2^{-1}(W_1 ∩ W_2)\]
   die Eigenschaft $\det D ψ > 0$ auf $φ_1^{-1}(W_1 ∩ W_2)$ besitzt. $ψ$ ist dann *orientieungserhaltend / orientierungstreu* \\
   $M$ heißt *orientierbar* wenn es einen Atlas aus gleichorientierten Karten gibt und dieser heißt dann *orientiert*.
   #+end_defn
   #+begin_ex latex
   1. Jede Mannigfaltigkeit, die durch eine einzige	Karte parametrisiert werden kann, ist orientierbar.
   2. Sei $γ: I \to ℝ^n$ eine \(C^1\)-Kurve, $I ⊂ ℝ$ ein offenes, beschränktes Intervall, $γ' \neq 0$, sodass $γ: I \to \im γ$ ein Homöomorphismus ist.
	  Dann ist $\im γ$ eine Mannigfaltigkeit und die Parametrisierung $γ$ induziert eine Orientierung of $\im γ$. Diese Orientierung korresponiert mit Orientierung von $T_{γ(t)} \im γ = \{c γ'(t) \mid c ∈ ℝ\}$
   #+end_ex
   #+begin_ex latex
   Es gibt in $ℝ^3$ ein nicht-orientiete zweidimensionale Fläche: *Möbius Band* (mit Rand). Ein Beispiel für eine geschlossene (ohne Rand) zweidimensionale Fläche in $ℝ^4$ stellt die Kleinsche Flasche dar. stellt die Kleinsche Flasche dar. stellt die Kleinsche Flasche dar.
   #+end_ex
   #+begin_remark latex
   1. Sei $\mathcal{A}$ ein orientierter Atlas. Sind Karten $φ_1^{-1}:W_1 \to U_1, φ_2^{-1}: W_2 \to U_2$ (nicht aus \(\mathcal{A}\)) jeweils gleichorientiert zu allen Karten aus $\mathcal{A}$, so sind auch
	  $φ_1^{-1}$ und $φ_2^{-1}$ gleichorientiert und $\mathcal{A} ∪ \{φ_1^{-1}, φ_2^{-1}\}$ ist auch ein orientierter Atlas (weil $∀ ξ ∈ W_1 ∩ W_2 ∃ φ_0^{-1}: W_0 \to U_0, ξ ∈ W_0$ aus $\mathcal{A}$ mit
      \[φ_2^{-1} \circ φ_1 = \underbrace{(φ_2^{-1} \circ φ_0)}_{\mathclap{\text{orientierungstreu}}} \circ \underbrace{(φ_0^{-1} \circ φ_1)}_{\mathclap{\text{orientierungstreu}}}\]
      in einer hinreichend kleinen Umgebung von $φ^{-1}(ξ) ∈ U_1$. Aus der Kettenregel folgt, dass $φ_2^{-1} \circ φ_1$ orientierungstreu ist)
   2. Orientierung auf $M$ $⇒$ Orientierung der Tangentialräume $T_p M$. Auf $M$ ist die Orientierung durch einen Atlas $\mathcal{A}$ gegeben. Sei $φ^{-1}: W \to U$ eine Karte aus $\mathcal{A}$ mit
	  $φ(0) = p$
	  \[(\pp{φ}{x_1}(u), \dots, \pp{φ}{x_m}(u))\]
	  gibt eine Orientierung von $T_p M$. Diese ist von der speziellen Wahl von $φ$ unabhängig.
   #+end_remark
   #+begin_proposition latex
   Eine Hyperfläche in $ℝ^n$ (\(n - 1\)-dimensionale Mannigfaltigkeit in $ℝ^n$) ist genau dann orientierbar, wenn as auf $M$ ein stetiges Normalenfeld gibt, das heißt eine stetige Abbildung $ν: M \to \mathbb{S}^{n - 1}$ und
   $ν(p) ∈ N_p M ∀ p ∈ M$.
   #+end_proposition
** Glatte Ränder
   #+ATTR_LATEX: :options [Relativtopologie und Rand]
   #+begin_defn latex
   Sei $(X, \mathcal{O})$ ein topologischer Raum, $Y ⊂ X$ eine nichtleere Teilmenge von $X$
   \[\mathcal{O} ∩ Y := \{U ∩ Y \mid U ∈ \mathcal{O}\}\]
   gibt eine *Relativtopologie*: Der Rand $\partial Y$ ist die Menge aller Punkte $x ∈ X$, sodass $∀ U ∈ \mathcal{O}$ mit $x ∈ U ∃ y ∈ U$ sodass $y ∈ Y$ und $∃ \tilde y ∈ U$ sodass $\tilde y ∈ Y^C = X \setminus Y$ \\
   $(Y, \mathcal{O} ∩ Y)$ ist ein topologischer Raunm.
   #+end_defn
   #+ATTR_LATEX: :options [Glatte Ränder und adaptierte Karten]
   #+begin_defn latex
   Sei $M ⊂ ℝ^n$ eine \(m\)-dimensionale Mannigfaltigkeit und $Ω ⊂ M$. Wir sagen dass $Ω$ einen *glatten Rand* hat, falls es für jedes $p ∈ \partial Ω$ eine Karte $φ^{-1}: W \to U, p ∈ W$ und $φ(U ∩ \{x_1 \leq 0\}) = Ω ∩ W$ sowie $φ(U ∩ \{x_1 = 0\}) = \partial Ω ∩ W$ gibt.
   Eine solche Karte heißt \(Ω\)-adaptiert. Ein Atlas heißt \(Ω\)-adaptiert, falls sämtliche seiner Karten deren definitionsbereich $\partial \mathcal{A}$ schneidet \(Ω\)-adaptiert sind.
   #+end_defn
   #+begin_lemma latex
   Sei $M$ eine \(m\)-dimensionale Mannigfaltigkeit in $ℝ^n, Ω ⊂ M$ eine Teilmenge mit glattem Rand. Dann gibt es einen \(Ω\)-adaptierten Atlas. Ist $M$ orientiert und $m \geq 2$ dann kann man erreichen, dass dieser
   \(Ω\)-adaptierte Atlas orientiert ist.
   #+end_lemma
   #+ATTR_LATEX: :options [Ränder als Mannigfaltigkeit]
   #+begin_thm latex
   Sei $M$ eine \(m\)-dimensionale Mannigfaltigkeit im $ℝ^m, m \leq n$ ist $Ω ⊂ M$ eine Teilmenge mit glattem Rand, so ist $\partial Ω$ eine \((m - 1)\)-dimensionale Mannigfaltigkeit im $ℝ^n$. Ist $M$ orientierbar, so ist auch $\partial Ω$
   #+end_thm
   #+begin_proof latex
   Sei $\mathcal{A}$ ein \(Ω\)-adaptierter Atlas. Die Karten $φ^{-1}:W \to U$ mit $\partial Ω ∩ W \neq \emptyset$ definieren wir eine stetige, bijektive Abbildung $\tilde φ^{-1}: \partial Ω ∩ W \to \tilde U$, wobei
   \[\tilde U := \{\tilde X ∈ ℝ^{m - 1} \mid (0, \tilde x) ∈ U ⊂ ℝ^m\}\]
   $\tilde φ(\tilde x) = φ(0, \tilde x), \tilde x ∈ \tilde U$. \\
   $U$ offen $⇒ \tilde U$ offen in $ℝ^{m - 1}$ mit $\partial Ω ∩ W$ offen in $\partial W$. $\tilde φ$ ist ein Homöomorphismus, weil $\tilde φ^{-1} = P \circ φ^{-1} \big|_{\partial Ω ∩ W}$ ($P: (x_1, \tilde x) \to \tilde x$) stetig ist.
   $⇒ \Rang D φ = m ⇒ D \tilde φ$ hat vollen Rand $⇒ D \tilde φ = m - 1 ⇒ \partial Ω$ ist eine Mannigfaltigkeit. \\
   $M$ orientieert, $m \geq 2$ $⇒$ $\mathcal{A}$ besteht aus gleichorientierten \(Ω\)-adaptierten Karten. Wir nehmen $φ_1^{-1}, φ_2^{-1}$ aus $\mathcal{A_0}$ ($W_1 ∩ W_2 ∩ \partial Ω \neq \emptyset$)
   $⇒$ wir bekommen $\tilde φ_1^{-1}, \tilde φ_2^{-1}$ und Kartenwechsel $ψ := \tilde φ_2^{-1} \circ φ_2$
   \begin{align*}
   \det D ψ(0, \tilde x) &= \det \begin{pmatrix}\pp{ψ_1}{x_1} & 0 \\ \ast & D \tilde ψ(\tilde x)\end{pmatrix} = \pp{ψ_1}{x_1} \det D \tilde ψ(\tilde x) > 0 \\
   \text{weil } \pp{ψ_1}{x_j}(0, x_2, \dots, x_m) = \begin{cases} \geq 0 & j = 1 \\ = 0 & j = 2, \dots, m\end{cases} \\
   \end{align*}
   #+end_proof
* Differentialformen und der Satz von Stokes
  Hier: $ω$ definiert auf offerner Umgebung von $M$ im $ℝ^n$, Differentialformen wirken auf ganz $ℝ^n$
  1. Alternierende \(k\)-Formen auf endlich-dimensionalen Vektorräumen
  2. Differentialformen, ordne jedem Punkt $p ∈ M$ eine alternierende \(k\)-Form zu.
  3. Integration von Differntialformen auf Mannigfaltigkeiten (Satz von Stokes)
  4. Anwendung (Satz von Gauß)
** Multilineare Algebra
   Multilinearität heißt: Messen des \(k\)-dimensionalen Volumens kleiner Maschen.
   #+ATTR_LATEX: :options [\(k\)-Formen]
   #+begin_defn latex
   Eine	*(alternierende) \(k\)-Form* auf einem \(n\)-dimensionalem Vektorraum ist eine in jedem Argument linear Abbildung $ω: V^k \to ℝ$, die bei der Vertauschung zweier Einträge das Vorzeichung wechselt.
   Den Vektorraum der \(k\)-Form bezeichnen mir mit $\Alt^k V, k ∈ ℕ$
   #+end_defn
   #+begin_ex latex
   Die Determinante
   \[(v_1, \dots, v_k) \to \det(v_1, \dots, v_k), v_1, \dots, v_k ∈ ℝ^k\]
   ist eine \(k\)-Form \\
   Für $k = 1$ ist dei Bedingung des Alternierens lerr. $\Alt^1 V = V^1 \simeq V$ ($V^1$ Dualraum zu $V$)
   #+end_ex
   #+begin_remark latex
   Für eine lineare Abbildung $ω: V^k \to ℝ$ sind die forgenden Eigenschaften äquivalent:
   1. $ω$ wechselt das Vorzeichen beim Vertausch zweier Einträge
	  \[ω(v_1, \dots, v_j, \dots v_i, \dots v_k) = - ω(v_1, \dots, v_i, \dots, v_j, \dots, v_k)\]
   2. $ω$ verschwindet wenn zwei Eintränge gleich sind
   3. $ω$ verschwindet, wenn die Eintränge linear abhängig sind
   4. Für eine Permutation $π ∈ σ_k$ (Symmetrische Grupppe) auf $\{1, \dots, k\}$ gilt
	  \[ω(v_{1}, \dots, v_{k}) = \sgn π ω(v_{π(1)}, \dots, v_{π(k)})\]
   #+end_remark
   #+ATTR_LATEX: :options [Äußeres Produkt]
   #+begin_defn latex
   Zu $ω ∈ \Alt^k V$ und $η ∈ \Alt^l V, k, l ∈ ℕ$, definieren wir das äußere Produkt (Dachprodukt) $ω ∧ η ∈ \Alt^{k + l} V$ durch
   \[(ω ∧ η)(v_1, \dots, v_{k + l}) := \frac{1}{k! l!} \sum_{π ∈ σ_{k + l}} \sgn π ω(v_{π(1)}, \dots, v_{π(k)}) η(v_{π(k + 1)}, \dots, v_{π(k + l)})\]]
   Mit Hilfe von Bemerkung 5.3 bekommen wir, dass $ω ∧ η$ ein Element aus $\Alt^{k + l}$ darstellt.
   #+end_defn
   #+begin_lemma latex
   Das äußere Produkt $∧: \Alt^k V × \Alt^l V \to \Alt^{k + l} V$ ist bilinear, assoziativ und antikommutativ. Das heißt $η ∧ ω = (-1)^{kl} (ω ∧ η)$ für $ω ∈ \Alt^k V, η ∈ \Alt^l V$.
   Für $ω ∈ \Alt^k V, 1 ∈ \Alt^{0} V$ ($=ℝ$) gilt $1 ∧ ω = ω ∧ 1$
   #+end_lemma
   #+begin_proof latex
   Bilinearität und $1 ∧ ω = ω ∧ 1 = ω$ sind klar \\
   Antikommutativität kommt aus den Eigenschaften von Permutationen
   \[π:(1, \dots, k + l) \to (k + 1, \dots, k + l, 1, \dots, k) ⇒ \sgn(π) = (-1)^{kl}\]
   zu zeigen: Für $ω . \Alt^k V, η ∈ \Alt^l V, ξ ∈ \Alt^m V$ gilt
   \begin{align*}
   \string((ω ∧ η) ∧ ξ\string)(v_1, \dots, v_{k + l + m}) &= (ω ∧ (η, ξ))(v_1, \dots, v_{k + l + m}) \\
   &= \sum_{π ∈ σ_{k + l + m}} \frac{\sgn π}{k! l! m!} ω(v_{π(1)}, \dots, v_{π(k)}) η(v_{π(k + 1)}, \dots, v_{π(k + l)}) ξ(v_{π(k + l + 1)}, \dots, v_{π(k + l + m)})
   \end{align*}
   Wir betrachten $ω ∧ (η ∧ ξ)$ (für $(ω ∧ η) ∧ ξ$ analog)
   \begin{align*}
   \string(ω ∧ (η ∧ ξ)\string)(v_1, \dots, v_{k + l + m}) &= \sum_{π ∈ σ} \frac{\sgn π}{k! (l + m)!} ω(v_{π(1)}, \dots, v_{π(k)}) (η ∧ ξ)(v_{π(k + 1)}, \dots, v_{π(k + l + m)}) \\
   \end{align*}
   Wir betrachten $a = (a_1, \dots, a_k), a_j ∈ \{1, \dots, k + l + m\}$ paarweise verschieden. Jede Permutation $π ∈ σ_{k + l + m}$ mit $π(j) = a_j ∀ j = 1, \dots, k$ lässt sich durch
   \[π(j) = \begin{cases}  a_j & j = 1, \dots, k \\ τ_a(k + π(j - k)) & j = k + 1, \dots, k + l + m\end{cases}\]
   Wobei $τ_a ∈ σ_{k + l + m}$ eine entsprechend gewählt Permutation ist imt $a_j = τ_a(j), j = 1, \dots, k$.
   Wir bezeichnen $\tilde π ∈ σ_{l + m}$
   \begin{gather*}
   ⇒ \sum_{a} \frac{\sgn τ_a}{k!}ω(v_{a_1}, \dots, v_{a_k}) \sum_{\tilde π ∈ σ_{l + m}} \frac{\sgn \tilde π}{l! m!} η(v_{τ_a(k + \tilde π(1))}, \dots, v_{τ_a(k + \tilde π(l))}) ξ(v_{τ_a(k + \tilde π(l + 1))}, \dots, v_{τ_a(k + \tilde π(l + m))}) \\
   \sum_{a} \frac{\sgn τ_a}{k!} ω(v_{a_1}, \dots, v_{a_k}) \sum_{\tilde π ∈ σ_{l + m}} \frac{\sgn \tilde π}{(l + m)!}(η ∧ ξ)(v_{τ_a(k + \tilde π(1))}, \dots, v_{τ_a(k + \tilde π(l + m))}) \\
   \end{gather*}
   Aus
   \[(η ∧ ξ)(v_{τ_a(k + \tilde π(1))}, \dots, v_{τ_a(k + \tilde π(l + m))}) = (\sgn \tilde π)(η ∧ ξ)(v_{τ_a(k + 1), \dots, v_{τ_a(k + l + m)}})\]
   und $(l + m! = \# σ_{l + m})$, folgt die	Gleichheit
   #+end_proof
   #+begin_remark latex
   Durch Induktion bekommt man für $ω_j ∈ \Alt^{k_j} V, j = 1, \dots, N$
   \[(ω_1 ∧ \dots ∧ ω_N)(v_1, \dots, v_{k_1 + \dots + k_N}) = \sum_{π ∈ σ_{k_1 + \dots + k_N}} \frac{\sgn π}{k_1! \dots k_N!} \prod_{j = 1}^N ω_j(v_{π(k + \dots + k_{j - 1} + 1)}, \dots, v_{π(k_1 + \dots + k_j)})\]
   Für $k_1 = \dots = k_N = 1, ω_1, \dots, ω_N ∈ \Alt^1 V = V^1, v_1, \dots, v_N ∈ V$ bekommen wir die Determinantenformel
   \[(ω_1 ∧ \dots ∧ ω_N)(v_1, \dots, v_N) = \det ((ω_j(v_l)))_{j,l = 1, \dots, N}\]
   #+end_remark
   #+begin_thm latex
   Für eine Basis $(δ_1, \dots, δ_n)$ des Dualraums	$V'$ ist $(δ_{j_1} ∧ \dots ∧ δ_{j_k} \mid 1 \leq j_1 < j_2 < \dots < j_k < n)$ eine Basis der $\Alt^k V$. Ist $(e_1, \dots, e_n)$ die zu $(δ_1, \dots, δ_n)$
   duale Basis von $V$ ($δ_j(e_k) = δ_{jk}$) so haben wir
   \[ω = \sum_{j_1 < \dots < jj_k} a_{j_1, \dots, j_k} δ_{j_1} ∧ \dots ∧ δ_{j_k}\]
   mit $a_{j_1, \dots, j_k} = ω(e_{j_1}, \dots, e_{j_k}) ∈ ℝ$. Mithin ist $\dim \Alt^k V = \cvec{n;k}$, insbesondere $\Alt^k V = \{0\}$ für $k > n$.
   #+end_thm
   #+begin_proof latex
   Indem wir auf beiden Seiten der behaupteten Gleichungen die Argumente $(e_{j_1}, \dots, e_{j_k})$ einsetzen ergibt sich $ω(e_{j_1}, \dots, e_{j_k}) = a_{j_1,\dots,j_k}$, was nach Definition korrekt ist.
   Da wir mit alternierenden \(k\)-Formen arbeiten, gilt die Gleichung für beliebige Argumente. Ist
   \[\sum_{j_1 < \dots j_k} b_{j_1, \dots, j_k} δ_{j_1} ∧ \dots ∧ δ_{j_k} = 0\]
   so erhält man durch Einsetzen von $(e_{j_1}, \dots, e_{j_k})$ mit $j_1 < \dots < j_k$ sofort $b_{j_1, \dots, j_k} = 0$ und somit lineare Unabhängigkeit.
   #+end_proof
   #+begin_defn latex
   Für eine lineare Abbildung $f: V \to W$ zwischen	endlich-dimensionalen Vektorräumen und $ω ∈ \Alt^k W$ erhalten wir durch
   \[(f^{\ast} ω)(v_1, \dots, v_k) = ω(f(v_1), \dots, f(v_k))\]
   die zurückgeholte Form $f^{\ast}ω ∈ \Alt^k V$. Dabei ist $f^{\ast}: \Alt^k W \to \Alt^k V$.
   #+end_defn
   #+begin_lemma latex
   Für eine lineare Abbildung $f: V \to W$ zwischen	endlich-dimensionalen reellen Vektorräumen und $ω ∈ \Alt^k W, η ∈ \Alt^l W$ gilt:
   \[f^{\ast}(ω ∧ η) = (f^{\ast} ω) ∧ (f^{\ast} η)\]
   #+end_lemma
   #+begin_proof latex
   Wir haben
   \begin{align*}
   f^{\ast}(ω ∧ η) (v_1, \dots, v_{k + l}) &= \\frac{1}{k! l!} \sum_{π ∈ σ_{k + l}} (\sgn π) ω(f(v_{π(1)}, \dots, v_{π(k)}))η(f(v_{π(k + 1)}, \dots, v_{π(k + l)})) \\
   &= \frac{1}{k! l!} \sum_{π ∈ σ_{k + l}} (\sgn π)(f^{\ast} ω)(v_{π(1)}, \dots, v_{π(k)})(f^{\ast} η)(v_{π(k + 1)}, \dots, v_{π(k + l)}) \\
   &= ((f^{\ast} ω) ∧ (f^{\ast} η))(v_1, \dots, v_{k + l})
   \end{align*}
   #+end_proof
   #+begin_lemma latex
   Ist $V$ ein endlich-dimensionaler, reeller Vektorraum $f: V \to V$ linear, sowie $ω ∈ \Alt^k V, n = \dim V$, so erhalten wir $f^{\ast} ω = (\det f) ω$.
   #+end_lemma
   #+begin_proof latex
   $\dim \Alt^n V = 1$ und wegen der Linearität von $f^{\ast}: \Alt^n V \to \Alt^n V$ gibt es ein $λ ∈ ℝ$ mit $f^{\ast} ω = λ ω ∀ ω ∈ \Alt^n V$. Mit einem Isomorphismus $Φ: V \to ℝ^n$
   und $\tilde ω = Φ^{\ast} \det$ ergibt sich für die Standardeinheitsbasis $(e_1, \dots, e_n) ⊂ ℝ^n$:
   \begin{align*}
   λ &= λ\det(e_1, \dots, e_n) = λ \tilde ω(Φ^{-1}(e_1), \dots, Φ^{-1}(e_n)) = f^{\ast} \tilde ω(Φ^{-1}(e_1), \dots, Φ^{-1}(e_n)) \\
   &= \tilde ω(f Φ^{-1}(e_1), \dots, f Φ^{-1}(e_n)) = \det(Φ f Φ^{-1}(e_1), \dots, Φ f Φ^{-1}(e_n)) = \det f
   \end{align*}
   #+end_proof
** Differentialformen
   #+ATTR_LATEX: :options [Differentialform]
   #+begin_defn latex
   Eine Differentialform der Ordnung $k, k ∈ ℕ ∩ \{0\}$, auf einer offenen Menge $Ω ⊂ ℝ^n$ ist eine Abbildung $ω: Ω \to \Alt^k ℝ^n$.
   #+end_defn
   #+ATTR_LATEX: :options [Differentiale und Differentialform]
   #+begin_ex latex
   Differnitalformen der Ordnung $0$ sind wegen $\Alt^0 ℝ^n = ℝ$ gerade die reellwertigen Funktionen auf $Ω$. Ist $f ∈ C^1(Ω)$, so liefert $x ↦ \d f(x) ∈ (ℝ^n)' \simeq ℝ^n$ eine
   Differentialform der Ordnnug $1$ (mit $(ℝ^n)'$ bezeichnen wir den Dualraum zu $ℝ^n$). ($f(x + h) - f(x) = (L x)h + o(\abs{h}), Lx: ℝ^n \to ℝ, L x$ oder $\d f(x), D f(x)$).
   Die Menge der Differentialformen der Ordnung $k$ wird mit punktweiser Addition und punktweiser skalaren Multiplikation zu einem Vektorraum. Auch das äußere Produkt definiert man punktweise.
   #+end_ex
   #+begin_notation latex
   Wir betrachten die Projektionsabbildung $x_j: Ω ⊂ ℝ^n \to ℝ, x ↦ \braket{x, e_j} = x_j, j = 1, \dots, n$. Nun erhält man
   \[∇ x_j(x) e_k = \braket{e_j, e_k} = δ_{jk}, j,k = 1, \dots, k\]
   sodass $(\d x_j)_{j = 1, \dots, n}$ die zur Standardbasis $(e_1, \dots, e_n)$ des $ℝ^n$ duale Basis des $(ℝ^n)'$ ist. Jede Differentialform der Ordnnug $k$ lässt sich eindeutig durch
   \[ω = \sum_{\mathclap{1\leq j_1 < \dots < j_k < n}} a_{j_1, \dots, j_k} \d x_{j_1} ∧ \dots ∧ \d x_{j_n}\]
   darstellen, wobei $a_{j_1, \dots, j_k} = ω(e_{j_1}, \dots, e_{j_n})$ ist. Für $f ∈ C^1(Ω)$ haben wir
   \[\d f(x) = \sum_{j = 1}^{n} \pp{f}{x_j}(x) \d x_j\]
   denn
   \[\sum_{j = 1}^{n} \pp{f}{x_j}(x) \d x_j(e_k) = \pp{f}{x_k}(x) = \d f(x) e_k\]
   da $\d x_j(e_k) = δ_{jk}$.
   #+end_notation
   #+ATTR_LATEX: :options [Zurückgeholte Form]
   #+begin_defn latex
   Für offene Mengen $Ω_1 ⊂ ℝ^m, Ω_2 ⊂ ℝ^n, f ∈ C^1(Ω_1, Ω_2)$ und eine Differentialform $ω$ der Ordnung $k$ auf $Ω_2$ ist die auf $Ω_1$ zurückgeholte Form $f^{\ast} ω$ durch
   \[(f^{\ast}ω)(x)(v_1, \dots, v_k) = ω(f(x))(\d f(x) v_1, \dots, \d f(x) v_k)\]
   erklärt.
   #+end_defn
   #+ATTR_LATEX: :options [Äußere Ableitung]
   #+begin_thm latex
   Für $k ∈ ℕ ∪ \{0\}$ gibt es genau eine Abbildung $d$ von der Menge der differenziebaren \(k\)-Formen nach $\Alt^{k + 1} ℝ^n$ die
   1. linear ist
   2. im Fall $k = 0$, für eine differenzierbare Abbildung $f: Ω \to ℝ$, das Differential $\d f$ liefert
   3. für jede differenzierbare Differentialform $ω$ der Ordnung $k$ und eine differenzierbare Differentialform $η$ der Ordnung $0$ die Produktregel
	  \[\d(ω ∧ η) = (\d ω) ∧ η + (-1)^k ω ∧ (\d η)\]
	  erfüllt und
   4. für $ω ∈ C^2(Ω, \Alt^k ℝ^n)$ der Exaktheitsbedingung $\d \d ω = 0$ genügt
   Ist
   \[ω = \sum_{\mathclap{j_1 < \dots < j_k}} a_{j_1, \dots, j_k} \d x_{j_1} ∧ \dots ∧ \d x_{j_k}\]
   so erhälten wir
   \[\d ω = \sum_{\mathclap{j_1 < \dots < j_k}} \d a_{j_1, \dots, j_k} ∧ \d x_{j_1} ∧ \dots ∧ \d x_{j_k}\]
   #+end_thm
   #+begin_defn latex
   Für eine differenzierbare Differentialform $ω$ wird $\d$ die äußere Ableitung, Cartan-Ableitung oder Differential genannt.
   #+end_defn
   #+begin_ex latex
   1. Jede differenziebare Differentialform $ω$ der Ordnung $(n - 1)$ auf $ℝ^n$ kann als
	  \[ω = \sum_{j = 1}^{n} (-1)^{j - 1} f_j \d x_1 ∧ \dots ∧ \d x_{j - 1} ∧ \d x_{j + 1} ∧ \dots ∧ \d x_n\]
	  dargestellt werden, wobei $f_1, \dots, f_n$ geeignete reelle differenzierbare Funktionen sind. Wir haben dann
	  \begin{align*}
	  \d ω &= \sum_{j = 1}^{n} (-1)^{j - 1} (\d f_j) ∧ \d x_1 ∧ \dots ∧ \d x_{j - 1} ∧ \d x_{j + 1} ∧ \dots ∧ \d x_n
	  \d f_j &= \sum_{l = 1}^{k} \pp{f}{x_l} \d x_l = \pp{f}{x_j} \d x_j ∧ \d x_1 ∧ \dots ∧ \d x_{j - 1} ∧ \d x_{j + 1} ∧ \dots ∧ \d x_n \\
	  \d ω &= \underbrace{\sum_{j = 1}^{n} \pp{f}{x_j}}_{=\Div f} \d x_1 ∧ \dots ∧ \d x_n
      \end{align*}
   2. Für $n = 3$ können wir eine Differentialform der Ordnung $1$ als $ω = f_1 \d x_1 + f_2 \d x_2 + f_3 \d x_3$ mit skalaren Funktionen $f_1, f_2, f_3$ schreiben. Sofern sie differenzierbar sind folgt
	  \begin{align*}
	  \d ω &= \d f_1 ∧ \d x_1 + \d f_2 ∧ \d x_2 + \d f_3 η \d x_3 \\
	  &= \pp{f_1}{x_2} \d x_2 ∧ \d x_1 + \pp{f_1}{x_3} \d x_3 ∧ \d x_1 + \pp{f_2}{x_1} \d x_1 ∧ \d x_2 + \pp{f_2}{x_3} \d x_3 ∧ \d x_2 + \pp{f_3}{x_2} \d x_2 ∧ \d x_3 + \pp{f_3}{x_1} \d x_1 ∧ \d x_3 \\
	  &= (\pp{f_2}{x_1} - \pp{f_1}{x_2}) \d x_1 ∧ \d x_2 + (\pp{f_3}{x_2} - \pp{f_2}{x_3}) \d x_2 ∧ \d x_3 + (\pp{f_1}{x_3} - \pp{f_3}{x_1}) \d x_3 ∧ \d x_1 \\
	  &= \rot f · \d \v F
      \end{align*}
	  wobei
	  \[\d \v F = \cvec{\d x_2 ∧ \d x_3; \d x_3 ∧ \d x_1; \d x_1 ∧ \d x_2}\]
	  das vektorielle Flächenelement ist,
	  \[\d \v S = \cvec{\d x_1; \d x_2; \d x_3}\]
	  das vektorielle Linienelement, $\d V = \d x_1 ∧ \d x_2 ∧ \d x_3$ das Volumenelement ist. Wir haben
	  \[\d f = ∇ f · \d \v S, \d(g · \d \v S) = (\rot g) · \d \v F, \d (h · \d \v F) = (\Div f) \d V\]
   #+end_ex
   #+begin_thm latex
   Für offene Mengen $Ω_1 ⊂ ℝ^n, f ∈ C^2(Ω_1, Ω_2)$ und eine differenzierbare Differenzialform auf $Ω_2$ ist auch die auf $Ω_1$ zurückgeholte Form $f^{\ast}ω$ differenzierbar und es gilt
   \[\d (f^{\ast} ω) = f^{\ast}(\d ω)\]
   #+end_thm
   #+begin_proof latex
   Für eine differenzierbare Differentialform der Ordnung $0$ ist $f^{\ast} g = g \circ f$ differenzierbar und für $x ∈ Ω_1$ und $v ∈ ℝ^m$ haben wir
   \[\d (f^{\ast} g)(v) = \d (g \circ f)(v) = \d g(f(x)) \d f(x) v = f^{\ast}(\d ω)(x)(v)\]
   Für allgemeine
   \[ω = \sum_{\mathclap{j_1 < \dots < j_k}} a_{j_1, \dots, j_k} \d x_{j_1} ∧ \dots ∧ \d x_{j_k}\]
   erhalten wir
   \begin{align*}
   f^{\ast} \d ω &= \sum_{\mathclap{j_1 < \dots < j_k}} \underbrace{f^{\ast} \d a_{j_1, \dots, j_k}}_{\mathclap{=\d (f^{\ast} a_{j_1, \dots, j_k})}} ∧ \overbrace{f \d x_{j_1}}^{\mathclap{\d (f^{\ast} x_{j_1})}} ∧ \dots ∧ \underbrace{f^{\ast} \d x_{j_k}}_{\mathclap{\d(f^{\ast} x_{j_k})}} \\
   &= \d(\sum_{\mathclap{j_1 < \dots < j_k}}(f^{\ast} a_{j_1, \dots, j_k})) ∧ \d(f^{\ast} x_{j_1}) ∧ \dots ∧ \d(f^{\ast} x_{j_k}) = \d (f^{\ast} ω)
   \end{align*}
   #+end_proof
** Integration von Differentialformen
   #+begin_defn latex
   Sei $Ω ⊂ ℝ^n$ offen. Eine Differentialform $ω = f \d x_1 ∧ \dots ∧ \d x_n$ heißt integrierbar über $A ⊂ Ω$ falls $f$ über $A$ integrierbar ist. Wir setzen
   \[∫_A ω = ∫_A f \d λ^n\]
   #+end_defn
   #+ATTR_LATEX: :options [Transformationsformel]
   #+begin_thm latex
   Sind $U, V ⊂ ℝ^n$ offen, $φ: V \to U$ ein orientierungstreuer \(C^1\)-Diffeomorphismus und $ω$ eine integrierbare Differentialform der Ordnung $n$ auf $U$ so gilt
   \[∫_V φ^{\ast} ω = ∫_U ω\]
   Im allgemeinen Fall $k ∈ \{1, \dots, n\}$ definieren wir Integrale zunächst über lokale Parametrisierung.
   #+end_thm
   #+begin_proof latex
   Für $ω = f \d x_1 ∧ \dots ∧ \d x_n$ erhalten wir zunächst
   \begin{align*}
   \string(φ^{\ast} ω\string)(x)(v_1, \dots, v_n) &= ω(φ(x))(\d φ(x) v_1, \dots, \d φ(x) v_n) \\
   &= f(φ(x))(\d x_1 ∧ \dots ∧ \d x_n)(\d φ(x) v_1, \dots, \d φ(x) v_n) \\
   &= f(φ(x))\underbrace{(\d φ(x))^{\ast}}_{\mathclap{\det \d φ(x)}}(\d x_1 ∧ \dots ∧ \d x_n)(v_1, \dots, v_n)
   \end{align*}
   also
   \[∫_V φ^{\ast} ω = ∫_V f φ \underbrace{\det \d φ(·)}_{> 0} \d λ^n = ∫_U f \d λ^n = ∫_U ω\]
   #+end_proof
   #+begin_defn latex
   Sei $Ω ü ℝ^n$ und $M ⊂ Ω$ eine \(k\)-dimensionale orientierte Mannigfaltigkeit sowie $φ^{-1}:W \to U$ eine Karte eines orientierte Atlanten. Eine auf $M \setminus W$ verschwindende Differnetialform $φ^{\ast} ω$ auf $U$ ist integrierbar und wir setzen
   \[∫_M ω = ∫_U φ^{\ast} ω\]
   Wie bei der Definition von Flächenintegralen muss man sich von der Unabhängigkeit dieser Definition von der gewählten Karte überzeugen. Dies folgt aus der angegebenen Transformationsformel. Entsprechendes gilt für die folgende Konvention.
   #+end_defn
   #+begin_defn latex
   Sei $Ω ü ℝ^n$ offen, $M ⊂ Ω$ eine \(k\)-dimensionale Mannigfaltigkeit mit orientiertem Atlas $(φ^{-1}_j: W_j \to U_j)_{j = 1, \dots, N}$. Eine Differentialform $ω: W \to \Alt^k ℝ^n$ heißt
   integrierbar, falls $χ_{W_j} ω$ für alle $j = 1, \dots, N$ im Sinne von vorheriger Definition integrierbar ist. Ist $(α_j)_{j = 1,\dots,N}$ eine der Überdeckung $(W_j)_{j = 1, \dots, N}$
   untergeordnete Partition der Eins und $α_j \circ φ_j$ messbar für $j = 1,\dots, N$ so definieren wir das Integral von $ω$ über $M$ durch
   \[∫_M = \sum_{j = 1}^{N} ∫_M a_j ω\]
   wobei auf der rechten Seite die in vorheriger Definition erklärten Integrale stehen.
   #+end_defn
   #+ATTR_LATEX: :options [Kurvenintegrale]
   #+begin_ex latex
   Sei $γ ∈ C^1(I, ℝ^n)$ für endliches Intervall $I = (a, b), 0 < c \leq \abs{γ'} \leq C < ∞$ auf $I$ und $γ: I \to \im γ$ ein Homöomorphismus, so ist das $\im γ$ eine
   eindimensionale Mannigfaltigkeit und für eine Differentialform
   \[ν = \sum_{j = 1}^{n} f_j \d x_j\]
   erhalten wir die zurückgeholte Form
   \[γ^{\ast} ν = \sum_{j = 1}^{n} (f_j \circ γ) \d γ_j\]
   Ist $ν$ integrierbar, so folgt
   \[∫_{\im γ} ν = ∫_i γ^{\ast} ν = ∫_I \braket{f(γ(t)), γ'(t)} \d t\]
   Sei nun $ω$ eine stetig differenzierbare Funktion auf einer Umgebung von $\im γ$. Dann haben wir für
   \begin{align*}
   ν &= \d ω = \sum_{j = 1}^{n} \pp{ω}{x_j} \d x_j \\
   ∫_{\im γ} \d ω &= ∫_I \braket{∇ ω(γ(t)), γ'(t)} \d t = ω(γ(b)) - ω(γ(a))
   \end{align*}
   #+end_ex
   #+ATTR_LATEX: :options [Stokes]
   #+begin_thm latex
   Sei $Ω ⊂ ℝ^n$ offen, $M ⊂ Ω$ eine \(k\)-dimensionale \(C^2\)-Mannigfaltigkeit, $K ⊂ M$ eine kompakte Teilmenge mit glattem Rand und $ω$ eine stetig differenzierbare Differentialform der
   Ordnung $k - 1$ auf $Ω$ mit $k \geq 2$. Der Rand $\partial K$ sei mit der von $K$ induzierten Ordnung ausgestattet. Dann gilt
   \[∫_K \d ω = ∫_{\partial K} ω\]
   #+end_thm
   #+begin_proof latex
   Sei $\mathcal{A}$ ein orientierter Atlas aus \(K\)-adaptierten Karten. Da $K$ kompakt ist, gibt es endlich viele Karten $(φ_j^{-1}: W_j \to U_j)_{j = 1, \dots, N}$ mit $K ⊂ \bigcup_{j = 1}^N W_j$.
   Nun sei $(α_j)_{j = 1, \dots, N}$ eine der Überdeckungen $(W_j)_{j = 1, \dots, N}$ untergeordnete Partition der Eins. Nun können wir $φ^{\ast}_j (α_j ω)$ durch Null stetig differenzierbar auf ganz
   $ℝ^n$ fortsetzen. Dann gilt
   \[∫_k \d(α_j ω) = ∫_{K ∩ W_j} \d (α_j ω) = ∫_{\{x_1 \leq 0\} ∩ U_j} φ^{\ast}(\d(α_j ω)) = ∫_{\{x_1 \leq 0\}} \d(φ^{\ast}(α_j ω))\]
   Wir haben hier $W_j ∩ \partial K \neq \emptyset$ angenommen, anderenfalls sieht man, dass das entsprechende Integral verschwindet. Sei nun $\tilde φ_j = φ_j \circ P: \tilde U_j \to W_j$ die vo
   $φ_j$ induzierte Randkarte, wo $P(x') = (0, x'), x' ∈ ℝ^{n - 1}$. Dann haben wir
   \[∫_{\partial K} α_j ω = ∫_{\partial K ∩ W_j} α_j ω = ∫_{\tilde U_j} \tilde φ_j^{\ast}(α_j ω) = ∫_{\tilde U_j} P^{\ast} φ_j^{\ast} (α_j ω) = ∫_{\{x_1 = 0\}} φ_j^{\ast}(α_j ω)\]
   Man erhält
   \[∫_K \d (α_j ω) = ∫_{\{x_1 \leq 0\}} \d(φ^{\ast}(α_j ω)) = ∫_{\partial \{x_1 \leq 0\}} φ^{\ast}(α_j ω) = ∫_{\partial K} α_j ω\]
   Summation über $j = 1, \dots, N$ liefert das Gewünschte.
   #+end_proof
   #+begin_lemma latex
   Für eine stetig differenzierbare Differentialform $ω$ der Ordnnug $k - 1$ mit kompaktem Träger auf $ℝ^k, k \geq 2$ ist
   \[∫_{\{x_1 \leq 0\}} \d ω = ∫_{\partial \{x_1 \leq 0\}} ω\]
   #+end_lemma
   #+begin_proof latex
   Für
   \[ω = \sum_{j = 1}^{k} (-1)^{j - 1} f_j \d x_1 ∧ \dots ∧ \d x_{j - 1} \d x_{j + 1} ∧ \dots ∧ \d x_k\]
   mit $f_j ∈ C^1(ℝ^k)$ folgt
   \[∫_{\{x_1 \leq 0\}} \d ω = ∫_{\{x_1 \leq 0\}} (\Div f) \d x_1 ∧ \dots ∧ \d x_k = ∫_{\{x_1 \leq 0\}} \Div f \d λ^n\]
   Mit dem Satz von Fubini können wir den \(j\)-ten Summanden in der Divergenz
   \[\Div f = \sum_{j = 1}^{n} \pp{f}{x_j}\]
   zunächst um $x_j$ integrieren. Wir erhalten
   \begin{align*}
   ∫_{-∞}^{∞} \pp{f}{x_j}(x) \d λ(x_j) &\underarrow[=]{kompakter Träger} \quad ∀ j = 2, \dots, k \\
   ∫_{-∞}^{∞} \pp{f}{x_1}(x) \d λ(x_1) &= f_1(0, \underbrace{x_2, \dots, x_k}_{x' ∈ ℝ^{k - 1}})
   \end{align*}
   also
   \[∫_{\{x_1 \leq 0\}} \d ω = ∫_{ℝ^{k - 1}} \d ω = ∫_{ℝ^{k - 1}} f_1(0, x') \d^{k - 1}(x')\]
   Für die Berechnung des Randintegrals bezeichnen wir die Elemente aus $ℝ^{k - 1}$ wieder mit $x' = (x'_1, \dots, x'_{k - 1})$ und schreiben dementsprechend $\d x_j', j = 1, \dots, k - 1$. Die
   Identität $ψ = \id_{ℝ^k}$ induziert die lokale Parametrisierung.
   \[\tilde φ: ℝ^{k - 1} \to \partial \{x_1 \leq 0\} = \{x_1 = 0\} ⊂ ℝ^k, x' ↦ (0, x')\]
   Man erhält
   \begin{align*}
   \tilde φ^{\ast} \d x_j = \d \tilde φ^{\ast} = \d(x_j \circ φ) = \begin{cases} 0 & j = 1 \\ \d x_{j - 1} & j = 2, \dots, k \end{cases}
   \end{align*}
   Schließlich erhält man
   \begin{align*}
   ∫_{\partial \{x_1 \leq 0\}} ω &= ∫_{ℝ^{k - 1}} \tilde φ^{\ast} ω = ∫_{ℝ^{k - 1}} f_1 \abs{\tilde φ(x')} \d x_1' ∧ \dots ∧ \d x_{k - 1}' \\
   &= ∫_{ℝ^{k - 1}} f_1(0, x') \d λ^{k - 1}(x')
   \end{align*}
   #+end_proof
   #+ATTR_LATEX: :options [Glatte Partition der Eins]
   #+begin_thm latex
   Sei $K ⊂ ℝ^n$ kompakt und $(U_j)_{j = 1, \dots, N}$ eine offene Überdeckung von $K$, also $K ⊂ \bigcup_{j = 1}^N U_j$. Dann gibt es eine Überdeckung $(U_j)_{j = 1, \dots, N}$ untergeordnete Partition der Eins $(α_j)_{j = 1, \dots, N}$ mit $α_j ∈ C^{∞} (ℝ^n)$
   und $\supp α_j ⊂ U_j, j = 1, \dots, N$
   #+end_thm
   #+ATTR_LATEX: :options [Satz von Stokes, klassisch]
   #+begin_thm latex
   Sei $Ω ⊂ ℝ^3$ offen, $M ⊂ Ω$ eine orientierte zweidimensionale \(C^2\)-Mannigfaltigkeit, $K ⊂ M$ eine kompakte Teilmene mit glattem Rand $\partial K$ und
   $g ∈ C^1(Ω, ℝ^3)$ ein Vektorgelt, Dann definiert $ω = g · \d \v s$ eine stetig differenzierbare Differntialform der Ordnung $1$ auf $Ω$, und wir haben
   \[∫_K \rot g · ν \d A^2 = ∫_{\partial K} g · τ \d A^1\]
   wobei $ν$ das äußere Normalenfeld auf $K$ bezeichnet und $τ$ das positiv orientierte Tangentialfeld, das von der $K$ induzierten Orientierung auf $\partial K$ bestimmt wird, ist.
   #+end_thm
   #+begin_proof latex
   Natürlich ist $g · \d \v s = g_1 \d x_1 + g_2 \d x_2 + g_3 \d x_3$ eine stetig differenzierbare Differentialform der Ordnung $1$ auf $Ω$. Nach Satz von Stokes haben wir:
   \[∫_K (\rot g) \d \v F = ∫_K \d(g · \d \v s) = ∫_{\partial K} g · \d \v s\]
   Wir nehmen nun an, dass $\partial K$ wie im Beispiel durch Kurvenintegrale durch eine Karte parametrisiert wird. Wir haben (hier: $I = \mathbb{S}^1 \simeq ℝ \setminus ℤ$)
   \begin{align*}
   ∫_{\partial K} g \d \v s = ∫_{\im γ} g \d \v s = ∫I γ^{\ast} (g · \d \v s) = ∫_I g(γ(t)) · γ'(t) \d t \\
   &= ∫_I g(γ(t)) · \underbrace{\frac{γ'(t)}{\abs{γ'(t)}}}_{τ(t)} \abs{γ'(t)} \d t = ∫_{\tilde I} g(\tilde γ(s)) \tilde τ(s) \d s
   \end{align*}
   wobei wir im letzten Schritt eine Reparametrisierung nach der Bogenlänge vorgenommen haben. Die Reparametrisierung ist ebenfalls eine Parametrisierung von $\partial K$, also
   \[∫_{\partial K} g \d \v s = ∫_{\partial K} g τ \d A^1\]
   Zu zeigen bleibt
   \[∫_K f \d \v F = ∫_K f · ν \d A^2\]
   für integrierbares $f$. Dieser Beweis wird hier an dieser Stelle ausgelassen. Mit $f = \rot g$ folgt die Behauptung.
   #+end_proof
   #+ATTR_LATEX: :options [Satz von Gauß, klassisch]
   #+begin_thm latex
   Sei $Ω ⊂ ℝ^3$ offen, $K ⊂ Ω$ kompakt mit glattem Rand $\partial K$ auf dem das äußere Normalenfeld $ν$
   definiert ind und $h ∈ C^1(Ω, ℝ^3)$ ein Vektorfeld. Dann definiert $ω = h · \d \v F$ eine stetig
   differenzierbare Differntialform der Ordnung 2 auf $Ω$ und wir haben
   \[∫_k \Div h \d λ^3 = ∫_{\partial K} h · ν \d A^2\]
   #+end_thm
   #+ATTR_LATEX: :options [Satz von Gauß (Divergenzsatz)]
   #+begin_thm latex
   Für $Ω ⊂ ℝ^n$ offen, ein Vektorfeld $h ∈ C^1(Ω, ℝ^n), K ⊂ Ω$ kompakt und glattem Rand und äußerem Normalenfeld $ν$
   gilt:
   \[∫_K \Div h \d λ^n = ∫_{\partial K} h · ν \d A^{n - 1}\]
   #+end_thm
   #+begin_proof latex
   Offenbar ist $h · \d \v F$ eine differenzierbare Differentialform der Ordnung $2$. Ansonsten ist
   Der erste Satz ein Spezialfall von letzten Satz für $n = 3$. Wir verwenden die Differentialform $\d \v F = (\d F_1, \dots, \d F_n)^T$ mit
   \[\d F_j = (-1)^{j - 1} \d x_1 ∧ \dots ∧ \d x_{j - 1} ∧ \d x_{j + 1} ∧ \dots ∧ \d x_n\]
   und
   \[∫_K f · \d \v F = ∫_K f · ν \d A^{n - 1}\]
   für integrierbare $f: Ω \to ℝ$. Wer erhalten:
   \begin{align*}
   ∫_K \Div h \d λ^n &= ∫_K \Div h \d x_1 ∧ \dots ∧ \d x_n = ∫_K \d (h · \d \v F) \\
   &= ∫_{\partial K} h · \d \v F = ∫_K h · ν \d A^{n - 1}
   \end{align*}
   #+end_proof
   #+ATTR_LATEX: :options [Partielle Integration]
   #+begin_korollar latex
   Für $Ω ⊂ ℝ^n$ offen, $u,v ∈ C^1(Ω), K ⊂ Ω$ kopakt mit glattem Rand und äußerem Normalenfeld $ν$ gilt
   \[∫_K \pp{u}{x_j} v \d λ^n = ∫_{\partial K} u v ν_j \d A^{n - 1} - ∫_K u \pp{v}{x_j} \d λ^n, \quad j = 1, \dots, N\]
   Insbesondere ist auch
   \[∫_K \pp{u}{x_j} \d λ^n = ∫_{\partial K} u ν_j \d A^{n - 1}\]
   #+end_korollar
   #+begin_proof latex
   Mit $h = u v e_j$ erhalten wir aus dem Divergenzsatz:
   \[∫_K (v \pp{u}{x_j} + u \pp{v}{x_j}) \d λ^n = ∫_K \Div h = ∫_{\partial K} h · ν \d A^{n - 1} ∫_{\partial K} u v ν_j \d A^{n - 1}\]
   mit $ν \equiv 1$ folgt die 2te Formel.
   #+end_proof
   #+ATTR_LATEX: :options [Green'sche Formeln]
   #+begin_korollar latex
   Für $Ω ⊂ R^n$ offen, $u, v ∈ C^2(Ω), K ⊂ Ω$ kompakt mit glattem Rand und äußerem Normalenfeld $ν$ gilt
   \begin{align*}
   ∫_K \Laplace u \d λ^n &= ∫_{\partial K} \pp{u}{ν} \d A \\
   ∫_K ∇ u · ∇ v \d λ^n &= ∫_{\partial K} u \pp{v}{ν} \d A - ∫_K u \Laplace v \d λ^n \\
   ∫_K (u \Laplace v - v \Laplace u) \d λ^n &= ∫_{\partial K}(u \pp{v}{ν} - v \pp{u}{ν}) \d A
   \end{align*}
   #+end_korollar
   #+begin_proof latex
   Wir setzen zunächst $h = ∇ u$, dann ist
   \[∫_K \Laplace u \d λ^n = ∫_K ∇ ∇ u \d λ^n = ∫_K \Div ∇ u = ∫_{\partial K} ∇ u · ν \d A^{n - 1} = ∫_{\partial K} \pp{u}{ν} \d A^{n - 1}\]
   Mit $h = u ∇ v$ ist
   \[\Div h = \sum_{j = 1}^{k} \pp{h}{x_j} = ∇u · ∇ v + u \Laplace v\]
   woraus sich
   \[∫_K(∇ u · ∇ v + u \Laplace v) \d λ^n = ∫_{\partial K} u \underbrace{∇ v · ν}_{\pp{u}{ν}} \d A^{n - 1}\]
   ergibt. Durch Vertauschen von $u, v$ in der letzten Gleichung und Subtraktion erhalten wir
   \[∫_K(u \Laplace v - v \Laplace u) \d λ^n = ∫_{\partial K}(u \pp{v}{ν} - v \pp{u}{ν}) \d A^{n - 1}\]
   #+end_proof
