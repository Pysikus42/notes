* Differentiation
  #+ATTR_LATEX: :options [4.1 Differenzquotienten]
  #+begin_defn latex
  Für eine Funktion $f:D\to \mathbb{R}, D\subseteq \mathbb{R}$, definieren wir in einem Punkt $x_0 \in D$ einen
  *Differenzquotienten* durch $D_n f(x_0):= \frac{f(x_0 + h) - f(x_0)}{h}$, wobei $x_0 + h \in D$
  #+end_defn
  #+ATTR_LATEX: :options [4.2 Ableitung]
  #+begin_defn latex
  $f:D\to\mathbb{R}$ heißt *differenzierbar* im Punkt $x_0 \in D$ mit *Ableitung* $f'(x_0)$, wenn
  für jede Nullfolge $(h_n)_{n\in\mathbb{N}}$ mit $x_0 + h_n \in D$, die Folge $(D_{h_n} f(x_0))_{n\in\mathbb{N}}$
  konvergiert zu $f'(x_0)$
  #+end_defn
  #+begin_remark latex
  $f'(x)$ ist eindeutig.
  #+end_remark
  #+begin_proof latex
  Für zwei Nulfolge $h_n, \tilde h_n$, sodass:
  \[\lim_{n\to\infty} D_{h_n} f(x_0) = a, \lim_{n\to\infty} D_{\tilde h_n} f(x_0) = \tilde a\]
  fassen wir eine Nullfolge $\{h_1, \tilde h_1, h_2, \tilde h_2, \ldots\}$ zusammen. Der
  zugeörige Differenzquotient konvergiert $\implies a = \tilde a$
  #+end_proof
  Notation:
  \begin{align*}
  f'(x_0) &=: \dd{f}{x}(x_0) \\
  f'(x_0) &= \lim_{\substack{x\in D \\ x\to x_0}}  \frac{f(x) - f(x_0)}{x - x_0}
  \end{align*}
  #+ATTR_LATEX: :options [4.3]
  #+begin_defn latex
  Eine Funktion $f:D\to\mathbb{R}$ heißt differenzierbar auf $D$, wenn sie in edem Punkt $x_0 \in D$ differenzierbar ist. Sie heißt stetig differenzierbar, wenn
  die Ableitung $f'$ auf $D$ eine stetige Funktion ist.
  #+end_defn
  #+begin_remark latex
  Im Falle eines Randpunktes behalten wir einseite Stetigkeit. $D = [a,b]:$
  - für $x_0 = a, x\downarrow a :\iff x > a \wedge x \to a$
  - für $x_0 = b, x\uparrow b :\iff x < b \wedge x \to b$
  #+end_remark
  #+ATTR_LATEX: :options [4.4]
  #+begin_thm latex
  Eine Funktion $f:D\to\mathbb{R}$ ist in einem $x_0 \in D$ genau dann differenzierbar mit Ableitung $f'(x_0)$, wenn
  \[\Forall \eps > 0 \Exists \delta_\eps > 0: x_0 + h \in D, \abs{h} < \delta_\eps \implies \abs{\frac{f(x_0 + h) - f(x_0)}{h} - f'(x_0)} <  \eps\]
  #+end_thm
  #+begin_proof latex
  Beweis aus der Definition des Grenzwerts.
  #+end_proof
  #+ATTR_LATEX: :options [4.5]
  #+begin_thm latex
  Eine Funktion $f:D\to\mathbb{R}$ ist genau dann in einem Punkt $x_0\in D$ differenzierbar, wenn es eine Konstante gibt, $x\in\mathbb{R}$, sodass
  \[f(x) = f(x_0) + c(x - x_0) + \omega(x), x\in D\]
  mit einer Funktion $\omega:D\to\mathbb{R}$, sodass
  \[\lim_{\substack{x\in D\\ x\to x_0}} = 0\]
  Diese Konstante $c = f'(x_0)$
  #+end_thm
  #+begin_proof latex
  Sei $f$ in $x$ differenzierbar und $\omega(x) := f(x) - f(x_0)(x - x_0)$. Dann aus differenzierbarkeit von $f$
  \[\frac{\omega(x)}{x - x_0} = \frac{f(x) - f(x_0)}{x - x_0} - f'(x_0) \xrightarrow{x\to x_0} 0\]
  Sei umgekehrt $f(x) = f(x_0) + c(x - x_0) + \omega(x)$ mit $\lim_{x\to x_0} \frac{\omega(x)}{x\to x_0} = 0$
  Dann gilt:
  \[\frac{f(x) - f(x_0)}{x - x_0} - c = \frac{\omega(x)}{x - x_0} \xrightarrow{x\to x_0} 0\]
  das heißt $f$ ist in $x_0$ differenzierbar mit Ableitung $f'(x_0)$
  #+end_proof
  #+begin_remark latex
  Der Satz besagt, dass affin-lineare Funktion (Gerade) $g(x) = f(x_0) + f'(x_0)(x - x_0)$
  approximiert die differenzierbare Funktion in $x_0 \in D$. Der Graph von $g$ ist
  die tangenta an dem Graphen von $f$ in $(x_0, f(x_0))$
  #+end_remark
  #+ATTR_LATEX: :options [4.6]
  #+begin_lemma latex
  Eine Funktion $f:D\to\mathbb{R}$ in $x_0 \in D$ differenzierbar ist dort stetig.
  #+end_lemma
  #+begin_proof latex
  \[f(x) = f(x_0) + f'(x_0)(x - x_0) + \omega(x) \Rightarrow f(x) \xrightarrow{x\to x_0} f(x_0)\]
  #+end_proof
  #+begin_remark latex
  Man kann die n-te Ableitung rekursiv definieren.
  \begin{align*}
  \frac{\d^n f}{\d x^n}(x) = f^{(n)}(x), n\geq 3 \\
  \frac{\d^2 f}{\d x^2} (x) = f^{(2)}(x) = f''(x)
  \end{align*}
  #+end_remark
  #+ATTR_LATEX: :options [4.7]
  #+begin_ex latex
  $f(x) = \abs{x}$ ist nicht in $x_0 = 0$ differenzierbar. Um dies zu sehen, betrachten wir eine Nullfolge
  \[h_n = (-1)^n \frac{1}{n}, n\in \mathbb{N}\]
  und
  \[\frac{f(h_n) - f(0)}{h_n} = \frac{\abs{h_n}}{h_n} = (-1)^n\]
  nicht konvergent. $in x_0 \neq 0$ ist $f(x) = \abs{x}$ differenzierbar
  #+end_ex
  #+ATTR_LATEX: :options [4.8]
  #+begin_lemma latex
  Für $f,g: D\to\mathbb{R}$ differenzierbar gelten die folgenden Rechenregeln:
  1. Linearkombination ist differenzierbar $(\alpha f + \beta g)' = \alpha f' + \beta g', \alpha,\beta\in\mathbb{R}$
  2. $(f\cdot g)'(x) = f'(x)g(x) + f(x) g'(x)$
  3. $g(x) \neq 0$
	 \[(\frac{f}{g})'(x) = \frac{f'(x)g(x) - f(x)g'(x)}{g^2(x)}\]
  #+end_lemma
  #+begin_proof latex
  1. Aus den Eigenschaften von konvergenten Zahlenfolgen
  2. Aus Definition:
     \begin{align*}
     \left\string(f\cdot g)'\left\string(x_0) &= \lim_{x\to x_0}  \frac{f(x)(g(x) - g(x_0)) + (g(x) - f(x_0))g(x)}{x - x_0} \\
     &= f(x_0)g'(x_0) + f'(x)g(x)
     \end{align*}
  3. Erst $f \equiv 1$
     \begin{align*}
     \left\string(\frac{1}{g})'\left\string(x) &= \lim_{x\to x_0} (\frac{1}{g(x)} - \frac{1}{g(x_0)}) \frac{1}{x - x_0} \\
     &= \lim_{x\to x_0} \frac{g(x_0) - g(x)}{g(x)g(x_0)} \frac{1}{x - x_0} \\
     &= \lim - \frac{g'(x_0)}{g^2(x_0)} \\
     \left\string(\frac{f}{g})'\left\string(x_0) = (f \frac{1}{g})'(x_0) = \frac{f' g - f g'}{g^2}(x)
     \end{align*}
  #+end_proof
  #+ATTR_LATEX: :options [4.9]
  #+begin_lemma latex
  Sei $f:D\to B\subseteq\mathbb{B}$ eine auf einem abgeschlossenen Definitionsbereich stetige und invertierbare Funktion mit Inverse $f^{-1}: B\to D$.
  Ist $f$ in einem $x_0 \in D$ differenzierbar mit $f'(x_0) \neq 0$, so ist auch $F^{-1}$ in einem $y_0 = f(x_0)$ differenzierbar
  und es gilt
  \[(f^{-1})'(y_0 = \frac{1}{f'(x_0)}, y_0 = f(x_0))\]
  #+end_lemma
  #+begin_proof latex
  Für $y_n = f(x_n), y_0 = f(x_0)$ mit $y_n \neq y_0$ und $y_n \xrightarrow{n\to\infty} y_0$.
  Aus Stetigkeit von $f^{-1}$ gilt auch $x_n \xrightarrow{n\to\infty} x_0$ und $x_n \neq x_0$.
  Aus der Differenzierbarkeit von $f$ in einem $x_0$ folgt:
  \[\frac{f^{-1}(y_n) - f^{-1}(y_0)}{y_n - y_0} = \frac{x_n - x_0}{f(x_n) - f(x_0)} = (\frac{f(x_n) - f(x_0)}{x_n - x_0})^{-1} \xrightarrow{n\to\infty} (f'(x_0))^{-1}\]
  Dies impliziert, dass $f^{-1}$ im Punkt $y_0 = f(x_0)$ differenzierbar ist mit der Ableitung $\frac{1}{f'/x_0}$
  #+end_proof
  #+ATTR_LATEX: :options [4.10]
  #+begin_ex latex
  \mbox{}
  1. $\displaystyle \ln'(y): f^{-1}(y) = \ln{y}, f(x) = e^x \implies \ln'(y) = \frac{1}{(e^x)'} = \frac{1}{e^x} = \frac{1}{y}$
  2. Umkehrfunktion des Sinus
	 \begin{align*}
	 y &= \sin{x}, x\in (-\frac{\pi}{2}, \frac{\pi}{2}) \\
	 x = \arcsin{y}, y\in (-1,1) = D \\
	 \arcsin'(y) = \frac{1}{\sin'(x)} = \frac{1}{\cos{x}} = \frac{1}{\sqrt{1 - \sin^2{x}}} = \frac{1}{\sqrt{1 - y^2}}
	 \end{align*}
  #+end_ex
  #+ATTR_LATEX: :options [4.11 Kettenregel]
  #+begin_lemma latex
  Seien $g:D_g \to \mathbb{R}, f:D_f \to D_g \subseteq \mathbb{R}$ stetige Funktionen. Die Funktion $f$ sei in $x_0 \in D_f$ differenzierbar
  und $g in y_0 = f(x_0)$ differenzierbar. Dann ist die zusammengesetzte Funktion $g(f(x_0)) =: (g\circ f)(x_0)$ in $x_0$ differenzierbar und
  es gilt
  \[(g\circ f)'(x_0) = g'(f(x_0))f'(x) \tag{Kettenregel}\]
  #+end_lemma
  #+begin_proof latex
  \begin{align*}
  \intertext{Wir definieren eine Funktion $\Delta g: D_g \to \mathbb{R}$ durch}
  \Delta g\string(y\string) &:= \begin{cases} \frac{g(y) - f(y_0)}{y - y_0} & y \neq y_0 \\ g'(y) & y = y_0\end{cases} \\
  \intertext{Da $g$ in $y_0$ differenzierbar ist gilt}
  \lim_{y \to y_0} \Delta g(y) &= g'(y_0) \\
  \intertext{Ferner gilt für $y\in D_g$:}
  g\string(y\string) - g(y_0) &= \Delta g(y)(y - y_0) \\
  \intertext{Damit erhalten wir}
  \string(g\circ f\string)'\string(x_0\string) &= \lim_{x\to x_0} \frac{g(f(x)) - g(f(x_0))}{x - x_0} \\
  &= \lim_{x \to x_0} \frac{\Delta g(f(x))(f(x) - f(x_0))}{x - x_0} \\
  &= \lim_{x\to x_0} \Delta g(f(x)) \lim_{x - x_0} \frac{f(x) - f(x_0)}{x - x_0} = g'(f(x_0))f'(x_0) \tag*{\qedhere}
  \end{align*}
  #+end_proof
  #+ATTR_LATEX: :options [4.12]
  #+begin_ex latex
  1. $g(x) = f(a x + b), a, b \in\mathbb{R} \implies g'(x) = a f'(a x + b)$
  2. $x^{\alpha} = e^{\alpha \ln{x}} = f(g(x)) = f(g(x)), f(y) := e^y, g(x) := \alpha \ln(x)$ \\
	 \[(x^{\alpha})' = f'(g(x))g'(x) = e^{\alpha\ln{x}}\alpha x^{-1} = \alpha x^{\alpha - 1}\]
  #+end_ex
** Mittelwertsätze und Extremalbedingungen
   #+ATTR_LATEX: :options [4.13]
   #+begin_defn latex
   Die Funktion $f:D\to\mathbb{R}$ hat in einem Punkt $x_0 \in D$ ein *globales Extremum* (Minimum oder Maximum), wenn gilt
   \[f(x_0) \leq f(x), x\in D \vee f(x_0) \geq f(x) \Forall x \in D\]
   Es handelt sich um ein *lokales Extremeum* (Minimum oder Moaximum), wenn auf einer $\delta$-Umgebung von $x_0$ (das heißt $U_\delta(x_0) = \{x\in D\mid\abs{x - x_0} < \delta\}$)
   gilt $f(x_0) \geq f(x) \Forall x\in U_\delta(x_0) \vee f(x_0) \leq f(x) \Forall x\in U_\delta(x_0)$
   Ein Extremum (globales oder lokales) heißt strikt, wenn es das isolierteste PUnkt in $D$ beziehungsweise in $U_\delta(x_0)$ ist, as heißt $f(x_0) > f(x) \vee f(x_0) < f(x)$
   #+end_defn
   #+ATTR_LATEX: :options [4.14 Satz von Extremum]
   #+begin_thm latex
   Besitz eine auf einem Intervall $I = (a,b)$ differenzierbare Funktion ein lokales Extremum $x_0 \in I$, so gilt dort notwendig $f'(x_0) = 0$
   #+end_thm
   #+begin_proof latex
   Habe $f$ in $x_0$ ein Minimum. Dann gilt für eine $(h_n)_{n\in\mathbb{N}}$ mit $h_n > 0, x_0 + h_n \in U_\delta(x_0)$
   \[\frac{f(x_0 + h_n) - f(x_0)}{h_n} \geq 0\]
   für eine Nullfolge $(h_n)_n\in\mathbb{N}$ mit $h_n < 0, x_0 + h_n \in U_\delta(x_0)$
   \[\frac{f(x_0 + h_n) - f(x_0)}{h_n} \leq 0\]
   Im Limes $h_n \to 0$ bekommen wir
   \[f'(x_0) \leq 0 \leq f'(x_0) \implies f'(x_0) = 0\]
   (Analog für Maximum)
   #+end_proof
   #+begin_remark latex
   Eine stetige Funktion besitzt auf einem abgeschlossenem Interball $[a,b]$ ein Minimum. Dieses kann in einem Randpunkt ($x_0 = a vee x_0 = b$) liegen,
   das heißt es ist nicht notwendig, das $f'(x_0) = 0$
   #+end_remark
   #+ATTR_LATEX: :options [4.15 Satz von Rolle]
   #+begin_thm latex
   Wenn eine im Interball $[a,b]$ stetige Funktion, in $(a,b)$ differenzierbar ist und $f(a) = f(b)$, so existiert ein $c\in (a,b)$, sodass $f'(c) = 0$
   #+end_thm
   #+begin_proof latex
   - Stetige Funktion auf $[a,b]$ nimmt ihr Maximum und Minimum
   - Wenn $f$ ist konstant $\implies f'(x) = 0$
   - Wen $f$ nicht konstant $\implies \Exists x_0 \in (a,b): f(x_0) > f(a) = f(b) \vee f(x_0) < f(a) = f(b)$
   $\implies$ das Maximum oder Minimum ist in einem $x_0 \in (a,b)$ angenommen $\implies f'(x_0) = 0$
   #+end_proof
   #+ATTR_LATEX: :options [4.16 1. Mittelwertsatz]
   #+begin_thm latex
   Ist $f$ stetig in $[a,b]$ und differenzierbar in $(a,b)$, so $\Exists c \in (a,b): f'(c) = \frac{f(b) - f(a)}{b - a}$
   #+end_thm
   #+begin_proof latex
   Wir definieren Funktion
   \[g(x) := f(x) - \frac{f(b) - f(a)}{b - a}(x - a)\]
   - $g$ ist stetig in $[a,b]$, differenzierbar in $(a,b)$
   - $g(a) = f(a) = g(b)$, Satz von Rolle liefert, dass $\Exists c\in(a,b): g'(c) = 0$
   \[0 = g'(c) = f'(c) - \frac{f(b) - f(a)}{b - a} \implies f'(c) = \frac{f(b) - f(a)}{b - a}\tag*{\qedhere}\]
   #+end_proof
   #+ATTR_LATEX: :options [4.17]
   #+begin_korollar latex
   Sei $f:(a,b) \to \mathbb{R}$ mindestens zweimal differenzierbar mit $f'(x_0) = 0$für ein $x_0 \in (a,b)$.
   Dann hat $f$ im Fall $f''(x_0) > 0$ in $x_0$ ein striktes lokales Minimum und im Fall $f''(x_0) < 0$ ein striktes lokales Maximum.
   #+end_korollar
   #+begin_proof latex
   Sei $f$ zweimal differenzierbar mit $f''(x_0) > 0$ Wegen
   \[f''(x_0) = \lim_{x\to x_0} \frac{f'(x) - f'(x_0)}{x - x_0} > 0\]
   gibt es ein $\eps \in \mathbb{R}_+$, sodass f+r $0 < \abs{x - x_0} < \eps$ gilt
   \[\frac{f'(x) - f'(x_0)}{x - x_0} > 0\]
   mit $f'(x_0) = 0$ folgt damit
   \begin{align*}
   f'(x) < 0 &\quad x\in (x_0 - \eps, x_0) \\
   f'(x) < 0 &\quad x\in(x_0, x_0 + \eps)
   \end{align*}
   $\implies f$ ist streng monoton fallend in $x\in (x_0 - \eps, x_0)$ und streng monoton wachsend in $(x_0, x_0 + \eps)$,
   das heißt $f$ hat in $x_0$ ein striktes lokales Maximum (Analog im Fall $f''(x_0) < 0$)
   #+end_proof
   #+begin_remark latex
   Es ist keine notwendige Bedingung zum Beispiel $f(x) = x^4$ hat lokales Minimum $x_0 = 0$, aber $f''(x_0) = 0$
   #+end_remark
   #+ATTR_LATEX: :options [4.18]
   #+begin_defn latex
   Sei $I$ ein offenes Intervall $f:I \to \mathbb{R}$ heißt
   - (streng) konvex $\iff \Forall \lambda \in (0,1), x, y \in I: f(\lambda x + (1 - \lambda)y) \leq (\underarrow[<]{streng}) \lambda f(x) + (1 - \lambda) f(y)$
   - (streng) konkab $\iff \Forall \lambda \in (0,1), x, y \in I: f(\lambda x + (1 - \lambda)y) \geq (\underarrow[>]{streng}) \lambda f(x) + (1 - \lambda) f(y)$
   #+end_defn
   #+ATTR_LATEX: :options [4.19]
   #+begin_ex latex
   $\exp$ ist eine (streng) konvexe Funktion
   Für $\lambda \in (0,1), x < y$ gilt:
   \begin{align*}
   \exp(\lambda x + (1 - \lambda)y) &= \exp(x + (1 - \lambda)(y - x)) = \exp(x)\exp((1 - \lambda)(y - x)) \\
   &= \exp(x)(\underbrace{\lambda + 1 - \lambda}_{= 1} + \sum_{j = 1}^{\infty}(1 - \lambda)^j \frac{(y - x)^j}{j'}) \\
   &= \lambda \exp(x) + (1 - \lambda)\exp(x)(1 + \sum_{j = 1}^{\infty}\underbrace{(1 - \lambda)^{j - 1}}_{< 1}) \frac{(y - x)^j}{j'} \\
   &< \lambda\exp(x) + (1 -  \lambda)\exp(x)\exp(y - x) = \lambda\exp(x) + (1 - \lambda)\exp(y)
   \end{align*}
   #+end_ex
   #+ATTR_LATEX: :options [4.20]
   #+begin_korollar latex
   Sei $I$ offen, $f: I\to\mathbb{R}$ zweimal differenzierbar. Falls $f''(x) \geq 0 \Forall x\in I$, so ist $f$ konvex.
   #+end_korollar
   #+begin_proof latex
   $f'' > 0 \implies f'$ monoton ist wachsend. Für $x = y$ ist $f(\lambda x + (1 - \lambda)y) = \lambda f(x) + (1 - \lambda)f(y)$
   Ohne Beschränkung der Allgemeinheit nehmen wir $x < y, x,y\in I, \lambda \in (0,1)$. Wir setzen $x_\lambda := \lambda x + (1 - \lambda)y$
   Nach dem Mittelwertsatz $\Exists \xi \in (x, x_\lambda)$ und $\eta \in (x_\lambda, y)$ mit
   \[\frac{f(x_\lambda) - f(x)}{x_\lambda - x} \underarrow[=]{Mittelwertsatz} = f'(\xi) \overarrow[\leq]{aus Monotonität} f''(\eta) \underarrow[=]{Mittelwertsatz} \frac{f(y) - f(x_\lambda)}{y - x_\lambda}\]
   \begin{align*}
   \intertext{Es gilt:}
   x_\lambda - x &= \lambda x + (1 -  \lambda)y - x = (1 - \lambda)(y - x) \\
   y - x_\lambda &= y - \lambda x - (1 - \lambda) y = \lambda(y - x) \\
   \intertext{Damit erhält man:}
   \frac{f(x_\lambda) - f(x)}{1 - \lambda} &\leq \frac{(f(y) - f(x_\lambda))}{(y - x_\lambda)} \frac{(x_\lambda - x)}{1 - \lambda} = (f(y) - f(x_\lambda))\frac{(1 - \lambda)(y - x)}{\lambda(y - x)(1 - \lambda)} = \frac{f(y) - f(x_\lambda)}{\lambda} \\
   &\implies f(x_\lambda) \leq \lambda f(x) + (1 - \lambda)f(y) \\
   &\implies f(\lambda x + (1 -\lambda) y) \leq \lambda f(x) + (1 - \lambda)f(y)  \implies f ~\text{ist konvex} \tag*{\qedhere} \\
   \end{align*}
   #+end_proof
   #+ATTR_LATEX: :options [2. Mittelwertsatz (verallgemeinert)]
   #+begin_thm latex
   Sind die Funktion $f$ und $g$ in $[a, b]$ stetig und in $(a, b)$ differenzierbar und $g'(x) \neq 0$ für $x\in (a, b)$,
   so gibt es ein $c\in (a, b)$ sodass
   \[\frac{f'(c)}{g'(c)} = \frac{f(b) - f(a)}{g(b) - g(a)}\]
   #+end_thm
   #+begin_proof latex
   Wegen $g'(x) \neq 0$ bekommen wir $g(a) \neq g(b)$ (wegen Satz von Rolle). Weiter
   \[\Exists c\in (a,b): \frac{g(b) - g(a)}{b - a} = g'(c) \neq 0\]
   Wir definieren auf $[a, b]$ die Funktion
   \[F(x) := f(x) - \frac{f(b) - f(a)}{g(b) - g(a)} g'(c)\]
   Wir verifizieren $\underline{F(a)} = f(a) = \underline{F(b)}$.
   Nach dem Setz von Rolle gibt es ein $c\in (a, b)$ mit $F'(c) = 0$, das heißt
   \begin{align*}
   0 &= F'(c) = f'(c) = \frac{f(b) - f(a)}{g(b) - g(a)} g'(c) \\
   \intertext{wegen $g'(c) \neq 0$:}
   \frac{f'(c)}{g'(c)} = \frac{f(b) - f(a)}{g(b) - g(a)} \tag*{\qedhere}
   \end{align*}
   #+end_proof
** Anwendung von MW Satz 2
   #+ATTR_LATEX: :options [Regeln von L'Hospital]
   #+begin_thm latex
   Es seien $f,g: I \to \mathbb{R}, I = (a, b)$ sodass $g'(x) \neq 0 \Forall x\i I$ und \[\lim_{x \downarrow a} \frac{f'(x)}{g'(x)} =: c \in \mathbb{R}\]
   Dann gelten die Folgenden Regeln:
   1. Im Fall
	  \[\lim_{x\downarrow a} f(x) = \lim_{x\downarrow a} g(x) = 0\]
	  ist $g(x) \neq 0$ in $I$ und es gilt
	  \[\lim_{x\downarrow a} \frac{f(x)}{g(x)} = c\]
   2. Im Fall $f(x) \to \pm \infty, g(x) \to\pm \infty$ für $x\downarrow a$ ist $g(x) \neq 0$ für $a < x y x_\ast \leq b$ und
	  \[\lim x\downarrow a \frac{f(x)}{g(x)} = c\]
   #+end_thm
   #+begin_proof latex
   1. Wir fassen $f$ und $g$ als Funktion auf, die in $a$ stetigs sind $f(a) = g(a) = 0$. Wegen $g'(x) \neq 0$ kann $g$ keine weitere
	  Nullstelle von $g$ in $I$ geben, das heißt $g(x) \neq 0$ in $I$. Satz 4.21 $\implies$
	  \[\Forall x \in I \Exists \xi \in (a, x): \frac{f(x)}{g(x)} = \frac{f'(\xi)}{g'(\xi)}\]
	  $\implies$ für $x \to a$ auch $\xi \to a$ und
	  \[\lim_{x\downarrow a} \frac{f(x)}{g(x)} = \lim_{\xi \downarrow a} \frac{f'(\xi)}{g'(\xi)}\]
   2. Sei $\eps > 0$ beliebig. Nach Vorraussetzung ist $g'(x) \neq 0$ in $(a, b)$.
	  \begin{gather*}
	  \intertext{Wir wählen ein $\delta > 0$ mit $a + \delta \leq x_\ast$, sodass}
	  \Forall x \in (a, a + \delta): f(x) \neq 0 \wedge g(x) \neq 0 \wedge \abs{\frac{f'(x)}{g'(x)} - c} < \eps \\
	  \intertext{Für beliebigs $x, y \in (a, a + \delta)$ mit $f(x) \neq f(y)$}
	  \frac{f(x)}{g(x)} = \frac{f(x) - f(y)}{g(x) - g(y)} \frac{g(x) - g(y)}{f(x) - f(y)} \frac{f(x)}{g(x)} = \frac{f(x) - f(y)}{g(x) - g(y)} \frac{(1 - \frac{g(y)}{g(x)})g(x)}{\underbrace{(1 - \frac{f(y)}{f(y)})}_{x\downarrow a \to 1}f(x)}  \frac{f(x)}{g(x)} \\
	  \implies \Exists \delta_\ast > 0: \Forall x \i n(a, a + \delta_\ast): \abs{\frac{f(x)}{g(x)} - \frac{f(x) - f(y)}{g(x) - g(y)}} < \eps
	  \intertext{Für ein $x$ sodass $a < x < \underbrace{a + \min\{\delta, \delta_\ast\}}_{x_\ast}$ bekommen wir}
	  \abs{\frac{f(x)}{g(x)} - c} < 2\eps \tag*{\qedhere}
	  \end{gather*}
   #+end_proof
   #+ATTR_LATEX: :options [4.23]
   #+begin_ex latex
   $I = (0, 1), f(x) = \ln(x), g(x) = x - 1, f'(x) = \frac{1}{x}, g'(x) = 1$
   \[\lim_{x\to 1} \frac{f'(x)}{g'(x)} = 1, \lim_{x\uparrow 1} \frac{\ln x}{x - 1} = \lim_{x\uparrow 1} \frac{\frac{1}{x}}{1} = 1\]
   #+end_ex
   #+begin_remark latex
   Analoge Aussagen gelten auch für $x \to \pm \infty$. Wir nehmen $y := \frac{1}{x} \to 0$ und
   \[\lim_{x\to\pm\infty} \frac{f(x)}{g(x)} = \lim_{y \to 0_{\pm}} \frac{f(\frac{1}{x})}{g(\frac{1}{x})} = \lim_{\lambda \to \pm \infty} \frac{f'(\lambda)}{g'(\lambda)}\]
   #+end_remark
   #+begin_remark latex
   Bei der Anwendung der Regeln von L'Hospital ist zunächst zu prüfen, ob die Limes von $\frac{f'(x)}{g'(x)}$ überhaupt existiert.
   zum Beispiel
   \[\lim_{x\downarrow 0} \frac{x^2 \sim(\frac{1}{x})}{\sin{x}} = \lim_{x \downarrow} \frac{x}{\sin{x}} x \sin{\frac{1}{x}}  = 0\]
   aber
   \[\lim_{x\downarrow 0} \frac{2x \sin{\frac{1}{x}} + x^2 \cos{\frac{1}{x}}(- \frac{1}{x^2})}{\cos{x}} = \lim_{x\downarrow 0} \frac{2x \sin{\frac{1}{x}} - \cos{\frac{1}{x}}}{\cos{x}} = -\lim_{x\downarrow 0} \cos{\frac{1}{x}}\]
   der existiert nicht
   #+end_remark
   #+begin_remark latex
   Die L'Hospital Regeln kann man auch anwenden in dem Fall
   \[f(x) \to 0, g(x) \to  \infty ~\text{für}~ \lim_{x\downarrow a} f(x) g(x) = \lim_{x\downarrow} \frac{f(x)}{\frac{1}{g(x)}}\]
   Auch für $0^0, \infty^0, 0^\infty$
   #+end_remark
   #+ATTR_LATEX: :options [4.24]
   #+begin_ex latex
   1. $\lim_{x\downarrow 0} x^x$ Wir logarithmieren und erhalten
	  \[\lim_{x\downarrow 0} x\ln x = \lim_{x\downarrow 0} \frac{\ln x}{\frac{1}{x}} = \lim_{x\downarrow 0} \frac{\frac{1}{x}}{-\frac{1}{x^2}} = 0\]
	  und
	  \[\lim_{x\downarrow 0} x^x = \lim_{x\downarrow 0} e^{x\ln x} = e^0 = 1\]
   2. $\lim_{x\to 1} x^{\frac{1}{x - 1}} = \lim_{e^{\frac{1}{x - 1} \ln x}}, \lim_{x \to 1} \frac{1}{x -1} \ln x = \lim_{x \to 1} \frac{\frac{1}{x}}{1} = 1 \implies \lim_{x \to 1} x^{\frac{1}{x - 1}} = e^1 = e$

   #+end_ex
